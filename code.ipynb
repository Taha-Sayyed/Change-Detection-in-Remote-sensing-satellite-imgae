{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the setup_directories.py file first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T04:14:39.812558Z",
     "iopub.status.busy": "2025-09-05T04:14:39.811735Z",
     "iopub.status.idle": "2025-09-05T04:14:39.820764Z",
     "shell.execute_reply": "2025-09-05T04:14:39.820164Z",
     "shell.execute_reply.started": "2025-09-05T04:14:39.812519Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ setup_directories.py created!\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Create setup_directories.py\n",
    "setup_code = '''# Setup script to create required directories in Kaggle\n",
    "import os\n",
    "\n",
    "def setup_kaggle_directories():\n",
    "    \"\"\"\n",
    "    Creates the required directory structure in Kaggle working directory\n",
    "    \"\"\"\n",
    "    # Create data_utils folder\n",
    "    data_utils_path = '/kaggle/working/data_utils'\n",
    "    os.makedirs(data_utils_path, exist_ok=True)\n",
    "    \n",
    "    # Create output directories for processed patches\n",
    "    output_dirs = [\n",
    "        '/kaggle/working/processed_data/train/T1',\n",
    "        '/kaggle/working/processed_data/train/T2', \n",
    "        '/kaggle/working/processed_data/train/label',\n",
    "        '/kaggle/working/processed_data/val/T1',\n",
    "        '/kaggle/working/processed_data/val/T2',\n",
    "        '/kaggle/working/processed_data/val/label',\n",
    "        '/kaggle/working/processed_data/test/T1',\n",
    "        '/kaggle/working/processed_data/test/T2',\n",
    "        '/kaggle/working/processed_data/test/label'\n",
    "    ]\n",
    "    \n",
    "    for dir_path in output_dirs:\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "        print(f\"Created directory: {dir_path}\")\n",
    "    \n",
    "    print(\"✅ All directories created successfully!\")\n",
    "    print(\"\\\\nDirectory structure:\")\n",
    "    print(\"📁 /kaggle/working/\")\n",
    "    print(\"  └── 📁 data_utils/\")\n",
    "    print(\"  └── 📁 processed_data/\")\n",
    "    print(\"      ├── 📁 train/ (T1, T2, label)\")\n",
    "    print(\"      ├── 📁 val/ (T1, T2, label)\")  \n",
    "    print(\"      └── 📁 test/ (T1, T2, label)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    setup_kaggle_directories()\n",
    "'''\n",
    "\n",
    "# Write the setup file\n",
    "with open('/kaggle/working/setup_directories.py', 'w') as f:\n",
    "    f.write(setup_code)\n",
    "\n",
    "print(\"✅ setup_directories.py created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T04:14:45.802638Z",
     "iopub.status.busy": "2025-09-05T04:14:45.802171Z",
     "iopub.status.idle": "2025-09-05T04:14:45.808437Z",
     "shell.execute_reply": "2025-09-05T04:14:45.807734Z",
     "shell.execute_reply.started": "2025-09-05T04:14:45.802613Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: /kaggle/working/processed_data/train/T1\n",
      "Created directory: /kaggle/working/processed_data/train/T2\n",
      "Created directory: /kaggle/working/processed_data/train/label\n",
      "Created directory: /kaggle/working/processed_data/val/T1\n",
      "Created directory: /kaggle/working/processed_data/val/T2\n",
      "Created directory: /kaggle/working/processed_data/val/label\n",
      "Created directory: /kaggle/working/processed_data/test/T1\n",
      "Created directory: /kaggle/working/processed_data/test/T2\n",
      "Created directory: /kaggle/working/processed_data/test/label\n",
      "✅ All directories created successfully!\n",
      "\n",
      "Directory structure:\n",
      "📁 /kaggle/working/\n",
      "  └── 📁 data_utils/\n",
      "  └── 📁 processed_data/\n",
      "      ├── 📁 train/ (T1, T2, label)\n",
      "      ├── 📁 val/ (T1, T2, label)\n",
      "      └── 📁 test/ (T1, T2, label)\n"
     ]
    }
   ],
   "source": [
    "exec(open('/kaggle/working/setup_directories.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data_utils folder and files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T04:14:53.545914Z",
     "iopub.status.busy": "2025-09-05T04:14:53.545659Z",
     "iopub.status.idle": "2025-09-05T04:14:53.550967Z",
     "shell.execute_reply": "2025-09-05T04:14:53.550240Z",
     "shell.execute_reply.started": "2025-09-05T04:14:53.545893Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ data_utils package created!\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Create data_utils directory\n",
    "import os\n",
    "os.makedirs('/kaggle/working/data_utils', exist_ok=True)\n",
    "\n",
    "# Create __init__.py to make it a package\n",
    "with open('/kaggle/working/data_utils/__init__.py', 'w') as f:\n",
    "    f.write('# Data utilities package\\n')\n",
    "\n",
    "print(\"✅ data_utils package created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T04:15:26.111514Z",
     "iopub.status.busy": "2025-09-05T04:15:26.110735Z",
     "iopub.status.idle": "2025-09-05T04:15:26.118522Z",
     "shell.execute_reply": "2025-09-05T04:15:26.117827Z",
     "shell.execute_reply.started": "2025-09-05T04:15:26.111487Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ augment.py created!\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Create augment.py\n",
    "# Copy the augment.py code here (from the artifact above)\n",
    "with open('/kaggle/working/data_utils/augment.py', 'w') as f:\n",
    "    f.write('''import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "import math\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as tf\n",
    "\n",
    "class Augmentation:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def randomSpaceAugment(self, image, source_size=(256, 256), angle=None, scale=(0.8, 1.25), unoverlap=None):\n",
    "        \"\"\"\n",
    "        Apply random spatial augmentations to a list of images\n",
    "        \n",
    "        Args:\n",
    "            image: List of PIL Images\n",
    "            source_size: Target size (height, width)\n",
    "            angle: Rotation angle (if None, random angle is chosen)\n",
    "            scale: Scale range tuple (min, max)\n",
    "            unoverlap: Overlap parameter (if None, random cropping is applied)\n",
    "        \"\"\"\n",
    "        if angle is None:\n",
    "            angle = transforms.RandomRotation.get_params([-180, 180])\n",
    "        \n",
    "        if isinstance(angle, list):\n",
    "            angle = random.choice(angle)\n",
    "        \n",
    "        # Rotation\n",
    "        for i in range(len(image)):\n",
    "            image[i] = image[i].rotate(angle)\n",
    "        \n",
    "        # Horizontal flip\n",
    "        if random.random() > 0.5:\n",
    "            for i in range(len(image)):\n",
    "                image[i] = tf.hflip(image[i])\n",
    "        \n",
    "        # Vertical flip  \n",
    "        if random.random() > 0.5:\n",
    "            for i in range(len(image)):\n",
    "                image[i] = tf.vflip(image[i])\n",
    "        \n",
    "        img_bias_y_rate = 0.0\n",
    "        img_bias_x_rate = 0.0\n",
    "        scale_times = 1.0\n",
    "        \n",
    "        # Scale resize\n",
    "        if random.random() > 0.25:\n",
    "            img_h, img_w = np.array(image[0]).shape[:2]\n",
    "            scale_times = torch.empty(1).uniform_(scale[0], scale[1]).item()\n",
    "            scale_h, scale_w = int(img_h * scale_times), int(img_w * scale_times)\n",
    "            \n",
    "            # Resize RGB images (first 2) with BICUBIC\n",
    "            for i in range(0, min(2, len(image))):\n",
    "                image[i] = image[i].resize((scale_w, scale_h))\n",
    "            \n",
    "            # Resize label images with NEAREST neighbor\n",
    "            for i in range(2, len(image)):\n",
    "                image[i] = image[i].resize((scale_w, scale_h), resample=Image.NEAREST)\n",
    "        \n",
    "        if unoverlap is None:\n",
    "            img_h, img_w = np.array(image[0]).shape[:2]\n",
    "            img_center_x = img_w // 2\n",
    "            img_center_y = img_h // 2\n",
    "            \n",
    "            # Calculate crop boundaries\n",
    "            angle_rad = math.radians(angle)\n",
    "            factor = (math.sin(angle_rad) + math.cos(angle_rad)) * scale_times\n",
    "            \n",
    "            crop_w_start_img1 = img_center_x - (source_size[1] * factor) // 2\n",
    "            crop_w_end_img1 = img_center_x + (source_size[1] * factor) // 2 - source_size[1]\n",
    "            crop_h_start_img1 = img_center_y - (source_size[0] * factor) // 2\n",
    "            crop_h_end_img1 = img_center_y + (source_size[0] * factor) // 2 - source_size[0]\n",
    "            \n",
    "            crop_w_range_img1 = (crop_w_start_img1, crop_w_end_img1)\n",
    "            crop_h_range_img1 = (crop_h_start_img1, crop_h_end_img1)\n",
    "            \n",
    "            crop_w_start_x_img1 = int(torch.empty(1).uniform_(min(crop_w_range_img1), max(crop_w_range_img1)).item())\n",
    "            crop_h_start_y_img1 = int(torch.empty(1).uniform_(min(crop_h_range_img1), max(crop_h_range_img1)).item())\n",
    "            \n",
    "            # Crop all images\n",
    "            for each_img in range(len(image)):\n",
    "                image[each_img] = image[each_img].crop((\n",
    "                    crop_w_start_x_img1,\n",
    "                    crop_h_start_y_img1, \n",
    "                    crop_w_start_x_img1 + source_size[1], \n",
    "                    crop_h_start_y_img1 + source_size[0]\n",
    "                ))\n",
    "        else:\n",
    "            # Center crop\n",
    "            img_h, img_w = np.array(image[0]).shape[:2]\n",
    "            img_center_x = img_w // 2\n",
    "            img_center_y = img_h // 2\n",
    "            crop_w_start_x = img_center_x - source_size[1] // 2\n",
    "            crop_h_start_y = img_center_y - source_size[0] // 2\n",
    "            \n",
    "            for each_img in range(len(image)):\n",
    "                image[each_img] = image[each_img].crop((\n",
    "                    crop_w_start_x, \n",
    "                    crop_h_start_y, \n",
    "                    crop_w_start_x + source_size[1], \n",
    "                    crop_h_start_y + source_size[0]\n",
    "                ))\n",
    "        \n",
    "        return image, img_bias_y_rate, img_bias_x_rate\n",
    "\n",
    "def mirrorPadding2D(image):\n",
    "    \"\"\"\n",
    "    Apply mirror padding to a 2D image\n",
    "    \n",
    "    Args:\n",
    "        image: numpy array of shape (h, w, c)\n",
    "    \n",
    "    Returns:\n",
    "        image_mirror_padding: mirror padded image of shape (2*h, 2*w, c)\n",
    "    \"\"\"\n",
    "    h, w, c = image.shape\n",
    "    th, dh = h // 2, h - h // 2\n",
    "    lw, rw = w // 2, w - w // 2\n",
    "    \n",
    "    image_mirror_padding = np.zeros((h * 2, w * 2, c), dtype=np.uint8)\n",
    "    \n",
    "    # Flip operations\n",
    "    image_td = np.flip(image, axis=0)\n",
    "    image_lr = np.flip(image, axis=1)\n",
    "    image_tdlr = np.flip(image, axis=(0, 1))\n",
    "    \n",
    "    # Place original image in center\n",
    "    image_mirror_padding[th:(th + h), lw:(lw + w)] = image\n",
    "    \n",
    "    # Fill corners\n",
    "    image_mirror_padding[0:th, 0:lw] = image_tdlr[dh:, rw:]\n",
    "    image_mirror_padding[0:th, (lw + w):] = image_tdlr[dh:, 0:rw]\n",
    "    image_mirror_padding[(dh + h):, 0:lw] = image_tdlr[0:dh, rw:]\n",
    "    image_mirror_padding[(dh + h):, (lw + w):] = image_tdlr[0:dh, 0:rw]\n",
    "    \n",
    "    # Fill edges\n",
    "    image_mirror_padding[0:th, lw:(lw + w)] = image_td[dh:, :]\n",
    "    image_mirror_padding[(th + h):, lw:(lw + w)] = image_td[0:dh, :]\n",
    "    image_mirror_padding[th:(th + h), 0:lw] = image_lr[:, rw:]\n",
    "    image_mirror_padding[th:(th + h), (lw + w):] = image_lr[:, 0:rw]\n",
    "    \n",
    "    return image_mirror_padding''')\n",
    "\n",
    "print(\"✅ augment.py created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implement augment.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T04:15:15.746301Z",
     "iopub.status.busy": "2025-09-05T04:15:15.745591Z",
     "iopub.status.idle": "2025-09-05T04:15:22.701832Z",
     "shell.execute_reply": "2025-09-05T04:15:22.701316Z",
     "shell.execute_reply.started": "2025-09-05T04:15:15.746276Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "import math\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as tf\n",
    "\n",
    "class Augmentation:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def randomSpaceAugment(self, image, source_size=(256, 256), angle=None, scale=(0.8, 1.25), unoverlap=None):\n",
    "        \"\"\"\n",
    "        Apply random spatial augmentations to a list of images\n",
    "        \n",
    "        Args:\n",
    "            image: List of PIL Images\n",
    "            source_size: Target size (height, width)\n",
    "            angle: Rotation angle (if None, random angle is chosen)\n",
    "            scale: Scale range tuple (min, max)\n",
    "            unoverlap: Overlap parameter (if None, random cropping is applied)\n",
    "        \"\"\"\n",
    "        if angle is None:\n",
    "            angle = transforms.RandomRotation.get_params([-180, 180])\n",
    "        \n",
    "        if isinstance(angle, list):\n",
    "            angle = random.choice(angle)\n",
    "        \n",
    "        # Rotation\n",
    "        for i in range(len(image)):\n",
    "            image[i] = image[i].rotate(angle)\n",
    "        \n",
    "        # Horizontal flip\n",
    "        if random.random() > 0.5:\n",
    "            for i in range(len(image)):\n",
    "                image[i] = tf.hflip(image[i])\n",
    "        \n",
    "        # Vertical flip  \n",
    "        if random.random() > 0.5:\n",
    "            for i in range(len(image)):\n",
    "                image[i] = tf.vflip(image[i])\n",
    "        \n",
    "        img_bias_y_rate = 0.0\n",
    "        img_bias_x_rate = 0.0\n",
    "        scale_times = 1.0\n",
    "        \n",
    "        # Scale resize\n",
    "        if random.random() > 0.25:\n",
    "            img_h, img_w = np.array(image[0]).shape[:2]\n",
    "            scale_times = torch.empty(1).uniform_(scale[0], scale[1]).item()\n",
    "            scale_h, scale_w = int(img_h * scale_times), int(img_w * scale_times)\n",
    "            \n",
    "            # Resize RGB images (first 2) with BICUBIC\n",
    "            for i in range(0, min(2, len(image))):\n",
    "                image[i] = image[i].resize((scale_w, scale_h))\n",
    "            \n",
    "            # Resize label images with NEAREST neighbor\n",
    "            for i in range(2, len(image)):\n",
    "                image[i] = image[i].resize((scale_w, scale_h), resample=Image.NEAREST)\n",
    "        \n",
    "        if unoverlap is None:\n",
    "            img_h, img_w = np.array(image[0]).shape[:2]\n",
    "            img_center_x = img_w // 2\n",
    "            img_center_y = img_h // 2\n",
    "            \n",
    "            # Calculate crop boundaries\n",
    "            angle_rad = math.radians(angle)\n",
    "            factor = (math.sin(angle_rad) + math.cos(angle_rad)) * scale_times\n",
    "            \n",
    "            crop_w_start_img1 = img_center_x - (source_size[1] * factor) // 2\n",
    "            crop_w_end_img1 = img_center_x + (source_size[1] * factor) // 2 - source_size[1]\n",
    "            crop_h_start_img1 = img_center_y - (source_size[0] * factor) // 2\n",
    "            crop_h_end_img1 = img_center_y + (source_size[0] * factor) // 2 - source_size[0]\n",
    "            \n",
    "            crop_w_range_img1 = (crop_w_start_img1, crop_w_end_img1)\n",
    "            crop_h_range_img1 = (crop_h_start_img1, crop_h_end_img1)\n",
    "            \n",
    "            crop_w_start_x_img1 = int(torch.empty(1).uniform_(min(crop_w_range_img1), max(crop_w_range_img1)).item())\n",
    "            crop_h_start_y_img1 = int(torch.empty(1).uniform_(min(crop_h_range_img1), max(crop_h_range_img1)).item())\n",
    "            \n",
    "            # Crop all images\n",
    "            for each_img in range(len(image)):\n",
    "                image[each_img] = image[each_img].crop((\n",
    "                    crop_w_start_x_img1,\n",
    "                    crop_h_start_y_img1, \n",
    "                    crop_w_start_x_img1 + source_size[1], \n",
    "                    crop_h_start_y_img1 + source_size[0]\n",
    "                ))\n",
    "        else:\n",
    "            # Center crop\n",
    "            img_h, img_w = np.array(image[0]).shape[:2]\n",
    "            img_center_x = img_w // 2\n",
    "            img_center_y = img_h // 2\n",
    "            crop_w_start_x = img_center_x - source_size[1] // 2\n",
    "            crop_h_start_y = img_center_y - source_size[0] // 2\n",
    "            \n",
    "            for each_img in range(len(image)):\n",
    "                image[each_img] = image[each_img].crop((\n",
    "                    crop_w_start_x, \n",
    "                    crop_h_start_y, \n",
    "                    crop_w_start_x + source_size[1], \n",
    "                    crop_h_start_y + source_size[0]\n",
    "                ))\n",
    "        \n",
    "        return image, img_bias_y_rate, img_bias_x_rate\n",
    "\n",
    "def mirrorPadding2D(image):\n",
    "    \"\"\"\n",
    "    Apply mirror padding to a 2D image\n",
    "    \n",
    "    Args:\n",
    "        image: numpy array of shape (h, w, c)\n",
    "    \n",
    "    Returns:\n",
    "        image_mirror_padding: mirror padded image of shape (2*h, 2*w, c)\n",
    "    \"\"\"\n",
    "    h, w, c = image.shape\n",
    "    th, dh = h // 2, h - h // 2\n",
    "    lw, rw = w // 2, w - w // 2\n",
    "    \n",
    "    image_mirror_padding = np.zeros((h * 2, w * 2, c), dtype=np.uint8)\n",
    "    \n",
    "    # Flip operations\n",
    "    image_td = np.flip(image, axis=0)\n",
    "    image_lr = np.flip(image, axis=1)\n",
    "    image_tdlr = np.flip(image, axis=(0, 1))\n",
    "    \n",
    "    # Place original image in center\n",
    "    image_mirror_padding[th:(th + h), lw:(lw + w)] = image\n",
    "    \n",
    "    # Fill corners\n",
    "    image_mirror_padding[0:th, 0:lw] = image_tdlr[dh:, rw:]\n",
    "    image_mirror_padding[0:th, (lw + w):] = image_tdlr[dh:, 0:rw]\n",
    "    image_mirror_padding[(dh + h):, 0:lw] = image_tdlr[0:dh, rw:]\n",
    "    image_mirror_padding[(dh + h):, (lw + w):] = image_tdlr[0:dh, 0:rw]\n",
    "    \n",
    "    # Fill edges\n",
    "    image_mirror_padding[0:th, lw:(lw + w)] = image_td[dh:, :]\n",
    "    image_mirror_padding[(th + h):, lw:(lw + w)] = image_td[0:dh, :]\n",
    "    image_mirror_padding[th:(th + h), 0:lw] = image_lr[:, rw:]\n",
    "    image_mirror_padding[th:(th + h), (lw + w):] = image_lr[:, 0:rw]\n",
    "    \n",
    "    return image_mirror_padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T04:15:32.619346Z",
     "iopub.status.busy": "2025-09-05T04:15:32.619028Z",
     "iopub.status.idle": "2025-09-05T04:15:32.636459Z",
     "shell.execute_reply": "2025-09-05T04:15:32.635763Z",
     "shell.execute_reply.started": "2025-09-05T04:15:32.619322Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ slicingPatch.py created!\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Create slicingPatch.py\n",
    "# Copy the slicingPatch.py code here (from the artifact above)\n",
    "with open('/kaggle/working/data_utils/slicingPatch.py', 'w') as f:\n",
    "    f.write('''import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "import numpy as np\n",
    "import socket\n",
    "from PIL import Image\n",
    "import glob\n",
    "import argparse\n",
    "import tqdm\n",
    "import gc\n",
    "import threading\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn.functional as F\n",
    "    GPU_AVAILABLE = torch.cuda.is_available()\n",
    "    if GPU_AVAILABLE:\n",
    "        print(f\"✅ PyTorch GPU available\")\n",
    "        print(f\"🔢 Number of GPUs detected: {torch.cuda.device_count()}\")\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            gpu_name = torch.cuda.get_device_name(i)\n",
    "            gpu_memory = torch.cuda.get_device_properties(i).total_memory / (1024**3)\n",
    "            print(f\"🖥️  GPU {i}: {gpu_name} ({gpu_memory:.1f}GB)\")\n",
    "    else:\n",
    "        print(\"⚠️ PyTorch available but no GPU detected\")\n",
    "except ImportError:\n",
    "    GPU_AVAILABLE = False\n",
    "    print(\"⚠️ PyTorch not available. Install with: pip install torch\")\n",
    "\n",
    "try:\n",
    "    from osgeo import gdal, gdal_array\n",
    "    GDAL_AVAILABLE = True\n",
    "except ImportError:\n",
    "    GDAL_AVAILABLE = False\n",
    "    print(\"Warning: GDAL not available. Only PNG/JPG processing will work.\")\n",
    "\n",
    "# Multi-scale factors for slicing\n",
    "multiScale = [1.0]\n",
    "\n",
    "# T4 optimized settings\n",
    "T4_OPTIMAL_BATCH_SIZE = 32  # Optimized for T4's memory bandwidth\n",
    "T4_MAX_IMAGE_SIZE = 4096    # Maximum image size to process in single GPU operation\n",
    "\n",
    "def setup_gpu_devices():\n",
    "    \"\"\"Setup and configure available GPUs\"\"\"\n",
    "    if not GPU_AVAILABLE:\n",
    "        return []\n",
    "    \n",
    "    devices = []\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        gpu_props = torch.cuda.get_device_properties(i)\n",
    "        \n",
    "        # Get memory info\n",
    "        torch.cuda.set_device(i)\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        total_memory = gpu_props.total_memory / (1024**3)  # GB\n",
    "        allocated_memory = torch.cuda.memory_allocated(i) / (1024**3)  # GB\n",
    "        free_memory = total_memory - allocated_memory\n",
    "        \n",
    "        devices.append({\n",
    "            'id': i,\n",
    "            'name': gpu_props.name,\n",
    "            'free_memory': free_memory,\n",
    "            'total_memory': total_memory,\n",
    "            'compute_capability': f\"{gpu_props.major}.{gpu_props.minor}\"\n",
    "        })\n",
    "        \n",
    "        print(f\"🖥️  GPU {i}: {gpu_props.name}\")\n",
    "        print(f\"   💾 Memory: {free_memory:.1f}GB free / {total_memory:.1f}GB total\")\n",
    "        print(f\"   🔧 Compute Capability: {gpu_props.major}.{gpu_props.minor}\")\n",
    "    \n",
    "    return devices\n",
    "\n",
    "def clear_gpu_memory(device_id=None):\n",
    "    \"\"\"Clear GPU memory to prevent OOM errors\"\"\"\n",
    "    if GPU_AVAILABLE:\n",
    "        if device_id is not None:\n",
    "            torch.cuda.set_device(device_id)\n",
    "            torch.cuda.empty_cache()\n",
    "        else:\n",
    "            # Clear all devices\n",
    "            for i in range(torch.cuda.device_count()):\n",
    "                torch.cuda.set_device(i)\n",
    "                torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "def writeTiff(im_data, path, im_bands, im_height, im_width, im_geotrans, im_proj):\n",
    "    \"\"\"\n",
    "    Write image data to TIFF format\n",
    "    Note: This function requires GDAL which may not be available in Kaggle\n",
    "    \"\"\"\n",
    "    if not GDAL_AVAILABLE:\n",
    "        raise ImportError(\"GDAL is required for TIFF operations but not available\")\n",
    "    \n",
    "    # Convert from GPU to CPU if needed\n",
    "    if GPU_AVAILABLE and torch.is_tensor(im_data):\n",
    "        im_data = im_data.cpu().numpy()\n",
    "    \n",
    "    if 'int8' in im_data.dtype.name:\n",
    "        datatype = gdal.GDT_Byte\n",
    "    elif 'int16' in im_data.dtype.name:\n",
    "        datatype = gdal.GDT_UInt16\n",
    "    elif 'int32' in im_data.dtype.name:\n",
    "        datatype = gdal.GDT_UInt32\n",
    "    else:\n",
    "        datatype = gdal.GDT_Float32\n",
    "    \n",
    "    if len(im_data.shape) == 3:\n",
    "        im_bands, im_height, im_width = im_data.shape\n",
    "    elif len(im_data.shape) == 2:\n",
    "        im_data = np.array([im_data])\n",
    "    else:\n",
    "        im_bands, (im_height, im_width) = 1, im_data.shape\n",
    "    \n",
    "    # Create file\n",
    "    driver = gdal.GetDriverByName(\"GTiff\")\n",
    "    dataset = driver.Create(path, im_width, im_height, 1, datatype)\n",
    "    \n",
    "    if dataset is not None:\n",
    "        dataset.SetGeoTransform(im_geotrans)\n",
    "        dataset.SetProjection(im_proj)\n",
    "        for i in range(im_bands):\n",
    "            dataset.GetRasterBand(i + 1).WriteArray(im_data[i])\n",
    "    del dataset\n",
    "\n",
    "def readTiff(filename):\n",
    "    \"\"\"\n",
    "    Read TIFF image file\n",
    "    Note: This function requires GDAL which may not be available in Kaggle\n",
    "    \"\"\"\n",
    "    if not GDAL_AVAILABLE:\n",
    "        raise ImportError(\"GDAL is required for TIFF operations but not available\")\n",
    "    \n",
    "    img_ds = gdal.Open(filename, gdal.GA_ReadOnly)\n",
    "    im_width = img_ds.RasterXSize\n",
    "    im_height = img_ds.RasterYSize\n",
    "    im_bands = img_ds.RasterCount\n",
    "    im_geotrans = img_ds.GetGeoTransform()\n",
    "    im_proj = img_ds.GetProjection()\n",
    "    \n",
    "    im_data = np.zeros((img_ds.RasterYSize, img_ds.RasterXSize, img_ds.RasterCount), \n",
    "                       gdal_array.GDALTypeCodeToNumericTypeCode(img_ds.GetRasterBand(1).DataType))\n",
    "    \n",
    "    for b in range(im_data.shape[2]):\n",
    "        im_data[:, :, b] = img_ds.GetRasterBand(b + 1).ReadAsArray()\n",
    "    \n",
    "    return im_data, img_ds\n",
    "\n",
    "def torch_resize_image_t4_optimized(img_array, new_size, is_label=False, device_id=0):\n",
    "    \"\"\"\n",
    "    T4-optimized GPU image resize using PyTorch\n",
    "    \n",
    "    Args:\n",
    "        img_array: Input image as numpy array\n",
    "        new_size: (width, height) tuple for new size\n",
    "        is_label: Whether this is a label image (use nearest neighbor)\n",
    "        device_id: GPU device ID to use\n",
    "    \n",
    "    Returns:\n",
    "        Resized image array as numpy\n",
    "    \"\"\"\n",
    "    if not GPU_AVAILABLE:\n",
    "        # CPU fallback using OpenCV\n",
    "        interpolation = cv2.INTER_NEAREST if is_label else cv2.INTER_CUBIC\n",
    "        return cv2.resize(img_array, new_size, interpolation=interpolation)\n",
    "    \n",
    "    try:\n",
    "        device = torch.device(f'cuda:{device_id}')\n",
    "        torch.cuda.set_device(device_id)\n",
    "        \n",
    "        # For very large images, use tiled processing\n",
    "        if max(img_array.shape[:2]) > T4_MAX_IMAGE_SIZE:\n",
    "            return torch_resize_large_image(img_array, new_size, is_label, device_id)\n",
    "        \n",
    "        # Convert numpy to torch tensor\n",
    "        if len(img_array.shape) == 3:\n",
    "            # Convert HWC to NCHW format for PyTorch\n",
    "            img_tensor = torch.from_numpy(img_array).permute(2, 0, 1).unsqueeze(0).float()\n",
    "        else:\n",
    "            # Single channel: HW to NCHW\n",
    "            img_tensor = torch.from_numpy(img_array).unsqueeze(0).unsqueeze(0).float()\n",
    "        \n",
    "        # Transfer to GPU\n",
    "        img_tensor = img_tensor.to(device)\n",
    "        \n",
    "        # Resize using PyTorch\n",
    "        mode = 'nearest' if is_label else 'bicubic'\n",
    "        \n",
    "        # PyTorch expects (N, C, H, W) and size as (H, W)\n",
    "        resized_tensor = F.interpolate(\n",
    "            img_tensor, \n",
    "            size=(new_size[1], new_size[0]),  # PyTorch expects (H, W)\n",
    "            mode=mode,\n",
    "            align_corners=False if mode == 'bicubic' else None\n",
    "        )\n",
    "        \n",
    "        # Convert back to numpy\n",
    "        if len(img_array.shape) == 3:\n",
    "            # Convert NCHW back to HWC\n",
    "            result = resized_tensor.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "        else:\n",
    "            # Convert NCHW back to HW\n",
    "            result = resized_tensor.squeeze(0).squeeze(0).cpu().numpy()\n",
    "        \n",
    "        # Clean up GPU memory\n",
    "        del img_tensor, resized_tensor\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        # Ensure correct data type\n",
    "        if is_label:\n",
    "            result = result.astype(np.uint8)\n",
    "        else:\n",
    "            result = result.astype(img_array.dtype)\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ T4 GPU resize failed on device {device_id}, falling back to CPU: {e}\")\n",
    "        clear_gpu_memory(device_id)\n",
    "        interpolation = cv2.INTER_NEAREST if is_label else cv2.INTER_CUBIC\n",
    "        return cv2.resize(img_array, new_size, interpolation=interpolation)\n",
    "\n",
    "def torch_resize_large_image(img_array, new_size, is_label=False, device_id=0):\n",
    "    \"\"\"\n",
    "    Handle very large images by processing in tiles using PyTorch\n",
    "    \"\"\"\n",
    "    tile_size = T4_MAX_IMAGE_SIZE // 2\n",
    "    overlap = 64\n",
    "    \n",
    "    # Calculate scale factors\n",
    "    scale_h = new_size[1] / img_array.shape[0]\n",
    "    scale_w = new_size[0] / img_array.shape[1]\n",
    "    \n",
    "    # Create output array\n",
    "    if len(img_array.shape) == 3:\n",
    "        output = np.zeros((new_size[1], new_size[0], img_array.shape[2]), dtype=img_array.dtype)\n",
    "    else:\n",
    "        output = np.zeros((new_size[1], new_size[0]), dtype=img_array.dtype)\n",
    "    \n",
    "    for y in range(0, img_array.shape[0], tile_size - overlap):\n",
    "        for x in range(0, img_array.shape[1], tile_size - overlap):\n",
    "            # Extract tile\n",
    "            y_end = min(y + tile_size, img_array.shape[0])\n",
    "            x_end = min(x + tile_size, img_array.shape[1])\n",
    "            tile = img_array[y:y_end, x:x_end]\n",
    "            \n",
    "            # Calculate output coordinates\n",
    "            out_y = int(y * scale_h)\n",
    "            out_x = int(x * scale_w)\n",
    "            out_y_end = int(y_end * scale_h)\n",
    "            out_x_end = int(x_end * scale_w)\n",
    "            \n",
    "            # Resize tile\n",
    "            tile_new_size = (out_x_end - out_x, out_y_end - out_y)\n",
    "            resized_tile = torch_resize_image_t4_optimized(tile, tile_new_size, is_label, device_id)\n",
    "            \n",
    "            # Place in output\n",
    "            if len(img_array.shape) == 3:\n",
    "                output[out_y:out_y_end, out_x:out_x_end, :] = resized_tile\n",
    "            else:\n",
    "                output[out_y:out_y_end, out_x:out_x_end] = resized_tile\n",
    "    \n",
    "    return output\n",
    "\n",
    "def torch_process_patches_dual_t4(img_array, patch_coords, imgsize, is_label=False, batch_size=32):\n",
    "    \"\"\"\n",
    "    Process patches using dual T4 GPUs for maximum performance with PyTorch\n",
    "    \n",
    "    Args:\n",
    "        img_array: Input image array\n",
    "        patch_coords: List of (start_h, end_h, start_w, end_w) coordinates\n",
    "        imgsize: Size of patches\n",
    "        is_label: Whether processing labels\n",
    "        batch_size: Batch size per GPU\n",
    "    \n",
    "    Returns:\n",
    "        List of patch arrays\n",
    "    \"\"\"\n",
    "    if not GPU_AVAILABLE or len(patch_coords) < batch_size:\n",
    "        # Fallback to CPU for small batches\n",
    "        return cpu_process_patches(img_array, patch_coords, is_label)\n",
    "    \n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    \n",
    "    if num_gpus == 1:\n",
    "        return torch_process_patches_single(img_array, patch_coords, imgsize, is_label, 0, batch_size)\n",
    "    \n",
    "    # Dual GPU processing\n",
    "    patches = [None] * len(patch_coords)\n",
    "    \n",
    "    def process_gpu_batch(gpu_id, coords_batch, indices_batch):\n",
    "        try:\n",
    "            device = torch.device(f'cuda:{gpu_id}')\n",
    "            torch.cuda.set_device(gpu_id)\n",
    "            \n",
    "            # Convert image to tensor once per batch\n",
    "            if len(img_array.shape) == 3:\n",
    "                # HWC to CHW\n",
    "                img_tensor = torch.from_numpy(img_array).permute(2, 0, 1).float().to(device)\n",
    "            else:\n",
    "                # HW to CHW (add channel dimension)\n",
    "                img_tensor = torch.from_numpy(img_array).unsqueeze(0).float().to(device)\n",
    "            \n",
    "            for i, (start_h, end_h, start_w, end_w) in enumerate(coords_batch):\n",
    "                if len(img_array.shape) == 3 and not is_label:\n",
    "                    # Multi-channel patch: CHW format\n",
    "                    patch_tensor = img_tensor[:, start_h:end_h, start_w:end_w]\n",
    "                    # Convert back to HWC for saving\n",
    "                    cpu_patch = patch_tensor.permute(1, 2, 0).cpu().numpy()\n",
    "                else:\n",
    "                    # Single channel patch\n",
    "                    if len(img_array.shape) == 3:\n",
    "                        # Take first channel for labels\n",
    "                        patch_tensor = img_tensor[0, start_h:end_h, start_w:end_w]\n",
    "                    else:\n",
    "                        patch_tensor = img_tensor[0, start_h:end_h, start_w:end_w]\n",
    "                    cpu_patch = patch_tensor.cpu().numpy()\n",
    "                \n",
    "                # Ensure correct data type\n",
    "                if is_label:\n",
    "                    cpu_patch = cpu_patch.astype(np.uint8)\n",
    "                else:\n",
    "                    cpu_patch = cpu_patch.astype(img_array.dtype)\n",
    "                \n",
    "                patches[indices_batch[i]] = cpu_patch\n",
    "            \n",
    "            # Clean up GPU memory\n",
    "            del img_tensor\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ GPU {gpu_id} batch processing failed: {e}\")\n",
    "            # Fallback to CPU for this batch\n",
    "            for i, (start_h, end_h, start_w, end_w) in enumerate(coords_batch):\n",
    "                if len(img_array.shape) == 3 and not is_label:\n",
    "                    patch = img_array[start_h:end_h, start_w:end_w, :]\n",
    "                else:\n",
    "                    patch = img_array[start_h:end_h, start_w:end_w]\n",
    "                patches[indices_batch[i]] = patch\n",
    "    \n",
    "    # Split work between GPUs\n",
    "    total_batches = len(patch_coords)\n",
    "    batches_per_gpu = total_batches // num_gpus\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=num_gpus) as executor:\n",
    "        futures = []\n",
    "        \n",
    "        for gpu_id in range(num_gpus):\n",
    "            start_idx = gpu_id * batches_per_gpu\n",
    "            if gpu_id == num_gpus - 1:  # Last GPU gets remaining work\n",
    "                end_idx = total_batches\n",
    "            else:\n",
    "                end_idx = start_idx + batches_per_gpu\n",
    "            \n",
    "            coords_batch = patch_coords[start_idx:end_idx]\n",
    "            indices_batch = list(range(start_idx, end_idx))\n",
    "            \n",
    "            future = executor.submit(process_gpu_batch, gpu_id, coords_batch, indices_batch)\n",
    "            futures.append(future)\n",
    "        \n",
    "        # Wait for all GPUs to complete\n",
    "        for future in as_completed(futures):\n",
    "            future.result()\n",
    "    \n",
    "    return [p for p in patches if p is not None]\n",
    "\n",
    "def torch_process_patches_single(img_array, patch_coords, imgsize, is_label, device_id, batch_size):\n",
    "    \"\"\"Process patches on a single GPU using PyTorch\"\"\"\n",
    "    try:\n",
    "        device = torch.device(f'cuda:{device_id}')\n",
    "        torch.cuda.set_device(device_id)\n",
    "        \n",
    "        # Convert image to tensor\n",
    "        if len(img_array.shape) == 3:\n",
    "            img_tensor = torch.from_numpy(img_array).permute(2, 0, 1).float().to(device)\n",
    "        else:\n",
    "            img_tensor = torch.from_numpy(img_array).unsqueeze(0).float().to(device)\n",
    "        \n",
    "        patches = []\n",
    "        \n",
    "        for start_h, end_h, start_w, end_w in patch_coords:\n",
    "            if len(img_array.shape) == 3 and not is_label:\n",
    "                patch_tensor = img_tensor[:, start_h:end_h, start_w:end_w]\n",
    "                cpu_patch = patch_tensor.permute(1, 2, 0).cpu().numpy()\n",
    "            else:\n",
    "                if len(img_array.shape) == 3:\n",
    "                    patch_tensor = img_tensor[0, start_h:end_h, start_w:end_w]\n",
    "                else:\n",
    "                    patch_tensor = img_tensor[0, start_h:end_h, start_w:end_w]\n",
    "                cpu_patch = patch_tensor.cpu().numpy()\n",
    "            \n",
    "            if is_label:\n",
    "                cpu_patch = cpu_patch.astype(np.uint8)\n",
    "            else:\n",
    "                cpu_patch = cpu_patch.astype(img_array.dtype)\n",
    "            \n",
    "            patches.append(cpu_patch)\n",
    "        \n",
    "        # Clean up\n",
    "        del img_tensor\n",
    "        return patches\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Single GPU processing failed: {e}\")\n",
    "        return cpu_process_patches(img_array, patch_coords, is_label)\n",
    "\n",
    "def cpu_process_patches(img_array, patch_coords, is_label):\n",
    "    \"\"\"CPU fallback for patch processing\"\"\"\n",
    "    patches = []\n",
    "    for start_h, end_h, start_w, end_w in patch_coords:\n",
    "        if len(img_array.shape) == 3 and not is_label:\n",
    "            patch = img_array[start_h:end_h, start_w:end_w, :]\n",
    "        else:\n",
    "            patch = img_array[start_h:end_h, start_w:end_w]\n",
    "        patches.append(patch)\n",
    "    return patches\n",
    "\n",
    "def getAxisBoundary(Index, length, imgsize, totalNums):\n",
    "    \"\"\"\n",
    "    Calculate boundary indices for slicing\n",
    "    \n",
    "    Args:\n",
    "        Index: Current index\n",
    "        length: Total length of the dimension\n",
    "        imgsize: Size of each slice\n",
    "        totalNums: Total number of slices\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (start, end) indices\n",
    "    \"\"\"\n",
    "    if (Index + 1 == totalNums) and (length % imgsize != 0):\n",
    "        start = length - imgsize\n",
    "        end = length\n",
    "    else:\n",
    "        start = Index * imgsize\n",
    "        end = (Index + 1) * imgsize\n",
    "    return start, end\n",
    "\n",
    "def slicingSingleImg(imgDir, outputDir, imgsize=512, scales=[1.0], isLabel=False, batch_size=T4_OPTIMAL_BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    Slice a single large image into smaller patches using dual T4 GPU acceleration with PyTorch\n",
    "    \n",
    "    Args:\n",
    "        imgDir: Path to input image\n",
    "        outputDir: Path to output directory\n",
    "        imgsize: Size of output patches\n",
    "        scales: List of scale factors\n",
    "        isLabel: Whether the image is a label/mask\n",
    "        batch_size: Number of patches to process in GPU batch (optimized for T4)\n",
    "    \"\"\"\n",
    "    path, name = os.path.split(imgDir)\n",
    "    subpath, datasetName = os.path.split(path)\n",
    "    _, datasetName = os.path.split(subpath)\n",
    "    filename, extension = os.path.splitext(name)\n",
    "    outputPath = os.path.join(outputDir, f\"{datasetName}_{filename}\")\n",
    "    \n",
    "    save_extension = \".png\"\n",
    "    \n",
    "    try:\n",
    "        if extension.lower() in [\".png\", \".jpg\", \".jpeg\", \".bmp\"]:\n",
    "            sourceImg = Image.open(imgDir)\n",
    "        elif extension.lower() in [\".tiff\", \".tif\"] and GDAL_AVAILABLE:\n",
    "            sourceImg, img_ds1 = readTiff(imgDir)\n",
    "            sourceImg = Image.fromarray(sourceImg) if len(sourceImg.shape) == 3 else Image.fromarray(sourceImg.squeeze(axis=2))\n",
    "        else:\n",
    "            print(f\"⚠️ Skipping unsupported format: {extension}\")\n",
    "            return\n",
    "        \n",
    "        sourceW, sourceH = sourceImg.size[0], sourceImg.size[1]\n",
    "        sourceC = len(sourceImg.getbands())\n",
    "        \n",
    "        for singleScale in scales:\n",
    "            # Convert PIL to numpy for GPU processing\n",
    "            img_array = np.array(sourceImg)\n",
    "            \n",
    "            # Determine optimal GPU for this operation\n",
    "            device_id = 0\n",
    "            if GPU_AVAILABLE and torch.cuda.device_count() > 1:\n",
    "                # Simple load balancing - use GPU with more free memory\n",
    "                device_id = 0\n",
    "            \n",
    "            # GPU-accelerated resize optimized for T4 with PyTorch\n",
    "            new_size = (int(sourceW * singleScale), int(sourceH * singleScale))\n",
    "            img = torch_resize_image_t4_optimized(img_array, new_size, isLabel, device_id)\n",
    "            \n",
    "            # Process labels on GPU if available\n",
    "            if isLabel:\n",
    "                if GPU_AVAILABLE:\n",
    "                    try:\n",
    "                        device = torch.device(f'cuda:{device_id}')\n",
    "                        torch.cuda.set_device(device_id)\n",
    "                        \n",
    "                        # Convert to tensor\n",
    "                        if len(img.shape) == 3:\n",
    "                            img_tensor = torch.from_numpy(img).to(device)\n",
    "                        else:\n",
    "                            img_tensor = torch.from_numpy(img).to(device)\n",
    "                        \n",
    "                        # Binary thresholding\n",
    "                        img_tensor = torch.where(img_tensor != 0, 255, img_tensor).to(torch.uint8)\n",
    "                        \n",
    "                        # Convert RGB label to binary if needed\n",
    "                        if sourceC != 1 and len(img_tensor.shape) == 3:\n",
    "                            img_tensor = torch.max(img_tensor, dim=2)[0]\n",
    "                        \n",
    "                        img = img_tensor.cpu().numpy()\n",
    "                        \n",
    "                        # Clean up\n",
    "                        del img_tensor\n",
    "                        torch.cuda.empty_cache()\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"⚠️ GPU label processing failed, using CPU: {e}\")\n",
    "                        img[img != 0] = 255\n",
    "                        img = img.astype(np.uint8)\n",
    "                        if sourceC != 1 and len(img.shape) == 3:\n",
    "                            img = img.max(axis=2)\n",
    "                else:\n",
    "                    img[img != 0] = 255\n",
    "                    img = img.astype(np.uint8)\n",
    "                    if sourceC != 1 and len(img.shape) == 3:\n",
    "                        img = img.max(axis=2)\n",
    "            \n",
    "            img_h, img_w = img.shape[0], img.shape[1]\n",
    "            h_nums, w_nums = img.shape[0] // imgsize, img.shape[1] // imgsize\n",
    "            \n",
    "            if img_h % imgsize != 0:\n",
    "                h_nums = h_nums + 1\n",
    "            if img_w % imgsize != 0:\n",
    "                w_nums = w_nums + 1\n",
    "            \n",
    "            if img_h < imgsize or img_w < imgsize:\n",
    "                continue\n",
    "            \n",
    "            print(f\"⚡ PyTorch T4 Processing scale {singleScale}: {h_nums}x{w_nums} patches\")\n",
    "            \n",
    "            # Collect patch coordinates for batch processing\n",
    "            patch_coords = []\n",
    "            patch_filenames = []\n",
    "            \n",
    "            for hIndex in range(h_nums):\n",
    "                start_h, end_h = getAxisBoundary(hIndex, img_h, imgsize, h_nums)\n",
    "                \n",
    "                for wIndex in range(w_nums):\n",
    "                    start_w, end_w = getAxisBoundary(wIndex, img_w, imgsize, w_nums)\n",
    "                    \n",
    "                    outputPathTemp = (f\"{outputPath}_scale-{singleScale}_y-{start_h}\"\n",
    "                                    f\"_x-{start_w}_imgsize-{imgsize}{save_extension}\")\n",
    "                    \n",
    "                    if not os.path.exists(outputPathTemp):\n",
    "                        patch_coords.append((start_h, end_h, start_w, end_w))\n",
    "                        patch_filenames.append(outputPathTemp)\n",
    "            \n",
    "            # Process patches with dual T4 optimization using PyTorch\n",
    "            total_patches = len(patch_coords)\n",
    "            if total_patches == 0:\n",
    "                continue\n",
    "                \n",
    "            print(f\"🚀 PyTorch T4 Dual-GPU processing {total_patches} patches...\")\n",
    "            \n",
    "            # Process all patches at once with dual GPU\n",
    "            patches = torch_process_patches_dual_t4(img, patch_coords, imgsize, isLabel, batch_size)\n",
    "            \n",
    "            # Save patches\n",
    "            print(f\"💾 Saving {len(patches)} patches...\")\n",
    "            for patch, filename in zip(patches, patch_filenames):\n",
    "                temp_img = Image.fromarray(patch)\n",
    "                temp_img.save(filename)\n",
    "            \n",
    "            # Clear GPU memory after processing\n",
    "            clear_gpu_memory()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {imgDir}: {str(e)}\")\n",
    "        clear_gpu_memory()\n",
    "\n",
    "def process_levir_dataset(input_path, output_path, imgsize=256, batch_size=T4_OPTIMAL_BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    Process the entire LEVIR-CD dataset with dual T4 GPU acceleration using PyTorch\n",
    "    \n",
    "    Args:\n",
    "        input_path: Path to input dataset\n",
    "        output_path: Path to output directory\n",
    "        imgsize: Size of output patches\n",
    "        batch_size: GPU batch size optimized for T4\n",
    "    \"\"\"\n",
    "    # Setup GPUs\n",
    "    gpu_devices = setup_gpu_devices()\n",
    "    \n",
    "    splits = ['train', 'val', 'test']\n",
    "    image_types = ['T1', 'T2', 'label']\n",
    "    \n",
    "    print(f\"🚀 Starting PyTorch T4 Dual-GPU accelerated processing...\")\n",
    "    print(f\"🎯 Detected {len(gpu_devices)} GPU(s)\")\n",
    "    print(f\"📦 T4-Optimized Batch Size: {batch_size}\")\n",
    "    print(f\"🔧 Image Size: {imgsize}\")\n",
    "    \n",
    "    for split in splits:\n",
    "        print(f\"\\n📁 Processing {split} split...\")\n",
    "        \n",
    "        for img_type in image_types:\n",
    "            input_dir = os.path.join(input_path, split, img_type)\n",
    "            output_dir = os.path.join(output_path, split, img_type)\n",
    "            \n",
    "            if not os.path.exists(input_dir):\n",
    "                print(f\"⚠️  Input directory not found: {input_dir}\")\n",
    "                continue\n",
    "            \n",
    "            if not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir, exist_ok=True)\n",
    "            \n",
    "            # Get all files in input directory\n",
    "            fileList = glob.glob(os.path.join(input_dir, \"*\"))\n",
    "            \n",
    "            if not fileList:\n",
    "                print(f\"⚠️  No files found in {input_dir}\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"🖼️  Processing {img_type}: {len(fileList)} files\")\n",
    "            \n",
    "            isLabel = (img_type == 'label')\n",
    "            count = 0\n",
    "            \n",
    "            for singleImg in tqdm.tqdm(fileList, desc=f\"PyTorch T4 Processing {img_type}\"):\n",
    "                count += 1\n",
    "                slicingSingleImg(\n",
    "                    singleImg, \n",
    "                    output_dir, \n",
    "                    scales=multiScale, \n",
    "                    imgsize=imgsize, \n",
    "                    isLabel=isLabel,\n",
    "                    batch_size=batch_size\n",
    "                )\n",
    "                \n",
    "                # Clear memory every few files to prevent accumulation\n",
    "                if count % 3 == 0:\n",
    "                    clear_gpu_memory()\n",
    "            \n",
    "            print(f\"✅ Completed {img_type}: {count}/{len(fileList)} files processed\")\n",
    "            clear_gpu_memory()  # Clear memory after each type\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function for command line usage\"\"\"\n",
    "    parser = argparse.ArgumentParser(description='PyTorch T4 Dual-GPU accelerated image slicing for change detection')\n",
    "    parser.add_argument(\"-i\", \"--input_dir\", \n",
    "                       default=\"/kaggle/input/processed-levir-cd-dataset/LEVIR-CD+_256\", \n",
    "                       type=str, help=\"Path to input dataset directory\")\n",
    "    parser.add_argument(\"-o\", \"--output_dir\", \n",
    "                       default=\"/kaggle/working/processed_data\", \n",
    "                       type=str, help=\"Path to output directory\")\n",
    "    parser.add_argument(\"-is\", \"--img_size\", default=256, type=int, help=\"Output patch size\")\n",
    "    parser.add_argument(\"-bs\", \"--batch_size\", default=T4_OPTIMAL_BATCH_SIZE, type=int, \n",
    "                       help=f\"GPU batch size (T4 optimized default: {T4_OPTIMAL_BATCH_SIZE})\")\n",
    "    parser.add_argument(\"-ol\", \"--overlap_size\", default=512, type=int, help=\"Overlap size (not implemented)\")\n",
    "    parser.add_argument('-c', \"--multi_scale_slicing\", action='store_true', default=False)\n",
    "\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    \n",
    "    if args.output_dir is None:\n",
    "        print(\"❌ Error: No output directory specified!\")\n",
    "        exit(0)\n",
    "    \n",
    "    if not os.path.exists(args.output_dir):\n",
    "        os.makedirs(args.output_dir)\n",
    "    \n",
    "    # T4-specific optimizations\n",
    "    if not GPU_AVAILABLE:\n",
    "        print(\"⚠️  Warning: GPU not available, running on CPU\")\n",
    "        args.batch_size = 1\n",
    "    else:\n",
    "        print(f\"⚡ Using PyTorch with T4 GPU(s), optimized batch size: {args.batch_size}\")\n",
    "        \n",
    "        # Adjust batch size based on image size for T4's memory\n",
    "        if args.img_size > 512:\n",
    "            args.batch_size = max(8, args.batch_size // 2)\n",
    "            print(f\"🔧 Adjusted batch size for large images: {args.batch_size}\")\n",
    "    \n",
    "    # Process dataset with PyTorch T4 optimizations\n",
    "    process_levir_dataset(args.input_dir, args.output_dir, args.img_size, args.batch_size)\n",
    "    \n",
    "    print(\"🎉 PyTorch T4 processing completed successfully!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()''')\n",
    "\n",
    "print(\"✅ slicingPatch.py created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Don't use the given below slicingPatch.py since it takes lot of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# slicingPatch.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "import numpy as np\n",
    "import socket\n",
    "from PIL import Image\n",
    "import glob\n",
    "import argparse\n",
    "import tqdm\n",
    "\n",
    "try:\n",
    "    from osgeo import gdal, gdal_array\n",
    "    GDAL_AVAILABLE = True\n",
    "except ImportError:\n",
    "    GDAL_AVAILABLE = False\n",
    "    print(\"Warning: GDAL not available. Only PNG/JPG processing will work.\")\n",
    "\n",
    "# Multi-scale factors for slicing\n",
    "multiScale = [1.0]\n",
    "\n",
    "def writeTiff(im_data, path, im_bands, im_height, im_width, im_geotrans, im_proj):\n",
    "    \"\"\"\n",
    "    Write image data to TIFF format\n",
    "    Note: This function requires GDAL which may not be available in Kaggle\n",
    "    \"\"\"\n",
    "    if not GDAL_AVAILABLE:\n",
    "        raise ImportError(\"GDAL is required for TIFF operations but not available\")\n",
    "    \n",
    "    if 'int8' in im_data.dtype.name:\n",
    "        datatype = gdal.GDT_Byte\n",
    "    elif 'int16' in im_data.dtype.name:\n",
    "        datatype = gdal.GDT_UInt16\n",
    "    elif 'int32' in im_data.dtype.name:\n",
    "        datatype = gdal.GDT_UInt32\n",
    "    else:\n",
    "        datatype = gdal.GDT_Float32\n",
    "    \n",
    "    if len(im_data.shape) == 3:\n",
    "        im_bands, im_height, im_width = im_data.shape\n",
    "    elif len(im_data.shape) == 2:\n",
    "        im_data = np.array([im_data])\n",
    "    else:\n",
    "        im_bands, (im_height, im_width) = 1, im_data.shape\n",
    "    \n",
    "    # Create file\n",
    "    driver = gdal.GetDriverByName(\"GTiff\")\n",
    "    dataset = driver.Create(path, im_width, im_height, 1, datatype)\n",
    "    \n",
    "    if dataset is not None:\n",
    "        dataset.SetGeoTransform(im_geotrans)  # Write affine transform parameters\n",
    "        dataset.SetProjection(im_proj)  # Write projection\n",
    "        for i in range(im_bands):\n",
    "            dataset.GetRasterBand(i + 1).WriteArray(im_data[i])\n",
    "    del dataset\n",
    "\n",
    "def readTiff(filename):\n",
    "    \"\"\"\n",
    "    Read TIFF image file\n",
    "    Note: This function requires GDAL which may not be available in Kaggle\n",
    "    \"\"\"\n",
    "    if not GDAL_AVAILABLE:\n",
    "        raise ImportError(\"GDAL is required for TIFF operations but not available\")\n",
    "    \n",
    "    img_ds = gdal.Open(filename, gdal.GA_ReadOnly)\n",
    "    im_width = img_ds.RasterXSize  # Number of columns\n",
    "    im_height = img_ds.RasterYSize  # Number of rows\n",
    "    im_bands = img_ds.RasterCount  # Number of bands\n",
    "    im_geotrans = img_ds.GetGeoTransform()  # Affine transformation\n",
    "    im_proj = img_ds.GetProjection()  # Map projection info\n",
    "    \n",
    "    im_data = np.zeros((img_ds.RasterYSize, img_ds.RasterXSize, img_ds.RasterCount), \n",
    "                       gdal_array.GDALTypeCodeToNumericTypeCode(img_ds.GetRasterBand(1).DataType))\n",
    "    \n",
    "    for b in range(im_data.shape[2]):\n",
    "        im_data[:, :, b] = img_ds.GetRasterBand(b + 1).ReadAsArray()\n",
    "    \n",
    "    return im_data, img_ds\n",
    "\n",
    "def getAxisBoundary(Index, length, imgsize, totalNums):\n",
    "    \"\"\"\n",
    "    Calculate boundary indices for slicing\n",
    "    \n",
    "    Args:\n",
    "        Index: Current index\n",
    "        length: Total length of the dimension\n",
    "        imgsize: Size of each slice\n",
    "        totalNums: Total number of slices\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (start, end) indices\n",
    "    \"\"\"\n",
    "    if (Index + 1 == totalNums) and (length % imgsize != 0):\n",
    "        start = length - imgsize\n",
    "        end = length\n",
    "    else:\n",
    "        start = Index * imgsize\n",
    "        end = (Index + 1) * imgsize\n",
    "    return start, end\n",
    "\n",
    "def slicingSingleImg(imgDir, outputDir, imgsize=512, scales=[1.0], isLabel=False):\n",
    "    \"\"\"\n",
    "    Slice a single large image into smaller patches\n",
    "    \n",
    "    Args:\n",
    "        imgDir: Path to input image\n",
    "        outputDir: Path to output directory\n",
    "        imgsize: Size of output patches\n",
    "        scales: List of scale factors\n",
    "        isLabel: Whether the image is a label/mask\n",
    "    \"\"\"\n",
    "    path, name = os.path.split(imgDir)\n",
    "    subpath, datasetName = os.path.split(path)\n",
    "    _, datasetName = os.path.split(subpath)\n",
    "    filename, extension = os.path.splitext(name)\n",
    "    outputPath = os.path.join(outputDir, f\"{datasetName}_{filename}\")\n",
    "    \n",
    "    save_extension = \".png\"\n",
    "    \n",
    "    try:\n",
    "        if extension.lower() in [\".png\", \".jpg\", \".jpeg\", \".bmp\"]:\n",
    "            sourceImg = Image.open(imgDir)\n",
    "        elif extension.lower() in [\".tiff\", \".tif\"] and GDAL_AVAILABLE:\n",
    "            sourceImg, img_ds1 = readTiff(imgDir)\n",
    "            sourceImg = Image.fromarray(sourceImg) if sourceImg.shape[2] != 1 else Image.fromarray(sourceImg.squeeze(axis=2))\n",
    "        else:\n",
    "            print(f\"Skipping unsupported format: {extension}\")\n",
    "            return\n",
    "        \n",
    "        sourceW, sourceH = sourceImg.size[0], sourceImg.size[1]\n",
    "        sourceC = len(sourceImg.getbands())\n",
    "        \n",
    "        for singleScale in scales:\n",
    "            # Determine resampling method based on image type\n",
    "            resample = Image.NEAREST if isLabel else Image.BICUBIC\n",
    "            img = sourceImg.resize((int(sourceW * singleScale), int(sourceH * singleScale)), resample=resample)\n",
    "            img = np.array(img)\n",
    "            \n",
    "            # Process labels\n",
    "            if isLabel:\n",
    "                img[img != 0] = 255\n",
    "                img = img.astype(np.uint8)\n",
    "                \n",
    "                # Convert RGB label to binary if needed\n",
    "                if sourceC != 1 and isLabel:\n",
    "                    img = img.max(axis=2)\n",
    "            \n",
    "            img_h, img_w = img.shape[0], img.shape[1]\n",
    "            h_nums, w_nums = img.shape[0] // imgsize, img.shape[1] // imgsize\n",
    "            \n",
    "            if img_h % imgsize != 0:\n",
    "                h_nums = h_nums + 1\n",
    "            if img_w % imgsize != 0:\n",
    "                w_nums = w_nums + 1\n",
    "            \n",
    "            if img_h < imgsize or img_w < imgsize:\n",
    "                continue\n",
    "            \n",
    "            print(f\"Processing scale {singleScale}: {h_nums}x{w_nums} patches\")\n",
    "            \n",
    "            for hIndex in tqdm.tqdm(range(h_nums), desc=f\"Processing {filename}\"):\n",
    "                start_h, end_h = getAxisBoundary(hIndex, img_h, imgsize, h_nums)\n",
    "                \n",
    "                for wIndex in range(w_nums):\n",
    "                    start_w, end_w = getAxisBoundary(wIndex, img_w, imgsize, w_nums)\n",
    "                    \n",
    "                    # Generate output filename\n",
    "                    outputPathTemp = (f\"{outputPath}_scale-{singleScale}_y-{start_h}\"\n",
    "                                    f\"_x-{start_w}_imgsize-{imgsize}{save_extension}\")\n",
    "                    \n",
    "                    if os.path.exists(outputPathTemp):\n",
    "                        continue\n",
    "                    \n",
    "                    # Extract patch\n",
    "                    if sourceC != 1 and not isLabel:\n",
    "                        temp_img = img[start_h:end_h, start_w:end_w, :]\n",
    "                    else:\n",
    "                        temp_img = img[start_h:end_h, start_w:end_w]\n",
    "                    \n",
    "                    # Save patch\n",
    "                    temp_img = Image.fromarray(temp_img)\n",
    "                    temp_img.save(outputPathTemp)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {imgDir}: {str(e)}\")\n",
    "\n",
    "def process_levir_dataset(input_path, output_path, imgsize=256):\n",
    "    \"\"\"\n",
    "    Process the entire LEVIR-CD dataset\n",
    "    \n",
    "    Args:\n",
    "        input_path: Path to input dataset (/kaggle/input/processed-levir-cd-dataset/LEVIR-CD+_256)\n",
    "        output_path: Path to output directory (/kaggle/working/processed_data)\n",
    "        imgsize: Size of output patches\n",
    "    \"\"\"\n",
    "    splits = ['train', 'val', 'test']\n",
    "    image_types = ['T1', 'T2', 'label']\n",
    "    \n",
    "    for split in splits:\n",
    "        print(f\"\\n🔄 Processing {split} split...\")\n",
    "        \n",
    "        for img_type in image_types:\n",
    "            input_dir = os.path.join(input_path, split, img_type)\n",
    "            output_dir = os.path.join(output_path, split, img_type)\n",
    "            \n",
    "            if not os.path.exists(input_dir):\n",
    "                print(f\"⚠️  Input directory not found: {input_dir}\")\n",
    "                continue\n",
    "            \n",
    "            if not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir, exist_ok=True)\n",
    "            \n",
    "            # Get all files in input directory\n",
    "            fileList = glob.glob(os.path.join(input_dir, \"*\"))\n",
    "            \n",
    "            if not fileList:\n",
    "                print(f\"⚠️  No files found in {input_dir}\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"📁 Processing {img_type}: {len(fileList)} files\")\n",
    "            \n",
    "            isLabel = (img_type == 'label')\n",
    "            count = 0\n",
    "            \n",
    "            for singleImg in fileList:\n",
    "                count += 1\n",
    "                slicingSingleImg(\n",
    "                    singleImg, \n",
    "                    output_dir, \n",
    "                    scales=multiScale, \n",
    "                    imgsize=imgsize, \n",
    "                    isLabel=isLabel\n",
    "                )\n",
    "                \n",
    "                if count % 10 == 0:  # Progress update every 10 files\n",
    "                    print(f\"    Processed {count}/{len(fileList)} files\")\n",
    "            \n",
    "            print(f\"✅ Completed {img_type}: {count}/{len(fileList)} files processed\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function for command line usage\"\"\"\n",
    "    parser = argparse.ArgumentParser(description='Slice large images into smaller patches for change detection')\n",
    "    parser.add_argument(\"-i\", \"--input_dir\", \n",
    "                       default=\"/kaggle/input/processed-levir-cd-dataset/LEVIR-CD+_256\", \n",
    "                       type=str, help=\"Path to input dataset directory\")\n",
    "    parser.add_argument(\"-o\", \"--output_dir\", \n",
    "                       default=\"/kaggle/working/processed_data\", \n",
    "                       type=str, help=\"Path to output directory\")\n",
    "    parser.add_argument(\"-is\", \"--img_size\", default=256, type=int, help=\"Output patch size\")\n",
    "    parser.add_argument(\"-ol\", \"--overlap_size\", default=512, type=int, help=\"Overlap size (not implemented)\")\n",
    "    parser.add_argument('-c', \"--multi_scale_slicing\", action='store_true', default=False)\n",
    "\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    \n",
    "    if args.output_dir is None:\n",
    "        print(\"Error: No output directory specified!\")\n",
    "        exit(0)\n",
    "    \n",
    "    if not os.path.exists(args.output_dir):\n",
    "        os.makedirs(args.output_dir)\n",
    "    \n",
    "    # Always process full dataset\n",
    "    process_levir_dataset(args.input_dir, args.output_dir, args.img_size)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T06:07:50.450521Z",
     "iopub.status.busy": "2025-09-04T06:07:50.449859Z",
     "iopub.status.idle": "2025-09-04T06:07:56.799623Z",
     "shell.execute_reply": "2025-09-04T06:07:56.799020Z",
     "shell.execute_reply.started": "2025-09-04T06:07:50.450498Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0+cu124\n",
      "CUDA available: True\n",
      "GPU count: 2\n",
      "GPU 0: Tesla T4\n",
      "GPU 1: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Check GPU availability\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the given below slicingPatch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-09-05T04:15:39.105926Z",
     "iopub.status.busy": "2025-09-05T04:15:39.105637Z",
     "iopub.status.idle": "2025-09-05T04:22:59.125753Z",
     "shell.execute_reply": "2025-09-05T04:22:59.125091Z",
     "shell.execute_reply.started": "2025-09-05T04:15:39.105903Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PyTorch GPU available\n",
      "🔢 Number of GPUs detected: 2\n",
      "🖥️  GPU 0: Tesla T4 (14.7GB)\n",
      "🖥️  GPU 1: Tesla T4 (14.7GB)\n",
      "⚡ Using PyTorch with T4 GPU(s), optimized batch size: 32\n",
      "🖥️  GPU 0: Tesla T4\n",
      "   💾 Memory: 14.7GB free / 14.7GB total\n",
      "   🔧 Compute Capability: 7.5\n",
      "🖥️  GPU 1: Tesla T4\n",
      "   💾 Memory: 14.7GB free / 14.7GB total\n",
      "   🔧 Compute Capability: 7.5\n",
      "🚀 Starting PyTorch T4 Dual-GPU accelerated processing...\n",
      "🎯 Detected 2 GPU(s)\n",
      "📦 T4-Optimized Batch Size: 32\n",
      "🔧 Image Size: 256\n",
      "\n",
      "📁 Processing train split...\n",
      "🖼️  Processing T1: 510 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   0%|          | 1/510 [00:00<02:45,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   1%|          | 3/510 [00:00<01:45,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   1%|          | 4/510 [00:00<01:28,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   1%|          | 5/510 [00:00<01:19,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   1%|▏         | 7/510 [00:01<01:22,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   2%|▏         | 8/510 [00:01<01:15,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   2%|▏         | 10/510 [00:01<01:20,  6.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   2%|▏         | 11/510 [00:01<01:17,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   3%|▎         | 13/510 [00:02<01:18,  6.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   3%|▎         | 14/510 [00:02<01:12,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   3%|▎         | 16/510 [00:02<01:15,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   3%|▎         | 17/510 [00:02<01:10,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   4%|▎         | 19/510 [00:03<01:14,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   4%|▍         | 20/510 [00:03<01:09,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   4%|▍         | 22/510 [00:03<01:14,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   5%|▍         | 23/510 [00:03<01:10,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   5%|▍         | 25/510 [00:04<01:18,  6.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   5%|▌         | 26/510 [00:04<01:14,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   5%|▌         | 28/510 [00:04<01:19,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   6%|▌         | 29/510 [00:04<01:15,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   6%|▌         | 31/510 [00:05<01:17,  6.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   6%|▋         | 32/510 [00:05<01:14,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   7%|▋         | 34/510 [00:05<01:15,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   7%|▋         | 35/510 [00:05<01:10,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   7%|▋         | 37/510 [00:06<01:12,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   7%|▋         | 38/510 [00:06<01:08,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   8%|▊         | 40/510 [00:06<01:11,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   8%|▊         | 41/510 [00:06<01:06,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   8%|▊         | 43/510 [00:06<01:10,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   9%|▉         | 45/510 [00:07<01:14,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   9%|▉         | 46/510 [00:07<01:09,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   9%|▉         | 48/510 [00:07<01:14,  6.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  10%|▉         | 49/510 [00:07<01:10,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  10%|▉         | 50/510 [00:07<01:06,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  10%|█         | 52/510 [00:08<01:09,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  10%|█         | 53/510 [00:08<01:05,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  11%|█         | 55/510 [00:08<01:08,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  11%|█         | 56/510 [00:08<01:05,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  11%|█▏        | 58/510 [00:09<01:08,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  12%|█▏        | 60/510 [00:09<01:12,  6.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  12%|█▏        | 61/510 [00:09<01:07,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  12%|█▏        | 62/510 [00:09<01:03,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  13%|█▎        | 64/510 [00:10<01:11,  6.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  13%|█▎        | 65/510 [00:10<01:06,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  13%|█▎        | 67/510 [00:10<01:09,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  13%|█▎        | 68/510 [00:10<01:05,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  14%|█▎        | 70/510 [00:11<01:09,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  14%|█▍        | 71/510 [00:11<01:04,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  14%|█▍        | 73/510 [00:11<01:07,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  15%|█▍        | 74/510 [00:11<01:03,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  15%|█▍        | 76/510 [00:12<01:07,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  15%|█▌        | 77/510 [00:12<01:03,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  15%|█▌        | 79/510 [00:12<01:06,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  16%|█▌        | 80/510 [00:12<01:02,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  16%|█▌        | 82/510 [00:13<01:06,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  16%|█▋        | 83/510 [00:13<01:01,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  17%|█▋        | 85/510 [00:13<01:05,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  17%|█▋        | 86/510 [00:13<01:01,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  17%|█▋        | 88/510 [00:13<01:05,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  17%|█▋        | 89/510 [00:14<01:01,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  18%|█▊        | 91/510 [00:14<01:03,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  18%|█▊        | 92/510 [00:14<01:01,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  18%|█▊        | 94/510 [00:14<01:04,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  19%|█▊        | 95/510 [00:14<00:59,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  19%|█▉        | 97/510 [00:15<01:04,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  19%|█▉        | 98/510 [00:15<01:01,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  20%|█▉        | 100/510 [00:15<01:03,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  20%|█▉        | 101/510 [00:15<00:59,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  20%|██        | 103/510 [00:16<01:03,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  20%|██        | 104/510 [00:16<00:58,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  21%|██        | 106/510 [00:16<01:02,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  21%|██        | 108/510 [00:17<01:06,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  21%|██▏       | 109/510 [00:17<01:00,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  22%|██▏       | 110/510 [00:17<00:58,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  22%|██▏       | 112/510 [00:17<01:01,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  22%|██▏       | 113/510 [00:17<00:57,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  23%|██▎       | 115/510 [00:18<01:00,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  23%|██▎       | 116/510 [00:18<00:57,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  23%|██▎       | 118/510 [00:18<01:00,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  23%|██▎       | 119/510 [00:18<00:55,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  24%|██▎       | 121/510 [00:19<00:59,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  24%|██▍       | 122/510 [00:19<00:55,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  24%|██▍       | 124/510 [00:19<00:59,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  25%|██▍       | 125/510 [00:19<00:56,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  25%|██▍       | 127/510 [00:20<01:00,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  25%|██▌       | 128/510 [00:20<00:57,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  25%|██▌       | 130/510 [00:20<00:59,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  26%|██▌       | 131/510 [00:20<00:55,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  26%|██▌       | 133/510 [00:20<00:58,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  26%|██▋       | 134/510 [00:21<00:55,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  27%|██▋       | 136/510 [00:21<00:57,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  27%|██▋       | 137/510 [00:21<00:53,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  27%|██▋       | 139/510 [00:21<00:56,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  27%|██▋       | 140/510 [00:22<00:53,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  28%|██▊       | 142/510 [00:22<00:56,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  28%|██▊       | 143/510 [00:22<00:53,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  28%|██▊       | 145/510 [00:22<00:55,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  29%|██▊       | 146/510 [00:22<00:52,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  29%|██▉       | 148/510 [00:23<00:56,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  29%|██▉       | 149/510 [00:23<00:52,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  30%|██▉       | 151/510 [00:23<00:55,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  30%|██▉       | 152/510 [00:23<00:52,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  30%|███       | 154/510 [00:24<00:54,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  30%|███       | 155/510 [00:24<00:50,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  31%|███       | 157/510 [00:24<00:53,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  31%|███       | 158/510 [00:24<00:50,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  31%|███▏      | 160/510 [00:25<00:53,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  32%|███▏      | 161/510 [00:25<00:50,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  32%|███▏      | 163/510 [00:25<00:52,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  32%|███▏      | 164/510 [00:25<00:49,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  33%|███▎      | 166/510 [00:26<00:52,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  33%|███▎      | 167/510 [00:26<00:49,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  33%|███▎      | 169/510 [00:26<00:51,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  33%|███▎      | 170/510 [00:26<00:48,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  34%|███▎      | 172/510 [00:26<00:51,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  34%|███▍      | 174/510 [00:27<00:54,  6.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  34%|███▍      | 175/510 [00:27<00:50,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  35%|███▍      | 177/510 [00:27<00:53,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  35%|███▍      | 178/510 [00:27<00:49,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  35%|███▌      | 180/510 [00:28<00:53,  6.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  35%|███▌      | 181/510 [00:28<00:49,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  36%|███▌      | 182/510 [00:28<00:46,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  36%|███▌      | 184/510 [00:28<00:48,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  36%|███▋      | 185/510 [00:28<00:45,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  37%|███▋      | 187/510 [00:29<00:48,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  37%|███▋      | 188/510 [00:29<00:44,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  37%|███▋      | 190/510 [00:29<00:48,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  37%|███▋      | 191/510 [00:29<00:45,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  38%|███▊      | 193/510 [00:30<00:51,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  38%|███▊      | 194/510 [00:30<00:48,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  38%|███▊      | 196/510 [00:30<00:49,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  39%|███▊      | 197/510 [00:30<00:46,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  39%|███▉      | 199/510 [00:31<00:47,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  39%|███▉      | 201/510 [00:31<00:50,  6.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  40%|███▉      | 202/510 [00:31<00:47,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  40%|███▉      | 203/510 [00:31<00:43,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  40%|████      | 205/510 [00:32<00:47,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  40%|████      | 206/510 [00:32<00:44,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  41%|████      | 208/510 [00:32<00:46,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  41%|████      | 210/510 [00:32<00:49,  6.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  41%|████▏     | 211/510 [00:32<00:46,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  42%|████▏     | 212/510 [00:33<00:43,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  42%|████▏     | 214/510 [00:33<00:44,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  42%|████▏     | 215/510 [00:33<00:42,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  43%|████▎     | 217/510 [00:33<00:44,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  43%|████▎     | 218/510 [00:34<00:41,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  43%|████▎     | 220/510 [00:34<00:45,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  43%|████▎     | 221/510 [00:34<00:44,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  44%|████▎     | 223/510 [00:34<00:45,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  44%|████▍     | 224/510 [00:34<00:42,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  44%|████▍     | 226/510 [00:35<00:44,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  45%|████▍     | 228/510 [00:35<00:47,  5.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  45%|████▍     | 229/510 [00:35<00:42,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  45%|████▌     | 230/510 [00:35<00:39,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  45%|████▌     | 232/510 [00:36<00:41,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  46%|████▌     | 234/510 [00:36<00:44,  6.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  46%|████▌     | 235/510 [00:36<00:40,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  46%|████▋     | 236/510 [00:36<00:38,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  47%|████▋     | 238/510 [00:37<00:40,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  47%|████▋     | 239/510 [00:37<00:39,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  47%|████▋     | 241/510 [00:37<00:40,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  47%|████▋     | 242/510 [00:37<00:38,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  48%|████▊     | 244/510 [00:38<00:39,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  48%|████▊     | 245/510 [00:38<00:38,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  48%|████▊     | 247/510 [00:38<00:39,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  49%|████▊     | 248/510 [00:38<00:37,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  49%|████▉     | 250/510 [00:38<00:39,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  49%|████▉     | 252/510 [00:39<00:42,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  50%|████▉     | 253/510 [00:39<00:38,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  50%|█████     | 255/510 [00:39<00:40,  6.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  50%|█████     | 256/510 [00:39<00:37,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  50%|█████     | 257/510 [00:40<00:36,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  51%|█████     | 259/510 [00:40<00:39,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  51%|█████     | 260/510 [00:40<00:36,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  51%|█████▏    | 262/510 [00:40<00:37,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  52%|█████▏    | 263/510 [00:40<00:35,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  52%|█████▏    | 265/510 [00:41<00:36,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  52%|█████▏    | 267/510 [00:41<00:39,  6.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  53%|█████▎    | 268/510 [00:41<00:36,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  53%|█████▎    | 269/510 [00:41<00:34,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  53%|█████▎    | 271/510 [00:42<00:36,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  53%|█████▎    | 272/510 [00:42<00:34,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  54%|█████▎    | 274/510 [00:42<00:36,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  54%|█████▍    | 275/510 [00:42<00:34,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  54%|█████▍    | 277/510 [00:43<00:36,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  55%|█████▍    | 278/510 [00:43<00:33,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  55%|█████▍    | 280/510 [00:43<00:36,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  55%|█████▌    | 281/510 [00:43<00:33,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  55%|█████▌    | 283/510 [00:44<00:35,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  56%|█████▌    | 284/510 [00:44<00:32,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  56%|█████▌    | 286/510 [00:44<00:34,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  56%|█████▋    | 287/510 [00:44<00:32,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  57%|█████▋    | 289/510 [00:45<00:34,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  57%|█████▋    | 290/510 [00:45<00:32,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  57%|█████▋    | 292/510 [00:45<00:34,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  57%|█████▋    | 293/510 [00:45<00:31,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  58%|█████▊    | 295/510 [00:45<00:33,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  58%|█████▊    | 296/510 [00:46<00:30,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  58%|█████▊    | 298/510 [00:46<00:32,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  59%|█████▊    | 299/510 [00:46<00:30,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  59%|█████▉    | 301/510 [00:46<00:32,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  59%|█████▉    | 302/510 [00:47<00:30,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  60%|█████▉    | 304/510 [00:47<00:31,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  60%|██████    | 306/510 [00:47<00:33,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  60%|██████    | 307/510 [00:47<00:31,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  60%|██████    | 308/510 [00:47<00:28,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  61%|██████    | 310/510 [00:48<00:30,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  61%|██████    | 311/510 [00:48<00:28,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  61%|██████▏   | 313/510 [00:48<00:30,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  62%|██████▏   | 314/510 [00:48<00:27,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  62%|██████▏   | 316/510 [00:49<00:29,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  62%|██████▏   | 317/510 [00:49<00:27,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  63%|██████▎   | 319/510 [00:49<00:28,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  63%|██████▎   | 320/510 [00:49<00:27,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  63%|██████▎   | 322/510 [00:50<00:30,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  63%|██████▎   | 323/510 [00:50<00:28,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  64%|██████▎   | 325/510 [00:50<00:29,  6.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  64%|██████▍   | 326/510 [00:50<00:27,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  64%|██████▍   | 328/510 [00:51<00:28,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  65%|██████▍   | 329/510 [00:51<00:26,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  65%|██████▍   | 331/510 [00:51<00:27,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  65%|██████▌   | 332/510 [00:51<00:25,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  65%|██████▌   | 334/510 [00:52<00:27,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  66%|██████▌   | 335/510 [00:52<00:25,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  66%|██████▌   | 337/510 [00:52<00:26,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  66%|██████▋   | 338/510 [00:52<00:25,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  67%|██████▋   | 340/510 [00:52<00:26,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  67%|██████▋   | 342/510 [00:53<00:27,  6.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  67%|██████▋   | 343/510 [00:53<00:25,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  67%|██████▋   | 344/510 [00:53<00:23,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  68%|██████▊   | 346/510 [00:53<00:25,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  68%|██████▊   | 347/510 [00:54<00:23,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  68%|██████▊   | 349/510 [00:54<00:24,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  69%|██████▊   | 350/510 [00:54<00:22,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  69%|██████▉   | 352/510 [00:54<00:24,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  69%|██████▉   | 353/510 [00:54<00:22,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  70%|██████▉   | 355/510 [00:55<00:23,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  70%|██████▉   | 356/510 [00:55<00:22,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  70%|███████   | 358/510 [00:55<00:23,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  70%|███████   | 359/510 [00:55<00:22,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  71%|███████   | 361/510 [00:56<00:23,  6.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  71%|███████   | 362/510 [00:56<00:21,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  71%|███████▏  | 364/510 [00:56<00:22,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  72%|███████▏  | 365/510 [00:56<00:21,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  72%|███████▏  | 367/510 [00:57<00:21,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  72%|███████▏  | 368/510 [00:57<00:20,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  73%|███████▎  | 370/510 [00:57<00:21,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  73%|███████▎  | 371/510 [00:57<00:19,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  73%|███████▎  | 373/510 [00:58<00:20,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  73%|███████▎  | 374/510 [00:58<00:19,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  74%|███████▎  | 376/510 [00:58<00:20,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  74%|███████▍  | 377/510 [00:58<00:18,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  74%|███████▍  | 379/510 [00:58<00:19,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  75%|███████▍  | 380/510 [00:59<00:18,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  75%|███████▍  | 382/510 [00:59<00:19,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  75%|███████▌  | 383/510 [00:59<00:18,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  75%|███████▌  | 385/510 [00:59<00:19,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  76%|███████▌  | 386/510 [01:00<00:19,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  76%|███████▌  | 388/510 [01:00<00:19,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  76%|███████▋  | 389/510 [01:00<00:17,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  77%|███████▋  | 391/510 [01:00<00:18,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  77%|███████▋  | 392/510 [01:01<00:17,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  77%|███████▋  | 394/510 [01:01<00:18,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  77%|███████▋  | 395/510 [01:01<00:16,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  78%|███████▊  | 397/510 [01:01<00:17,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  78%|███████▊  | 398/510 [01:01<00:16,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  78%|███████▊  | 400/510 [01:02<00:16,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  79%|███████▊  | 401/510 [01:02<00:15,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  79%|███████▉  | 403/510 [01:02<00:16,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  79%|███████▉  | 404/510 [01:02<00:15,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  80%|███████▉  | 406/510 [01:03<00:16,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  80%|███████▉  | 407/510 [01:03<00:15,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  80%|████████  | 409/510 [01:03<00:15,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  80%|████████  | 410/510 [01:03<00:14,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  81%|████████  | 412/510 [01:04<00:15,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  81%|████████  | 414/510 [01:04<00:15,  6.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  81%|████████▏ | 415/510 [01:04<00:14,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  82%|████████▏ | 417/510 [01:04<00:15,  6.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  82%|████████▏ | 418/510 [01:05<00:13,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  82%|████████▏ | 419/510 [01:05<00:12,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  83%|████████▎ | 421/510 [01:05<00:14,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  83%|████████▎ | 422/510 [01:05<00:13,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  83%|████████▎ | 424/510 [01:06<00:13,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  83%|████████▎ | 425/510 [01:06<00:12,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  84%|████████▎ | 427/510 [01:06<00:12,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  84%|████████▍ | 428/510 [01:06<00:11,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  84%|████████▍ | 430/510 [01:06<00:12,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  85%|████████▍ | 431/510 [01:07<00:11,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  85%|████████▍ | 433/510 [01:07<00:12,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  85%|████████▌ | 434/510 [01:07<00:11,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  85%|████████▌ | 436/510 [01:07<00:11,  6.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  86%|████████▌ | 437/510 [01:08<00:10,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  86%|████████▌ | 439/510 [01:08<00:11,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  86%|████████▋ | 440/510 [01:08<00:10,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  87%|████████▋ | 442/510 [01:08<00:10,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  87%|████████▋ | 443/510 [01:08<00:09,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  87%|████████▋ | 445/510 [01:09<00:10,  6.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  88%|████████▊ | 447/510 [01:09<00:10,  6.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  88%|████████▊ | 448/510 [01:09<00:09,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  88%|████████▊ | 449/510 [01:09<00:08,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  88%|████████▊ | 451/510 [01:10<00:09,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  89%|████████▊ | 452/510 [01:10<00:08,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  89%|████████▉ | 454/510 [01:10<00:08,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  89%|████████▉ | 455/510 [01:10<00:07,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  90%|████████▉ | 457/510 [01:11<00:08,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  90%|████████▉ | 458/510 [01:11<00:07,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  90%|█████████ | 460/510 [01:11<00:07,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  90%|█████████ | 461/510 [01:11<00:07,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  91%|█████████ | 463/510 [01:12<00:07,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  91%|█████████ | 464/510 [01:12<00:06,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  91%|█████████▏| 466/510 [01:12<00:06,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  92%|█████████▏| 468/510 [01:12<00:06,  6.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  92%|█████████▏| 469/510 [01:13<00:06,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  92%|█████████▏| 471/510 [01:13<00:06,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  93%|█████████▎| 472/510 [01:13<00:05,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  93%|█████████▎| 473/510 [01:13<00:05,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  93%|█████████▎| 475/510 [01:13<00:05,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  94%|█████████▎| 477/510 [01:14<00:05,  6.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  94%|█████████▎| 478/510 [01:14<00:04,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  94%|█████████▍| 479/510 [01:14<00:04,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  94%|█████████▍| 481/510 [01:14<00:04,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  95%|█████████▍| 482/510 [01:14<00:03,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  95%|█████████▍| 484/510 [01:15<00:03,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  95%|█████████▌| 485/510 [01:15<00:03,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  95%|█████████▌| 487/510 [01:15<00:03,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  96%|█████████▌| 488/510 [01:15<00:03,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  96%|█████████▌| 490/510 [01:16<00:03,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  96%|█████████▋| 492/510 [01:16<00:02,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  97%|█████████▋| 493/510 [01:16<00:02,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  97%|█████████▋| 494/510 [01:16<00:02,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  97%|█████████▋| 496/510 [01:17<00:02,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  97%|█████████▋| 497/510 [01:17<00:01,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  98%|█████████▊| 499/510 [01:17<00:01,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  98%|█████████▊| 500/510 [01:17<00:01,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  98%|█████████▊| 502/510 [01:18<00:01,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  99%|█████████▉| 504/510 [01:18<00:00,  6.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  99%|█████████▉| 505/510 [01:18<00:00,  6.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  99%|█████████▉| 507/510 [01:18<00:00,  6.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1: 100%|█████████▉| 508/510 [01:19<00:00,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1: 100%|█████████▉| 509/510 [01:19<00:00,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1: 100%|██████████| 510/510 [01:19<00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed T1: 510/510 files processed\n",
      "🖼️  Processing T2: 510 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   0%|          | 1/510 [00:00<01:03,  8.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   0%|          | 2/510 [00:00<01:02,  8.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   1%|          | 4/510 [00:00<01:23,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   1%|          | 5/510 [00:00<01:14,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   1%|▏         | 7/510 [00:01<01:17,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   2%|▏         | 8/510 [00:01<01:12,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   2%|▏         | 10/510 [00:01<01:16,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   2%|▏         | 11/510 [00:01<01:12,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   3%|▎         | 13/510 [00:02<01:18,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   3%|▎         | 14/510 [00:02<01:14,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   3%|▎         | 16/510 [00:02<01:17,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   3%|▎         | 17/510 [00:02<01:12,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   4%|▎         | 19/510 [00:02<01:16,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   4%|▍         | 20/510 [00:03<01:11,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   4%|▍         | 22/510 [00:03<01:15,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   5%|▍         | 23/510 [00:03<01:11,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   5%|▍         | 25/510 [00:03<01:15,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   5%|▌         | 26/510 [00:04<01:11,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   5%|▌         | 28/510 [00:04<01:13,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   6%|▌         | 29/510 [00:04<01:09,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   6%|▌         | 31/510 [00:04<01:13,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   6%|▋         | 32/510 [00:04<01:09,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   7%|▋         | 34/510 [00:05<01:12,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   7%|▋         | 35/510 [00:05<01:07,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   7%|▋         | 37/510 [00:05<01:12,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   7%|▋         | 38/510 [00:05<01:07,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   8%|▊         | 40/510 [00:06<01:10,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   8%|▊         | 41/510 [00:06<01:06,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   8%|▊         | 43/510 [00:06<01:10,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   9%|▊         | 44/510 [00:06<01:06,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   9%|▉         | 46/510 [00:07<01:11,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   9%|▉         | 47/510 [00:07<01:07,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  10%|▉         | 49/510 [00:07<01:12,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  10%|▉         | 50/510 [00:07<01:07,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  10%|█         | 52/510 [00:08<01:11,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  10%|█         | 53/510 [00:08<01:07,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  11%|█         | 55/510 [00:08<01:11,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  11%|█         | 56/510 [00:08<01:08,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  11%|█▏        | 58/510 [00:09<01:09,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  12%|█▏        | 59/510 [00:09<01:05,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  12%|█▏        | 61/510 [00:09<01:09,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  12%|█▏        | 62/510 [00:09<01:05,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  13%|█▎        | 64/510 [00:09<01:08,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  13%|█▎        | 65/510 [00:10<01:04,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  13%|█▎        | 67/510 [00:10<01:09,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  13%|█▎        | 68/510 [00:10<01:08,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  14%|█▎        | 70/510 [00:10<01:11,  6.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  14%|█▍        | 71/510 [00:11<01:06,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  14%|█▍        | 73/510 [00:11<01:08,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  15%|█▍        | 74/510 [00:11<01:04,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  15%|█▍        | 76/510 [00:11<01:08,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  15%|█▌        | 77/510 [00:12<01:05,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  15%|█▌        | 79/510 [00:12<01:07,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  16%|█▌        | 80/510 [00:12<01:04,  6.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  16%|█▌        | 82/510 [00:12<01:07,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  16%|█▋        | 83/510 [00:12<01:02,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  17%|█▋        | 85/510 [00:13<01:06,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  17%|█▋        | 86/510 [00:13<01:02,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  17%|█▋        | 88/510 [00:13<01:05,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  17%|█▋        | 89/510 [00:13<01:00,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  18%|█▊        | 91/510 [00:14<01:04,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  18%|█▊        | 92/510 [00:14<01:00,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  18%|█▊        | 94/510 [00:14<01:04,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  19%|█▊        | 95/510 [00:14<00:59,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  19%|█▉        | 97/510 [00:15<01:03,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  19%|█▉        | 98/510 [00:15<01:00,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  20%|█▉        | 100/510 [00:15<01:04,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  20%|█▉        | 101/510 [00:15<01:00,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  20%|██        | 103/510 [00:16<01:03,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  20%|██        | 104/510 [00:16<00:59,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  21%|██        | 106/510 [00:16<01:02,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  21%|██        | 107/510 [00:16<00:59,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  21%|██▏       | 109/510 [00:17<01:02,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  22%|██▏       | 110/510 [00:17<00:58,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  22%|██▏       | 112/510 [00:17<01:02,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  22%|██▏       | 113/510 [00:17<00:59,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  23%|██▎       | 115/510 [00:17<01:01,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  23%|██▎       | 116/510 [00:18<00:57,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  23%|██▎       | 118/510 [00:18<01:00,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  23%|██▎       | 119/510 [00:18<00:57,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  24%|██▎       | 121/510 [00:18<01:00,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  24%|██▍       | 122/510 [00:19<00:56,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  24%|██▍       | 124/510 [00:19<00:59,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  25%|██▍       | 125/510 [00:19<00:56,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  25%|██▍       | 127/510 [00:19<00:59,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  25%|██▌       | 128/510 [00:19<00:55,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  25%|██▌       | 130/510 [00:20<00:59,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  26%|██▌       | 131/510 [00:20<00:56,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  26%|██▌       | 133/510 [00:20<01:02,  6.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  26%|██▋       | 134/510 [00:20<00:59,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  27%|██▋       | 136/510 [00:21<01:01,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  27%|██▋       | 137/510 [00:21<00:57,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  27%|██▋       | 139/510 [00:21<00:58,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  28%|██▊       | 141/510 [00:22<01:01,  6.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  28%|██▊       | 142/510 [00:22<00:56,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  28%|██▊       | 143/510 [00:22<00:52,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  28%|██▊       | 145/510 [00:22<00:56,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  29%|██▉       | 147/510 [00:23<00:59,  6.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  29%|██▉       | 148/510 [00:23<00:55,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  29%|██▉       | 149/510 [00:23<00:51,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  30%|██▉       | 151/510 [00:23<00:55,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  30%|██▉       | 152/510 [00:23<00:52,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  30%|███       | 154/510 [00:24<00:54,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  30%|███       | 155/510 [00:24<00:52,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  31%|███       | 157/510 [00:24<00:57,  6.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  31%|███       | 158/510 [00:24<00:54,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  31%|███▏      | 160/510 [00:25<00:54,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  32%|███▏      | 162/510 [00:25<00:58,  5.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  32%|███▏      | 163/510 [00:25<00:53,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  32%|███▏      | 164/510 [00:25<00:51,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  33%|███▎      | 166/510 [00:26<00:54,  6.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  33%|███▎      | 167/510 [00:26<00:50,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  33%|███▎      | 169/510 [00:26<00:52,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  33%|███▎      | 170/510 [00:26<00:49,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  34%|███▎      | 172/510 [00:27<00:52,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  34%|███▍      | 173/510 [00:27<00:48,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  34%|███▍      | 175/510 [00:27<00:53,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  35%|███▍      | 176/510 [00:27<00:50,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  35%|███▍      | 178/510 [00:27<00:51,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  35%|███▌      | 179/510 [00:28<00:49,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  35%|███▌      | 181/510 [00:28<00:51,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  36%|███▌      | 182/510 [00:28<00:49,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  36%|███▌      | 184/510 [00:28<00:51,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  36%|███▋      | 185/510 [00:29<00:47,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  37%|███▋      | 187/510 [00:29<00:50,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  37%|███▋      | 188/510 [00:29<00:47,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  37%|███▋      | 190/510 [00:29<00:50,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  37%|███▋      | 191/510 [00:29<00:46,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  38%|███▊      | 193/510 [00:30<00:49,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  38%|███▊      | 194/510 [00:30<00:48,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  38%|███▊      | 196/510 [00:30<00:51,  6.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  39%|███▊      | 197/510 [00:30<00:47,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  39%|███▉      | 199/510 [00:31<00:49,  6.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  39%|███▉      | 200/510 [00:31<00:45,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  40%|███▉      | 202/510 [00:31<00:48,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  40%|████      | 204/510 [00:32<00:50,  6.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  40%|████      | 205/510 [00:32<00:47,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  40%|████      | 206/510 [00:32<00:44,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  41%|████      | 208/510 [00:32<00:47,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  41%|████      | 209/510 [00:32<00:44,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  41%|████▏     | 211/510 [00:33<00:46,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  42%|████▏     | 212/510 [00:33<00:43,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  42%|████▏     | 214/510 [00:33<00:45,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  42%|████▏     | 215/510 [00:33<00:43,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  43%|████▎     | 217/510 [00:34<00:44,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  43%|████▎     | 219/510 [00:34<00:47,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  43%|████▎     | 220/510 [00:34<00:43,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  43%|████▎     | 221/510 [00:34<00:41,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  44%|████▎     | 223/510 [00:35<00:43,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  44%|████▍     | 224/510 [00:35<00:41,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  44%|████▍     | 226/510 [00:35<00:44,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  45%|████▍     | 227/510 [00:35<00:41,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  45%|████▍     | 229/510 [00:35<00:43,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  45%|████▌     | 230/510 [00:36<00:40,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  45%|████▌     | 232/510 [00:36<00:43,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  46%|████▌     | 233/510 [00:36<00:40,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  46%|████▌     | 235/510 [00:36<00:42,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  46%|████▋     | 236/510 [00:37<00:40,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  47%|████▋     | 238/510 [00:37<00:42,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  47%|████▋     | 239/510 [00:37<00:39,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  47%|████▋     | 241/510 [00:37<00:41,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  47%|████▋     | 242/510 [00:37<00:38,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  48%|████▊     | 244/510 [00:38<00:41,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  48%|████▊     | 245/510 [00:38<00:38,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  48%|████▊     | 247/510 [00:38<00:40,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  49%|████▊     | 248/510 [00:38<00:38,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  49%|████▉     | 250/510 [00:39<00:40,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  49%|████▉     | 251/510 [00:39<00:38,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  50%|████▉     | 253/510 [00:39<00:40,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  50%|████▉     | 254/510 [00:39<00:37,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  50%|█████     | 256/510 [00:40<00:39,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  50%|█████     | 257/510 [00:40<00:36,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  51%|█████     | 259/510 [00:40<00:41,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  51%|█████     | 260/510 [00:40<00:37,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  51%|█████▏    | 262/510 [00:41<00:39,  6.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  52%|█████▏    | 263/510 [00:41<00:36,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  52%|█████▏    | 265/510 [00:41<00:37,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  52%|█████▏    | 266/510 [00:41<00:35,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  53%|█████▎    | 268/510 [00:42<00:36,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  53%|█████▎    | 269/510 [00:42<00:34,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  53%|█████▎    | 271/510 [00:42<00:38,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  53%|█████▎    | 272/510 [00:42<00:35,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  54%|█████▎    | 274/510 [00:43<00:37,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  54%|█████▍    | 276/510 [00:43<00:38,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  54%|█████▍    | 277/510 [00:43<00:36,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  55%|█████▍    | 278/510 [00:43<00:33,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  55%|█████▍    | 280/510 [00:43<00:35,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  55%|█████▌    | 282/510 [00:44<00:37,  6.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  55%|█████▌    | 283/510 [00:44<00:34,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  56%|█████▌    | 284/510 [00:44<00:32,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  56%|█████▌    | 286/510 [00:44<00:34,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  56%|█████▋    | 287/510 [00:45<00:32,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  57%|█████▋    | 289/510 [00:45<00:34,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  57%|█████▋    | 290/510 [00:45<00:32,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  57%|█████▋    | 292/510 [00:45<00:33,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  57%|█████▋    | 293/510 [00:45<00:31,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  58%|█████▊    | 295/510 [00:46<00:33,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  58%|█████▊    | 296/510 [00:46<00:31,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  58%|█████▊    | 298/510 [00:46<00:32,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  59%|█████▊    | 299/510 [00:46<00:30,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  59%|█████▉    | 301/510 [00:47<00:32,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  59%|█████▉    | 302/510 [00:47<00:30,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  60%|█████▉    | 304/510 [00:47<00:32,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  60%|█████▉    | 305/510 [00:47<00:30,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  60%|██████    | 307/510 [00:48<00:33,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  60%|██████    | 308/510 [00:48<00:31,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  61%|██████    | 310/510 [00:48<00:33,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  61%|██████    | 311/510 [00:48<00:31,  6.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  61%|██████▏   | 313/510 [00:49<00:31,  6.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  62%|██████▏   | 314/510 [00:49<00:29,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  62%|██████▏   | 316/510 [00:49<00:30,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  62%|██████▏   | 317/510 [00:49<00:28,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  63%|██████▎   | 319/510 [00:50<00:29,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  63%|██████▎   | 320/510 [00:50<00:27,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  63%|██████▎   | 322/510 [00:50<00:30,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  63%|██████▎   | 323/510 [00:50<00:28,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  64%|██████▎   | 325/510 [00:51<00:29,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  64%|██████▍   | 326/510 [00:51<00:27,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  64%|██████▍   | 328/510 [00:51<00:27,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  65%|██████▍   | 330/510 [00:51<00:29,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  65%|██████▍   | 331/510 [00:52<00:27,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  65%|██████▌   | 332/510 [00:52<00:25,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  65%|██████▌   | 334/510 [00:52<00:26,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  66%|██████▌   | 335/510 [00:52<00:24,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  66%|██████▌   | 337/510 [00:52<00:26,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  66%|██████▋   | 338/510 [00:53<00:25,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  67%|██████▋   | 340/510 [00:53<00:26,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  67%|██████▋   | 341/510 [00:53<00:24,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  67%|██████▋   | 343/510 [00:53<00:26,  6.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  67%|██████▋   | 344/510 [00:54<00:25,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  68%|██████▊   | 346/510 [00:54<00:27,  6.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  68%|██████▊   | 347/510 [00:54<00:25,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  68%|██████▊   | 349/510 [00:54<00:25,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  69%|██████▊   | 350/510 [00:55<00:23,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  69%|██████▉   | 352/510 [00:55<00:24,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  69%|██████▉   | 353/510 [00:55<00:23,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  70%|██████▉   | 355/510 [00:55<00:24,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  70%|██████▉   | 356/510 [00:55<00:22,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  70%|███████   | 358/510 [00:56<00:23,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  70%|███████   | 359/510 [00:56<00:22,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  71%|███████   | 361/510 [00:56<00:23,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  71%|███████   | 362/510 [00:56<00:21,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  71%|███████▏  | 364/510 [00:57<00:22,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  72%|███████▏  | 365/510 [00:57<00:21,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  72%|███████▏  | 367/510 [00:57<00:22,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  72%|███████▏  | 368/510 [00:57<00:22,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  73%|███████▎  | 370/510 [00:58<00:24,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  73%|███████▎  | 371/510 [00:58<00:22,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  73%|███████▎  | 373/510 [00:58<00:22,  6.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  73%|███████▎  | 374/510 [00:58<00:20,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  74%|███████▎  | 376/510 [00:59<00:20,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  74%|███████▍  | 377/510 [00:59<00:19,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  74%|███████▍  | 379/510 [00:59<00:20,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  75%|███████▍  | 380/510 [00:59<00:18,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  75%|███████▍  | 382/510 [01:00<00:19,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  75%|███████▌  | 383/510 [01:00<00:18,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  75%|███████▌  | 385/510 [01:00<00:20,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  76%|███████▌  | 386/510 [01:00<00:18,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  76%|███████▌  | 388/510 [01:01<00:19,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  76%|███████▋  | 389/510 [01:01<00:18,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  77%|███████▋  | 391/510 [01:01<00:19,  6.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  77%|███████▋  | 392/510 [01:01<00:18,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  77%|███████▋  | 394/510 [01:02<00:18,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  77%|███████▋  | 395/510 [01:02<00:17,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  78%|███████▊  | 397/510 [01:02<00:17,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  78%|███████▊  | 398/510 [01:02<00:16,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  78%|███████▊  | 400/510 [01:03<00:17,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  79%|███████▊  | 401/510 [01:03<00:16,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  79%|███████▉  | 403/510 [01:03<00:16,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  79%|███████▉  | 404/510 [01:03<00:15,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  80%|███████▉  | 406/510 [01:04<00:16,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  80%|███████▉  | 407/510 [01:04<00:15,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  80%|████████  | 409/510 [01:04<00:15,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  80%|████████  | 410/510 [01:04<00:14,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  81%|████████  | 412/510 [01:04<00:15,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  81%|████████  | 413/510 [01:05<00:14,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  81%|████████▏ | 415/510 [01:05<00:14,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  82%|████████▏ | 416/510 [01:05<00:13,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  82%|████████▏ | 418/510 [01:05<00:14,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  82%|████████▏ | 420/510 [01:06<00:14,  6.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  83%|████████▎ | 421/510 [01:06<00:13,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  83%|████████▎ | 422/510 [01:06<00:12,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  83%|████████▎ | 424/510 [01:06<00:13,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  83%|████████▎ | 425/510 [01:06<00:12,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  84%|████████▎ | 427/510 [01:07<00:12,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  84%|████████▍ | 428/510 [01:07<00:11,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  84%|████████▍ | 430/510 [01:07<00:12,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  85%|████████▍ | 431/510 [01:07<00:11,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  85%|████████▍ | 433/510 [01:08<00:11,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  85%|████████▌ | 434/510 [01:08<00:10,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  85%|████████▌ | 436/510 [01:08<00:11,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  86%|████████▌ | 437/510 [01:08<00:10,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  86%|████████▌ | 439/510 [01:09<00:11,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  86%|████████▋ | 440/510 [01:09<00:10,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  87%|████████▋ | 442/510 [01:09<00:10,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  87%|████████▋ | 443/510 [01:09<00:10,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  87%|████████▋ | 445/510 [01:10<00:10,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  87%|████████▋ | 446/510 [01:10<00:09,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  88%|████████▊ | 448/510 [01:10<00:10,  6.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  88%|████████▊ | 449/510 [01:10<00:09,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  88%|████████▊ | 451/510 [01:11<00:09,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  89%|████████▊ | 452/510 [01:11<00:08,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  89%|████████▉ | 454/510 [01:11<00:08,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  89%|████████▉ | 455/510 [01:11<00:08,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  90%|████████▉ | 457/510 [01:12<00:08,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  90%|████████▉ | 458/510 [01:12<00:07,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  90%|█████████ | 460/510 [01:12<00:07,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  90%|█████████ | 461/510 [01:12<00:07,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  91%|█████████ | 463/510 [01:12<00:07,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  91%|█████████ | 464/510 [01:13<00:06,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  91%|█████████▏| 466/510 [01:13<00:06,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  92%|█████████▏| 467/510 [01:13<00:06,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  92%|█████████▏| 469/510 [01:13<00:06,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  92%|█████████▏| 470/510 [01:14<00:05,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  93%|█████████▎| 472/510 [01:14<00:05,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  93%|█████████▎| 473/510 [01:14<00:05,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  93%|█████████▎| 475/510 [01:14<00:05,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  93%|█████████▎| 476/510 [01:14<00:04,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  94%|█████████▎| 478/510 [01:15<00:04,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  94%|█████████▍| 479/510 [01:15<00:04,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  94%|█████████▍| 481/510 [01:15<00:04,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  95%|█████████▍| 482/510 [01:15<00:04,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  95%|█████████▍| 484/510 [01:16<00:04,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  95%|█████████▌| 485/510 [01:16<00:03,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  95%|█████████▌| 487/510 [01:16<00:03,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  96%|█████████▌| 488/510 [01:16<00:03,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  96%|█████████▌| 490/510 [01:17<00:03,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  96%|█████████▋| 491/510 [01:17<00:02,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  97%|█████████▋| 493/510 [01:17<00:02,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  97%|█████████▋| 494/510 [01:17<00:02,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  97%|█████████▋| 496/510 [01:18<00:02,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  97%|█████████▋| 497/510 [01:18<00:01,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  98%|█████████▊| 499/510 [01:18<00:01,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  98%|█████████▊| 500/510 [01:18<00:01,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  98%|█████████▊| 502/510 [01:19<00:01,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  99%|█████████▊| 503/510 [01:19<00:01,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  99%|█████████▉| 505/510 [01:19<00:00,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  99%|█████████▉| 506/510 [01:19<00:00,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2: 100%|█████████▉| 508/510 [01:20<00:00,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2: 100%|█████████▉| 509/510 [01:20<00:00,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2: 100%|██████████| 510/510 [01:20<00:00,  6.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed T2: 510/510 files processed\n",
      "🖼️  Processing label: 510 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   0%|          | 0/510 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   0%|          | 1/510 [00:00<01:35,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   0%|          | 2/510 [00:00<01:09,  7.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   1%|          | 3/510 [00:00<01:21,  6.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   1%|          | 4/510 [00:00<01:09,  7.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   2%|▏         | 8/510 [00:01<01:01,  8.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   2%|▏         | 10/510 [00:01<01:04,  7.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   3%|▎         | 14/510 [00:01<01:00,  8.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   3%|▎         | 17/510 [00:02<00:59,  8.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   4%|▍         | 20/510 [00:02<01:00,  8.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   4%|▍         | 21/510 [00:02<01:07,  7.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   4%|▍         | 22/510 [00:02<01:03,  7.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   5%|▌         | 26/510 [00:03<00:58,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   5%|▌         | 27/510 [00:03<01:05,  7.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   6%|▌         | 29/510 [00:03<00:58,  8.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   6%|▌         | 31/510 [00:04<01:03,  7.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   6%|▋         | 33/510 [00:04<01:09,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   7%|▋         | 35/510 [00:04<00:58,  8.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   7%|▋         | 38/510 [00:05<00:58,  8.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   8%|▊         | 39/510 [00:05<01:06,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   8%|▊         | 41/510 [00:05<00:57,  8.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   9%|▊         | 44/510 [00:05<00:57,  8.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   9%|▉         | 45/510 [00:05<01:06,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   9%|▉         | 47/510 [00:06<00:56,  8.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  10%|▉         | 49/510 [00:06<01:01,  7.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  10%|▉         | 50/510 [00:06<00:57,  8.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  10%|█         | 53/510 [00:07<00:58,  7.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  11%|█         | 56/510 [00:07<00:57,  7.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  11%|█         | 57/510 [00:07<01:05,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  11%|█▏        | 58/510 [00:07<00:59,  7.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  12%|█▏        | 62/510 [00:08<00:54,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  12%|█▏        | 63/510 [00:08<01:03,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  13%|█▎        | 65/510 [00:08<00:54,  8.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  13%|█▎        | 68/510 [00:09<00:54,  8.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  14%|█▎        | 69/510 [00:09<01:03,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  14%|█▍        | 71/510 [00:09<00:54,  8.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  14%|█▍        | 73/510 [00:09<00:58,  7.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  15%|█▍        | 74/510 [00:09<00:54,  7.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  15%|█▍        | 76/510 [00:10<01:03,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  15%|█▌        | 77/510 [00:10<01:00,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  15%|█▌        | 79/510 [00:10<01:02,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  16%|█▌        | 81/510 [00:10<01:05,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  16%|█▋        | 83/510 [00:11<00:53,  7.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  17%|█▋        | 86/510 [00:11<00:52,  8.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  17%|█▋        | 87/510 [00:11<01:01,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  17%|█▋        | 89/510 [00:11<00:51,  8.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  18%|█▊        | 91/510 [00:12<00:54,  7.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  18%|█▊        | 93/510 [00:12<00:59,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  19%|█▊        | 95/510 [00:12<00:50,  8.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  19%|█▉        | 98/510 [00:13<00:50,  8.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  20%|█▉        | 101/510 [00:13<00:50,  8.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  20%|██        | 102/510 [00:13<00:58,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  20%|██        | 104/510 [00:13<00:50,  8.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  21%|██        | 107/510 [00:14<00:49,  8.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  21%|██        | 108/510 [00:14<00:57,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  22%|██▏       | 110/510 [00:14<00:48,  8.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  22%|██▏       | 113/510 [00:15<00:48,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  22%|██▏       | 114/510 [00:15<00:56,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  23%|██▎       | 116/510 [00:15<00:48,  8.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  23%|██▎       | 119/510 [00:15<00:47,  8.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  24%|██▎       | 121/510 [00:16<00:50,  7.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  25%|██▍       | 125/510 [00:16<00:46,  8.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  25%|██▌       | 128/510 [00:17<00:46,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  25%|██▌       | 129/510 [00:17<00:52,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  26%|██▌       | 131/510 [00:17<00:46,  8.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  26%|██▋       | 134/510 [00:17<00:46,  8.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  27%|██▋       | 137/510 [00:18<00:45,  8.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  27%|██▋       | 138/510 [00:18<00:53,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  27%|██▋       | 140/510 [00:18<00:45,  8.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  28%|██▊       | 142/510 [00:18<00:48,  7.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  28%|██▊       | 144/510 [00:19<00:52,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  29%|██▊       | 146/510 [00:19<00:45,  8.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  29%|██▉       | 149/510 [00:19<00:44,  8.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  30%|██▉       | 151/510 [00:20<00:49,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  30%|███       | 153/510 [00:20<00:50,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  30%|███       | 155/510 [00:20<00:44,  7.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  31%|███       | 158/510 [00:21<00:43,  8.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  31%|███       | 159/510 [00:21<00:49,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  31%|███▏      | 160/510 [00:21<00:46,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  32%|███▏      | 163/510 [00:21<00:44,  7.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  33%|███▎      | 166/510 [00:22<00:44,  7.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  33%|███▎      | 168/510 [00:22<00:48,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  33%|███▎      | 170/510 [00:22<00:41,  8.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  34%|███▍      | 173/510 [00:23<00:41,  8.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  34%|███▍      | 174/510 [00:23<00:48,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  34%|███▍      | 175/510 [00:23<00:44,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  35%|███▍      | 178/510 [00:23<00:43,  7.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  35%|███▌      | 180/510 [00:24<00:46,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  36%|███▌      | 182/510 [00:24<00:40,  8.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  36%|███▋      | 185/510 [00:24<00:39,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  36%|███▋      | 186/510 [00:24<00:46,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  37%|███▋      | 188/510 [00:25<00:39,  8.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  37%|███▋      | 191/510 [00:25<00:39,  8.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  38%|███▊      | 192/510 [00:25<00:45,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  38%|███▊      | 194/510 [00:25<00:38,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  39%|███▊      | 197/510 [00:26<00:38,  8.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  39%|███▉      | 199/510 [00:26<00:41,  7.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  39%|███▉      | 201/510 [00:26<00:44,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  40%|███▉      | 203/510 [00:27<00:37,  8.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  40%|████      | 205/510 [00:27<00:39,  7.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  41%|████      | 207/510 [00:27<00:43,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  41%|████      | 209/510 [00:27<00:36,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  41%|████▏     | 211/510 [00:28<00:39,  7.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  42%|████▏     | 213/510 [00:28<00:41,  7.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  42%|████▏     | 215/510 [00:28<00:36,  8.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  43%|████▎     | 217/510 [00:28<00:38,  7.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  43%|████▎     | 221/510 [00:29<00:35,  8.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  44%|████▎     | 222/510 [00:29<00:40,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  44%|████▍     | 224/510 [00:29<00:34,  8.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  44%|████▍     | 226/510 [00:30<00:39,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  45%|████▍     | 228/510 [00:30<00:42,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  45%|████▌     | 230/510 [00:30<00:35,  7.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  46%|████▌     | 233/510 [00:31<00:34,  8.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  46%|████▌     | 234/510 [00:31<00:39,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  46%|████▋     | 236/510 [00:31<00:33,  8.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  47%|████▋     | 239/510 [00:31<00:33,  8.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  47%|████▋     | 240/510 [00:32<00:38,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  47%|████▋     | 242/510 [00:32<00:32,  8.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  48%|████▊     | 245/510 [00:32<00:32,  8.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  49%|████▊     | 248/510 [00:32<00:31,  8.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  49%|████▉     | 251/510 [00:33<00:31,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  50%|████▉     | 254/510 [00:33<00:30,  8.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  50%|█████     | 256/510 [00:34<00:32,  7.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  51%|█████     | 258/510 [00:34<00:36,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  51%|█████     | 260/510 [00:34<00:30,  8.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  51%|█████     | 261/510 [00:34<00:35,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  52%|█████▏    | 263/510 [00:34<00:30,  8.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  52%|█████▏    | 265/510 [00:35<00:32,  7.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  53%|█████▎    | 268/510 [00:35<00:31,  7.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  53%|█████▎    | 272/510 [00:36<00:28,  8.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  54%|█████▎    | 273/510 [00:36<00:33,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  54%|█████▎    | 274/510 [00:36<00:30,  7.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  54%|█████▍    | 277/510 [00:36<00:30,  7.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  55%|█████▍    | 279/510 [00:37<00:31,  7.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  55%|█████▌    | 281/510 [00:37<00:27,  8.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  55%|█████▌    | 283/510 [00:37<00:29,  7.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  56%|█████▋    | 287/510 [00:38<00:27,  8.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  56%|█████▋    | 288/510 [00:38<00:31,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  57%|█████▋    | 290/510 [00:38<00:26,  8.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  57%|█████▋    | 292/510 [00:38<00:28,  7.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  58%|█████▊    | 295/510 [00:39<00:27,  7.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  58%|█████▊    | 298/510 [00:39<00:27,  7.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  59%|█████▉    | 300/510 [00:39<00:29,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  59%|█████▉    | 302/510 [00:40<00:27,  7.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  60%|█████▉    | 305/510 [00:40<00:25,  7.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  60%|██████    | 307/510 [00:40<00:26,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  61%|██████    | 309/510 [00:41<00:27,  7.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  61%|██████    | 311/510 [00:41<00:24,  8.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  62%|██████▏   | 314/510 [00:41<00:24,  8.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  62%|██████▏   | 315/510 [00:41<00:26,  7.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  62%|██████▏   | 316/510 [00:41<00:24,  7.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  63%|██████▎   | 320/510 [00:42<00:22,  8.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  63%|██████▎   | 321/510 [00:42<00:26,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  63%|██████▎   | 323/510 [00:42<00:22,  8.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  64%|██████▍   | 326/510 [00:43<00:22,  8.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  64%|██████▍   | 327/510 [00:43<00:25,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  65%|██████▍   | 329/510 [00:43<00:22,  8.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  65%|██████▍   | 331/510 [00:43<00:23,  7.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  65%|██████▌   | 333/510 [00:44<00:24,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  66%|██████▌   | 335/510 [00:44<00:21,  8.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  66%|██████▋   | 338/510 [00:44<00:21,  8.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  66%|██████▋   | 339/510 [00:45<00:23,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  67%|██████▋   | 340/510 [00:45<00:22,  7.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  67%|██████▋   | 344/510 [00:45<00:20,  8.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  68%|██████▊   | 347/510 [00:45<00:19,  8.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  69%|██████▊   | 350/510 [00:46<00:19,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  69%|██████▉   | 351/510 [00:46<00:22,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  69%|██████▉   | 353/510 [00:46<00:19,  8.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  70%|██████▉   | 355/510 [00:47<00:20,  7.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  70%|███████   | 357/510 [00:47<00:21,  7.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  70%|███████   | 358/510 [00:47<00:19,  7.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  71%|███████   | 362/510 [00:47<00:17,  8.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  72%|███████▏  | 365/510 [00:48<00:17,  8.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  72%|███████▏  | 367/510 [00:48<00:19,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  72%|███████▏  | 368/510 [00:48<00:18,  7.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  73%|███████▎  | 370/510 [00:49<00:19,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  73%|███████▎  | 372/510 [00:49<00:21,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  73%|███████▎  | 373/510 [00:49<00:18,  7.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  74%|███████▎  | 376/510 [00:49<00:17,  7.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  74%|███████▍  | 377/510 [00:50<00:16,  7.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  75%|███████▍  | 380/510 [00:50<00:16,  7.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  75%|███████▍  | 381/510 [00:50<00:18,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  75%|███████▍  | 382/510 [00:50<00:17,  7.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  75%|███████▌  | 385/510 [00:51<00:16,  7.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  76%|███████▋  | 389/510 [00:51<00:14,  8.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  77%|███████▋  | 392/510 [00:52<00:14,  8.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  77%|███████▋  | 395/510 [00:52<00:14,  8.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  78%|███████▊  | 396/510 [00:52<00:16,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  78%|███████▊  | 398/510 [00:52<00:13,  8.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  79%|███████▊  | 401/510 [00:53<00:13,  8.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  79%|███████▉  | 402/510 [00:53<00:15,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  79%|███████▉  | 403/510 [00:53<00:13,  7.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  80%|███████▉  | 407/510 [00:54<00:12,  8.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  80%|████████  | 409/510 [00:54<00:13,  7.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  81%|████████  | 411/510 [00:54<00:13,  7.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  81%|████████  | 413/510 [00:54<00:11,  8.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  81%|████████  | 414/510 [00:55<00:13,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  82%|████████▏ | 416/510 [00:55<00:11,  8.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  82%|████████▏ | 418/510 [00:55<00:12,  7.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  82%|████████▏ | 420/510 [00:55<00:12,  7.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  83%|████████▎ | 421/510 [00:55<00:11,  7.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  83%|████████▎ | 425/510 [00:56<00:10,  8.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  84%|████████▎ | 426/510 [00:56<00:11,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  84%|████████▍ | 428/510 [00:56<00:09,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  84%|████████▍ | 430/510 [00:57<00:10,  7.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  85%|████████▍ | 433/510 [00:57<00:09,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  86%|████████▌ | 437/510 [00:57<00:08,  8.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  86%|████████▌ | 439/510 [00:58<00:09,  7.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  86%|████████▋ | 441/510 [00:58<00:09,  7.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  87%|████████▋ | 443/510 [00:58<00:08,  8.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  87%|████████▋ | 445/510 [00:59<00:08,  7.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  88%|████████▊ | 448/510 [00:59<00:07,  7.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  89%|████████▊ | 452/510 [00:59<00:07,  8.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  89%|████████▉ | 455/510 [01:00<00:06,  7.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  89%|████████▉ | 456/510 [01:00<00:07,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  90%|████████▉ | 458/510 [01:00<00:06,  8.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  90%|█████████ | 461/510 [01:01<00:06,  8.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  91%|█████████ | 463/510 [01:01<00:06,  7.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  91%|█████████▏| 466/510 [01:01<00:05,  7.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  92%|█████████▏| 470/510 [01:02<00:04,  8.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  92%|█████████▏| 471/510 [01:02<00:05,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  93%|█████████▎| 473/510 [01:02<00:04,  8.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  93%|█████████▎| 475/510 [01:02<00:04,  7.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  94%|█████████▎| 477/510 [01:03<00:04,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  94%|█████████▍| 479/510 [01:03<00:03,  8.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  94%|█████████▍| 481/510 [01:03<00:03,  7.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  95%|█████████▌| 485/510 [01:04<00:03,  8.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  95%|█████████▌| 486/510 [01:04<00:03,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  95%|█████████▌| 487/510 [01:04<00:03,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  96%|█████████▋| 491/510 [01:05<00:02,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  97%|█████████▋| 493/510 [01:05<00:02,  7.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  97%|█████████▋| 497/510 [01:05<00:01,  8.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  98%|█████████▊| 500/510 [01:06<00:01,  8.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  98%|█████████▊| 501/510 [01:06<00:01,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  99%|█████████▊| 503/510 [01:06<00:00,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  99%|█████████▉| 506/510 [01:07<00:00,  8.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label: 100%|█████████▉| 509/510 [01:07<00:00,  8.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label: 100%|██████████| 510/510 [01:07<00:00,  7.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed label: 510/510 files processed\n",
      "\n",
      "📁 Processing val split...\n",
      "🖼️  Processing T1: 127 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   1%|          | 1/127 [00:00<00:15,  8.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   2%|▏         | 2/127 [00:00<00:14,  8.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   3%|▎         | 4/127 [00:00<00:18,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   5%|▍         | 6/127 [00:00<00:19,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   6%|▌         | 7/127 [00:01<00:17,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   6%|▋         | 8/127 [00:01<00:16,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   8%|▊         | 10/127 [00:01<00:17,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   9%|▊         | 11/127 [00:01<00:16,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  10%|█         | 13/127 [00:01<00:17,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  11%|█         | 14/127 [00:02<00:16,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  13%|█▎        | 16/127 [00:02<00:17,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  13%|█▎        | 17/127 [00:02<00:16,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  15%|█▍        | 19/127 [00:02<00:16,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  16%|█▌        | 20/127 [00:03<00:15,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  17%|█▋        | 22/127 [00:03<00:15,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  18%|█▊        | 23/127 [00:03<00:15,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  20%|█▉        | 25/127 [00:03<00:15,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  20%|██        | 26/127 [00:03<00:14,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  22%|██▏       | 28/127 [00:04<00:15,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  23%|██▎       | 29/127 [00:04<00:14,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  24%|██▍       | 31/127 [00:04<00:14,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  25%|██▌       | 32/127 [00:04<00:13,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  27%|██▋       | 34/127 [00:05<00:14,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  28%|██▊       | 35/127 [00:05<00:13,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  29%|██▉       | 37/127 [00:05<00:14,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  30%|██▉       | 38/127 [00:05<00:12,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  31%|███▏      | 40/127 [00:06<00:13,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  32%|███▏      | 41/127 [00:06<00:12,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  34%|███▍      | 43/127 [00:06<00:12,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  35%|███▍      | 44/127 [00:06<00:11,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  36%|███▌      | 46/127 [00:07<00:12,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  37%|███▋      | 47/127 [00:07<00:11,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  39%|███▊      | 49/127 [00:07<00:11,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  39%|███▉      | 50/127 [00:07<00:11,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  41%|████      | 52/127 [00:08<00:11,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  43%|████▎     | 54/127 [00:08<00:11,  6.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  43%|████▎     | 55/127 [00:08<00:10,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  44%|████▍     | 56/127 [00:08<00:10,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  46%|████▌     | 58/127 [00:08<00:11,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  46%|████▋     | 59/127 [00:09<00:10,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  48%|████▊     | 61/127 [00:09<00:10,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  49%|████▉     | 62/127 [00:09<00:09,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  50%|█████     | 64/127 [00:09<00:09,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  51%|█████     | 65/127 [00:10<00:08,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  53%|█████▎    | 67/127 [00:10<00:09,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  54%|█████▎    | 68/127 [00:10<00:08,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  55%|█████▌    | 70/127 [00:10<00:08,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  56%|█████▌    | 71/127 [00:10<00:08,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  57%|█████▋    | 73/127 [00:11<00:08,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  58%|█████▊    | 74/127 [00:11<00:07,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  60%|█████▉    | 76/127 [00:11<00:07,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  61%|██████    | 77/127 [00:11<00:07,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  62%|██████▏   | 79/127 [00:12<00:07,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  63%|██████▎   | 80/127 [00:12<00:07,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  65%|██████▍   | 82/127 [00:12<00:07,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  65%|██████▌   | 83/127 [00:12<00:06,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  67%|██████▋   | 85/127 [00:13<00:06,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  68%|██████▊   | 86/127 [00:13<00:05,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  69%|██████▉   | 88/127 [00:13<00:05,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  70%|███████   | 89/127 [00:13<00:05,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  72%|███████▏  | 91/127 [00:14<00:05,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  72%|███████▏  | 92/127 [00:14<00:04,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  74%|███████▍  | 94/127 [00:14<00:05,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  75%|███████▍  | 95/127 [00:14<00:04,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  76%|███████▋  | 97/127 [00:15<00:04,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  78%|███████▊  | 99/127 [00:15<00:04,  6.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  79%|███████▊  | 100/127 [00:15<00:04,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  80%|███████▉  | 101/127 [00:15<00:03,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  81%|████████  | 103/127 [00:15<00:03,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  83%|████████▎ | 105/127 [00:16<00:03,  6.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  83%|████████▎ | 106/127 [00:16<00:03,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  84%|████████▍ | 107/127 [00:16<00:02,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  86%|████████▌ | 109/127 [00:16<00:02,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  87%|████████▋ | 111/127 [00:17<00:02,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  88%|████████▊ | 112/127 [00:17<00:02,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  90%|████████▉ | 114/127 [00:17<00:02,  6.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  91%|█████████ | 115/127 [00:17<00:01,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  91%|█████████▏| 116/127 [00:17<00:01,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  93%|█████████▎| 118/127 [00:18<00:01,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  94%|█████████▍| 120/127 [00:18<00:01,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  95%|█████████▌| 121/127 [00:18<00:00,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  96%|█████████▌| 122/127 [00:18<00:00,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  98%|█████████▊| 124/127 [00:19<00:00,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  98%|█████████▊| 125/127 [00:19<00:00,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1: 100%|██████████| 127/127 [00:19<00:00,  6.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "✅ Completed T1: 127/127 files processed\n",
      "🖼️  Processing T2: 127 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   1%|          | 1/127 [00:00<00:15,  8.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   2%|▏         | 2/127 [00:00<00:15,  8.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   3%|▎         | 4/127 [00:00<00:18,  6.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   5%|▍         | 6/127 [00:00<00:19,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   6%|▌         | 7/127 [00:01<00:18,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   6%|▋         | 8/127 [00:01<00:16,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   8%|▊         | 10/127 [00:01<00:17,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   9%|▊         | 11/127 [00:01<00:16,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  10%|█         | 13/127 [00:01<00:17,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  11%|█         | 14/127 [00:02<00:16,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  13%|█▎        | 16/127 [00:02<00:16,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  13%|█▎        | 17/127 [00:02<00:15,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  15%|█▍        | 19/127 [00:02<00:17,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  16%|█▌        | 20/127 [00:03<00:16,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  17%|█▋        | 22/127 [00:03<00:16,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  18%|█▊        | 23/127 [00:03<00:14,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  20%|█▉        | 25/127 [00:03<00:15,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  20%|██        | 26/127 [00:03<00:14,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  22%|██▏       | 28/127 [00:04<00:15,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  23%|██▎       | 29/127 [00:04<00:14,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  24%|██▍       | 31/127 [00:04<00:14,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  25%|██▌       | 32/127 [00:04<00:13,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  27%|██▋       | 34/127 [00:05<00:14,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  28%|██▊       | 35/127 [00:05<00:13,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  29%|██▉       | 37/127 [00:05<00:13,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  30%|██▉       | 38/127 [00:05<00:12,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  31%|███▏      | 40/127 [00:06<00:13,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  32%|███▏      | 41/127 [00:06<00:12,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  34%|███▍      | 43/127 [00:06<00:13,  6.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  35%|███▍      | 44/127 [00:06<00:12,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  36%|███▌      | 46/127 [00:07<00:12,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  37%|███▋      | 47/127 [00:07<00:11,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  39%|███▊      | 49/127 [00:07<00:12,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  39%|███▉      | 50/127 [00:07<00:11,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  41%|████      | 52/127 [00:08<00:11,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  42%|████▏     | 53/127 [00:08<00:10,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  43%|████▎     | 55/127 [00:08<00:11,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  44%|████▍     | 56/127 [00:08<00:10,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  46%|████▌     | 58/127 [00:08<00:10,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  46%|████▋     | 59/127 [00:09<00:09,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  48%|████▊     | 61/127 [00:09<00:10,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  49%|████▉     | 62/127 [00:09<00:09,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  50%|█████     | 64/127 [00:09<00:09,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  51%|█████     | 65/127 [00:10<00:08,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  53%|█████▎    | 67/127 [00:10<00:09,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  54%|█████▎    | 68/127 [00:10<00:08,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  55%|█████▌    | 70/127 [00:10<00:08,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  56%|█████▌    | 71/127 [00:10<00:08,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  57%|█████▋    | 73/127 [00:11<00:08,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  58%|█████▊    | 74/127 [00:11<00:07,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  60%|█████▉    | 76/127 [00:11<00:07,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  61%|██████    | 77/127 [00:11<00:07,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  62%|██████▏   | 79/127 [00:12<00:07,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  63%|██████▎   | 80/127 [00:12<00:06,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  65%|██████▍   | 82/127 [00:12<00:07,  6.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  65%|██████▌   | 83/127 [00:12<00:06,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  67%|██████▋   | 85/127 [00:13<00:06,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  68%|██████▊   | 86/127 [00:13<00:05,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  69%|██████▉   | 88/127 [00:13<00:05,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  70%|███████   | 89/127 [00:13<00:05,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  72%|███████▏  | 91/127 [00:14<00:05,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  72%|███████▏  | 92/127 [00:14<00:05,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  74%|███████▍  | 94/127 [00:14<00:04,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  75%|███████▍  | 95/127 [00:14<00:04,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  76%|███████▋  | 97/127 [00:15<00:04,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  78%|███████▊  | 99/127 [00:15<00:04,  6.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  79%|███████▊  | 100/127 [00:15<00:04,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  80%|███████▉  | 101/127 [00:15<00:03,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  81%|████████  | 103/127 [00:15<00:03,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  82%|████████▏ | 104/127 [00:16<00:03,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  83%|████████▎ | 106/127 [00:16<00:03,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  84%|████████▍ | 107/127 [00:16<00:02,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  86%|████████▌ | 109/127 [00:16<00:02,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  87%|████████▋ | 110/127 [00:17<00:02,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  88%|████████▊ | 112/127 [00:17<00:02,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  89%|████████▉ | 113/127 [00:17<00:02,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  91%|█████████ | 115/127 [00:17<00:01,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  91%|█████████▏| 116/127 [00:17<00:01,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  93%|█████████▎| 118/127 [00:18<00:01,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  94%|█████████▎| 119/127 [00:18<00:01,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  95%|█████████▌| 121/127 [00:18<00:00,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  96%|█████████▌| 122/127 [00:18<00:00,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  98%|█████████▊| 124/127 [00:19<00:00,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  98%|█████████▊| 125/127 [00:19<00:00,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2: 100%|██████████| 127/127 [00:19<00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "✅ Completed T2: 127/127 files processed\n",
      "🖼️  Processing label: 127 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   2%|▏         | 2/127 [00:00<00:12, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   3%|▎         | 4/127 [00:00<00:15,  8.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   6%|▌         | 7/127 [00:00<00:15,  7.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   7%|▋         | 9/127 [00:01<00:15,  7.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   9%|▊         | 11/127 [00:01<00:13,  8.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  11%|█         | 14/127 [00:01<00:13,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  12%|█▏        | 15/127 [00:01<00:16,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  13%|█▎        | 17/127 [00:02<00:13,  8.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  15%|█▍        | 19/127 [00:02<00:14,  7.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  17%|█▋        | 21/127 [00:02<00:15,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  17%|█▋        | 22/127 [00:02<00:14,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  19%|█▉        | 24/127 [00:03<00:14,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  20%|█▉        | 25/127 [00:03<00:13,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  23%|██▎       | 29/127 [00:03<00:11,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  25%|██▌       | 32/127 [00:04<00:11,  8.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  27%|██▋       | 34/127 [00:04<00:11,  7.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  28%|██▊       | 35/127 [00:04<00:11,  8.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  29%|██▉       | 37/127 [00:04<00:12,  7.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  31%|███       | 39/127 [00:05<00:12,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  32%|███▏      | 41/127 [00:05<00:10,  8.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  35%|███▍      | 44/127 [00:05<00:10,  8.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  37%|███▋      | 47/127 [00:06<00:09,  8.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  38%|███▊      | 48/127 [00:06<00:11,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  39%|███▉      | 50/127 [00:06<00:09,  8.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  41%|████      | 52/127 [00:06<00:09,  7.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  43%|████▎     | 54/127 [00:07<00:10,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  44%|████▍     | 56/127 [00:07<00:08,  8.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  46%|████▋     | 59/127 [00:07<00:08,  8.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  47%|████▋     | 60/127 [00:07<00:09,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  48%|████▊     | 61/127 [00:08<00:08,  7.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  50%|█████     | 64/127 [00:08<00:08,  7.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  54%|█████▎    | 68/127 [00:08<00:07,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  56%|█████▌    | 71/127 [00:09<00:06,  8.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  58%|█████▊    | 74/127 [00:09<00:06,  8.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  60%|█████▉    | 76/127 [00:09<00:06,  7.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  62%|██████▏   | 79/127 [00:10<00:06,  7.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  64%|██████▍   | 81/127 [00:10<00:06,  7.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  65%|██████▌   | 83/127 [00:10<00:05,  8.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  68%|██████▊   | 86/127 [00:11<00:05,  8.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  70%|███████   | 89/127 [00:11<00:04,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  71%|███████   | 90/127 [00:11<00:05,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  72%|███████▏  | 92/127 [00:12<00:04,  8.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  74%|███████▍  | 94/127 [00:12<00:04,  7.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  76%|███████▌  | 96/127 [00:12<00:04,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  78%|███████▊  | 99/127 [00:13<00:04,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  79%|███████▊  | 100/127 [00:13<00:03,  7.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  82%|████████▏ | 104/127 [00:13<00:02,  8.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  83%|████████▎ | 106/127 [00:13<00:02,  7.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  87%|████████▋ | 110/127 [00:14<00:02,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  87%|████████▋ | 111/127 [00:14<00:02,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  88%|████████▊ | 112/127 [00:14<00:02,  7.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  90%|████████▉ | 114/127 [00:15<00:01,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  91%|█████████▏| 116/127 [00:15<00:01,  8.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  94%|█████████▎| 119/127 [00:15<00:00,  8.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  96%|█████████▌| 122/127 [00:16<00:00,  8.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  98%|█████████▊| 125/127 [00:16<00:00,  8.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label: 100%|██████████| 127/127 [00:16<00:00,  7.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "✅ Completed label: 127/127 files processed\n",
      "\n",
      "📁 Processing test split...\n",
      "🖼️  Processing T1: 348 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   0%|          | 1/348 [00:00<00:41,  8.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   1%|          | 2/348 [00:00<00:41,  8.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   1%|          | 4/348 [00:00<00:50,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   1%|▏         | 5/348 [00:00<00:48,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   2%|▏         | 7/348 [00:01<00:51,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   2%|▏         | 8/348 [00:01<00:49,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   3%|▎         | 10/348 [00:01<00:51,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   3%|▎         | 11/348 [00:01<00:48,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   4%|▎         | 13/348 [00:01<00:51,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   4%|▍         | 14/348 [00:02<00:48,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   5%|▍         | 16/348 [00:02<00:50,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   5%|▍         | 17/348 [00:02<00:47,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   5%|▌         | 19/348 [00:02<00:49,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   6%|▌         | 20/348 [00:03<00:46,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   6%|▋         | 22/348 [00:03<00:50,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   7%|▋         | 23/348 [00:03<00:47,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   7%|▋         | 25/348 [00:03<00:49,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   8%|▊         | 27/348 [00:04<00:52,  6.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   8%|▊         | 28/348 [00:04<00:48,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   8%|▊         | 29/348 [00:04<00:47,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   9%|▉         | 31/348 [00:04<00:49,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:   9%|▉         | 32/348 [00:04<00:46,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  10%|▉         | 34/348 [00:05<00:47,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  10%|█         | 35/348 [00:05<00:46,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  11%|█         | 37/348 [00:05<00:50,  6.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  11%|█         | 38/348 [00:05<00:49,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  11%|█▏        | 40/348 [00:06<00:53,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  12%|█▏        | 42/348 [00:06<00:52,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  12%|█▏        | 43/348 [00:06<00:47,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  13%|█▎        | 45/348 [00:07<00:50,  6.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  13%|█▎        | 46/348 [00:07<00:45,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  14%|█▎        | 47/348 [00:07<00:42,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  14%|█▍        | 49/348 [00:07<00:45,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  14%|█▍        | 50/348 [00:07<00:41,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  15%|█▍        | 52/348 [00:08<00:44,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  15%|█▌        | 53/348 [00:08<00:42,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  16%|█▌        | 55/348 [00:08<00:44,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  16%|█▋        | 57/348 [00:08<00:47,  6.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  17%|█▋        | 58/348 [00:08<00:43,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  17%|█▋        | 59/348 [00:09<00:41,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  18%|█▊        | 61/348 [00:09<00:43,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  18%|█▊        | 62/348 [00:09<00:41,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  18%|█▊        | 64/348 [00:09<00:44,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  19%|█▊        | 65/348 [00:10<00:43,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  19%|█▉        | 67/348 [00:10<00:44,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  20%|█▉        | 68/348 [00:10<00:41,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  20%|██        | 70/348 [00:10<00:42,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  20%|██        | 71/348 [00:10<00:39,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  21%|██        | 73/348 [00:11<00:43,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  22%|██▏       | 75/348 [00:11<00:44,  6.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  22%|██▏       | 76/348 [00:11<00:41,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  22%|██▏       | 77/348 [00:11<00:38,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  23%|██▎       | 79/348 [00:12<00:40,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  23%|██▎       | 80/348 [00:12<00:37,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  24%|██▎       | 82/348 [00:12<00:41,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  24%|██▍       | 83/348 [00:12<00:39,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  24%|██▍       | 85/348 [00:13<00:41,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  25%|██▌       | 87/348 [00:13<00:42,  6.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  25%|██▌       | 88/348 [00:13<00:39,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  26%|██▌       | 90/348 [00:13<00:41,  6.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  26%|██▌       | 91/348 [00:14<00:38,  6.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  26%|██▋       | 92/348 [00:14<00:36,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  27%|██▋       | 94/348 [00:14<00:37,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  27%|██▋       | 95/348 [00:14<00:37,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  28%|██▊       | 97/348 [00:15<00:39,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  28%|██▊       | 98/348 [00:15<00:37,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  29%|██▊       | 100/348 [00:15<00:38,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  29%|██▉       | 101/348 [00:15<00:35,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  30%|██▉       | 103/348 [00:15<00:38,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  30%|██▉       | 104/348 [00:16<00:36,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  30%|███       | 106/348 [00:16<00:37,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  31%|███       | 107/348 [00:16<00:35,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  31%|███▏      | 109/348 [00:16<00:37,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  32%|███▏      | 110/348 [00:17<00:35,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  32%|███▏      | 112/348 [00:17<00:36,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  32%|███▏      | 113/348 [00:17<00:33,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  33%|███▎      | 115/348 [00:17<00:35,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  33%|███▎      | 116/348 [00:17<00:33,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  34%|███▍      | 118/348 [00:18<00:36,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  34%|███▍      | 119/348 [00:18<00:33,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  35%|███▍      | 121/348 [00:18<00:35,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  35%|███▌      | 122/348 [00:18<00:32,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  36%|███▌      | 124/348 [00:19<00:34,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  36%|███▌      | 125/348 [00:19<00:32,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  36%|███▋      | 127/348 [00:19<00:34,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  37%|███▋      | 128/348 [00:19<00:31,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  37%|███▋      | 130/348 [00:20<00:33,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  38%|███▊      | 131/348 [00:20<00:31,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  38%|███▊      | 133/348 [00:20<00:32,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  39%|███▊      | 134/348 [00:20<00:30,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  39%|███▉      | 136/348 [00:21<00:32,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  40%|███▉      | 138/348 [00:21<00:34,  6.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  40%|███▉      | 139/348 [00:21<00:31,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  41%|████      | 141/348 [00:21<00:33,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  41%|████      | 142/348 [00:22<00:30,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  41%|████      | 143/348 [00:22<00:28,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  42%|████▏     | 145/348 [00:22<00:30,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  42%|████▏     | 146/348 [00:22<00:29,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  43%|████▎     | 148/348 [00:22<00:30,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  43%|████▎     | 149/348 [00:23<00:28,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  43%|████▎     | 151/348 [00:23<00:30,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  44%|████▎     | 152/348 [00:23<00:27,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  44%|████▍     | 154/348 [00:23<00:29,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  45%|████▍     | 155/348 [00:23<00:27,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  45%|████▌     | 157/348 [00:24<00:28,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  45%|████▌     | 158/348 [00:24<00:26,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  46%|████▌     | 160/348 [00:24<00:28,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  46%|████▋     | 161/348 [00:24<00:27,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  47%|████▋     | 163/348 [00:25<00:28,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  47%|████▋     | 164/348 [00:25<00:26,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  48%|████▊     | 166/348 [00:25<00:27,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  48%|████▊     | 167/348 [00:25<00:26,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  49%|████▊     | 169/348 [00:26<00:28,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  49%|████▉     | 170/348 [00:26<00:26,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  49%|████▉     | 172/348 [00:26<00:27,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  50%|████▉     | 173/348 [00:26<00:25,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  50%|█████     | 175/348 [00:27<00:26,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  51%|█████     | 177/348 [00:27<00:27,  6.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  51%|█████     | 178/348 [00:27<00:25,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  51%|█████▏    | 179/348 [00:27<00:24,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  52%|█████▏    | 181/348 [00:28<00:25,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  52%|█████▏    | 182/348 [00:28<00:24,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  53%|█████▎    | 184/348 [00:28<00:25,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  53%|█████▎    | 185/348 [00:28<00:23,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  54%|█████▎    | 187/348 [00:28<00:24,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  54%|█████▍    | 189/348 [00:29<00:25,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  55%|█████▍    | 190/348 [00:29<00:23,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  55%|█████▌    | 192/348 [00:29<00:24,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  55%|█████▌    | 193/348 [00:29<00:23,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  56%|█████▌    | 194/348 [00:29<00:22,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  56%|█████▋    | 196/348 [00:30<00:23,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  57%|█████▋    | 197/348 [00:30<00:21,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  57%|█████▋    | 199/348 [00:30<00:22,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  57%|█████▋    | 200/348 [00:30<00:20,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  58%|█████▊    | 202/348 [00:31<00:22,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  58%|█████▊    | 203/348 [00:31<00:20,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  59%|█████▉    | 205/348 [00:31<00:22,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  59%|█████▉    | 206/348 [00:31<00:20,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  60%|█████▉    | 208/348 [00:32<00:21,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  60%|██████    | 209/348 [00:32<00:20,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  61%|██████    | 211/348 [00:32<00:21,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  61%|██████    | 212/348 [00:32<00:19,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  61%|██████▏   | 214/348 [00:33<00:20,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  62%|██████▏   | 215/348 [00:33<00:19,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  62%|██████▏   | 217/348 [00:33<00:19,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  63%|██████▎   | 219/348 [00:33<00:20,  6.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  63%|██████▎   | 220/348 [00:33<00:19,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  64%|██████▎   | 221/348 [00:34<00:18,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  64%|██████▍   | 223/348 [00:34<00:19,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  64%|██████▍   | 224/348 [00:34<00:17,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  65%|██████▍   | 226/348 [00:34<00:18,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  65%|██████▌   | 227/348 [00:35<00:17,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  66%|██████▌   | 229/348 [00:35<00:18,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  66%|██████▌   | 230/348 [00:35<00:17,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  67%|██████▋   | 232/348 [00:35<00:18,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  67%|██████▋   | 233/348 [00:36<00:17,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  68%|██████▊   | 235/348 [00:36<00:22,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  68%|██████▊   | 237/348 [00:36<00:20,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  68%|██████▊   | 238/348 [00:37<00:18,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  69%|██████▊   | 239/348 [00:37<00:17,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  69%|██████▉   | 241/348 [00:37<00:17,  6.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  70%|██████▉   | 242/348 [00:37<00:16,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  70%|███████   | 244/348 [00:37<00:16,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  71%|███████   | 246/348 [00:38<00:16,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  71%|███████   | 247/348 [00:38<00:15,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  71%|███████▏  | 248/348 [00:38<00:14,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  72%|███████▏  | 250/348 [00:38<00:14,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  72%|███████▏  | 251/348 [00:38<00:13,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  73%|███████▎  | 253/348 [00:39<00:14,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  73%|███████▎  | 254/348 [00:39<00:13,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  74%|███████▎  | 256/348 [00:39<00:14,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  74%|███████▍  | 257/348 [00:39<00:13,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  74%|███████▍  | 259/348 [00:40<00:13,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  75%|███████▍  | 260/348 [00:40<00:12,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  75%|███████▌  | 262/348 [00:40<00:13,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  76%|███████▌  | 263/348 [00:40<00:12,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  76%|███████▌  | 265/348 [00:41<00:12,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  76%|███████▋  | 266/348 [00:41<00:11,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  77%|███████▋  | 268/348 [00:41<00:12,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  77%|███████▋  | 269/348 [00:41<00:11,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  78%|███████▊  | 271/348 [00:42<00:11,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  78%|███████▊  | 272/348 [00:42<00:10,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  79%|███████▊  | 274/348 [00:42<00:11,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  79%|███████▉  | 275/348 [00:42<00:10,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  80%|███████▉  | 277/348 [00:43<00:11,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  80%|████████  | 279/348 [00:43<00:11,  6.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  80%|████████  | 280/348 [00:43<00:10,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  81%|████████  | 281/348 [00:43<00:09,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  81%|████████▏ | 283/348 [00:43<00:09,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  82%|████████▏ | 285/348 [00:44<00:10,  6.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  82%|████████▏ | 286/348 [00:44<00:09,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  82%|████████▏ | 287/348 [00:44<00:08,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  83%|████████▎ | 289/348 [00:44<00:09,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  83%|████████▎ | 290/348 [00:45<00:08,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  84%|████████▍ | 292/348 [00:45<00:08,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  84%|████████▍ | 294/348 [00:45<00:08,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  85%|████████▍ | 295/348 [00:45<00:08,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  85%|████████▌ | 296/348 [00:45<00:07,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  86%|████████▌ | 298/348 [00:46<00:07,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  86%|████████▌ | 299/348 [00:46<00:07,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  86%|████████▋ | 301/348 [00:46<00:07,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  87%|████████▋ | 302/348 [00:46<00:06,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  87%|████████▋ | 304/348 [00:47<00:06,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  88%|████████▊ | 305/348 [00:47<00:06,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  88%|████████▊ | 307/348 [00:47<00:06,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  89%|████████▊ | 308/348 [00:47<00:05,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  89%|████████▉ | 310/348 [00:48<00:05,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  89%|████████▉ | 311/348 [00:48<00:05,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  90%|████████▉ | 313/348 [00:48<00:05,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  90%|█████████ | 314/348 [00:48<00:04,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  91%|█████████ | 316/348 [00:49<00:04,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  91%|█████████▏| 318/348 [00:49<00:04,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  92%|█████████▏| 319/348 [00:49<00:04,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  92%|█████████▏| 320/348 [00:49<00:04,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  93%|█████████▎| 322/348 [00:50<00:04,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  93%|█████████▎| 324/348 [00:50<00:03,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  93%|█████████▎| 325/348 [00:50<00:03,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  94%|█████████▎| 326/348 [00:50<00:03,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  94%|█████████▍| 328/348 [00:50<00:03,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  95%|█████████▍| 329/348 [00:51<00:02,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  95%|█████████▌| 331/348 [00:51<00:02,  6.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  95%|█████████▌| 332/348 [00:51<00:02,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  96%|█████████▌| 334/348 [00:51<00:02,  6.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  96%|█████████▋| 335/348 [00:52<00:01,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  97%|█████████▋| 337/348 [00:52<00:01,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  97%|█████████▋| 339/348 [00:52<00:01,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  98%|█████████▊| 340/348 [00:52<00:01,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  98%|█████████▊| 341/348 [00:52<00:00,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  99%|█████████▊| 343/348 [00:53<00:00,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  99%|█████████▉| 344/348 [00:53<00:00,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1:  99%|█████████▉| 346/348 [00:53<00:00,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1: 100%|█████████▉| 347/348 [00:53<00:00,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T1: 100%|██████████| 348/348 [00:54<00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed T1: 348/348 files processed\n",
      "🖼️  Processing T2: 348 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   0%|          | 0/348 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   0%|          | 1/348 [00:00<00:42,  8.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   1%|          | 2/348 [00:00<00:42,  8.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   1%|          | 4/348 [00:00<00:51,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   1%|▏         | 5/348 [00:00<00:48,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   2%|▏         | 7/348 [00:01<00:53,  6.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   2%|▏         | 8/348 [00:01<00:50,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   3%|▎         | 10/348 [00:01<00:51,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   3%|▎         | 11/348 [00:01<00:48,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   4%|▎         | 13/348 [00:02<00:53,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   4%|▍         | 14/348 [00:02<00:49,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   5%|▍         | 16/348 [00:02<00:52,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   5%|▍         | 17/348 [00:02<00:48,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   5%|▌         | 19/348 [00:02<00:50,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   6%|▌         | 20/348 [00:03<00:46,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   6%|▋         | 22/348 [00:03<00:50,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   7%|▋         | 24/348 [00:03<00:53,  6.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   7%|▋         | 25/348 [00:03<00:49,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   8%|▊         | 27/348 [00:04<00:52,  6.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   8%|▊         | 28/348 [00:04<00:47,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   8%|▊         | 29/348 [00:04<00:45,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   9%|▉         | 31/348 [00:04<00:47,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:   9%|▉         | 32/348 [00:04<00:45,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  10%|▉         | 34/348 [00:05<00:48,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  10%|█         | 35/348 [00:05<00:45,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  11%|█         | 37/348 [00:05<00:47,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  11%|█         | 38/348 [00:05<00:44,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  11%|█▏        | 40/348 [00:06<00:50,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  12%|█▏        | 42/348 [00:06<00:51,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  12%|█▏        | 43/348 [00:06<00:47,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  13%|█▎        | 44/348 [00:06<00:44,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  13%|█▎        | 46/348 [00:07<00:47,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  14%|█▎        | 47/348 [00:07<00:44,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  14%|█▍        | 49/348 [00:07<00:47,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  14%|█▍        | 50/348 [00:07<00:44,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  15%|█▍        | 52/348 [00:08<00:45,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  15%|█▌        | 53/348 [00:08<00:43,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  16%|█▌        | 55/348 [00:08<00:45,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  16%|█▌        | 56/348 [00:08<00:42,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  17%|█▋        | 58/348 [00:09<00:45,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  17%|█▋        | 59/348 [00:09<00:42,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  18%|█▊        | 61/348 [00:09<00:44,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  18%|█▊        | 62/348 [00:09<00:42,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  18%|█▊        | 64/348 [00:10<00:45,  6.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  19%|█▊        | 65/348 [00:10<00:42,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  19%|█▉        | 67/348 [00:10<00:43,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  20%|█▉        | 68/348 [00:10<00:40,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  20%|██        | 70/348 [00:10<00:43,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  20%|██        | 71/348 [00:11<00:39,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  21%|██        | 73/348 [00:11<00:43,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  21%|██▏       | 74/348 [00:11<00:40,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  22%|██▏       | 76/348 [00:11<00:44,  6.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  22%|██▏       | 77/348 [00:12<00:41,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  23%|██▎       | 79/348 [00:12<00:44,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  23%|██▎       | 80/348 [00:12<00:40,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  24%|██▎       | 82/348 [00:12<00:42,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  24%|██▍       | 83/348 [00:13<00:39,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  24%|██▍       | 85/348 [00:13<00:41,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  25%|██▍       | 86/348 [00:13<00:38,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  25%|██▌       | 88/348 [00:13<00:41,  6.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  26%|██▌       | 89/348 [00:13<00:38,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  26%|██▌       | 91/348 [00:14<00:39,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  27%|██▋       | 93/348 [00:14<00:41,  6.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  27%|██▋       | 94/348 [00:14<00:37,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  28%|██▊       | 96/348 [00:15<00:40,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  28%|██▊       | 97/348 [00:15<00:37,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  28%|██▊       | 98/348 [00:15<00:35,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  29%|██▊       | 100/348 [00:15<00:37,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  29%|██▉       | 101/348 [00:15<00:35,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  30%|██▉       | 103/348 [00:16<00:38,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  30%|███       | 105/348 [00:16<00:39,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  30%|███       | 106/348 [00:16<00:37,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  31%|███       | 107/348 [00:16<00:34,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  31%|███▏      | 109/348 [00:17<00:36,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  32%|███▏      | 110/348 [00:17<00:34,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  32%|███▏      | 112/348 [00:17<00:36,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  32%|███▏      | 113/348 [00:17<00:33,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  33%|███▎      | 115/348 [00:17<00:35,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  33%|███▎      | 116/348 [00:18<00:33,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  34%|███▍      | 118/348 [00:18<00:35,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  34%|███▍      | 119/348 [00:18<00:33,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  35%|███▍      | 121/348 [00:18<00:34,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  35%|███▌      | 122/348 [00:19<00:32,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  36%|███▌      | 124/348 [00:19<00:34,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  36%|███▌      | 125/348 [00:19<00:32,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  36%|███▋      | 127/348 [00:19<00:34,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  37%|███▋      | 128/348 [00:19<00:31,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  37%|███▋      | 130/348 [00:20<00:33,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  38%|███▊      | 131/348 [00:20<00:31,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  38%|███▊      | 133/348 [00:20<00:33,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  39%|███▊      | 134/348 [00:20<00:30,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  39%|███▉      | 136/348 [00:21<00:32,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  39%|███▉      | 137/348 [00:21<00:30,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  40%|███▉      | 139/348 [00:21<00:32,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  40%|████      | 140/348 [00:21<00:31,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  41%|████      | 142/348 [00:22<00:32,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  41%|████      | 143/348 [00:22<00:29,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  42%|████▏     | 145/348 [00:22<00:31,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  42%|████▏     | 146/348 [00:22<00:29,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  43%|████▎     | 148/348 [00:23<00:30,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  43%|████▎     | 150/348 [00:23<00:32,  6.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  43%|████▎     | 151/348 [00:23<00:29,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  44%|████▎     | 152/348 [00:23<00:27,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  44%|████▍     | 154/348 [00:24<00:30,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  45%|████▍     | 155/348 [00:24<00:28,  6.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  45%|████▌     | 157/348 [00:24<00:29,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  45%|████▌     | 158/348 [00:24<00:27,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  46%|████▌     | 160/348 [00:24<00:29,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  47%|████▋     | 162/348 [00:25<00:30,  6.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  47%|████▋     | 163/348 [00:25<00:27,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  47%|████▋     | 164/348 [00:25<00:26,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  48%|████▊     | 166/348 [00:25<00:27,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  48%|████▊     | 167/348 [00:26<00:26,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  49%|████▊     | 169/348 [00:26<00:27,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  49%|████▉     | 170/348 [00:26<00:26,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  49%|████▉     | 172/348 [00:26<00:28,  6.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  50%|████▉     | 173/348 [00:26<00:26,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  50%|█████     | 175/348 [00:27<00:27,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  51%|█████     | 176/348 [00:27<00:25,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  51%|█████     | 178/348 [00:27<00:26,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  51%|█████▏    | 179/348 [00:27<00:24,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  52%|█████▏    | 181/348 [00:28<00:25,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  52%|█████▏    | 182/348 [00:28<00:24,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  53%|█████▎    | 184/348 [00:28<00:25,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  53%|█████▎    | 185/348 [00:28<00:23,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  54%|█████▎    | 187/348 [00:29<00:24,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  54%|█████▍    | 188/348 [00:29<00:22,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  55%|█████▍    | 190/348 [00:29<00:24,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  55%|█████▍    | 191/348 [00:29<00:23,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  55%|█████▌    | 193/348 [00:30<00:25,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  56%|█████▌    | 194/348 [00:30<00:23,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  56%|█████▋    | 196/348 [00:30<00:24,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  57%|█████▋    | 197/348 [00:30<00:22,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  57%|█████▋    | 199/348 [00:31<00:23,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  57%|█████▋    | 200/348 [00:31<00:21,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  58%|█████▊    | 202/348 [00:31<00:22,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  58%|█████▊    | 203/348 [00:31<00:20,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  59%|█████▉    | 205/348 [00:32<00:24,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  59%|█████▉    | 206/348 [00:32<00:23,  6.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  60%|█████▉    | 208/348 [00:32<00:23,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  60%|██████    | 209/348 [00:32<00:22,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  61%|██████    | 211/348 [00:33<00:22,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  61%|██████    | 212/348 [00:33<00:20,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  61%|██████▏   | 214/348 [00:33<00:21,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  62%|██████▏   | 215/348 [00:33<00:19,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  62%|██████▏   | 217/348 [00:34<00:20,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  63%|██████▎   | 218/348 [00:34<00:18,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  63%|██████▎   | 220/348 [00:34<00:19,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  64%|██████▎   | 221/348 [00:34<00:18,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  64%|██████▍   | 223/348 [00:34<00:19,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  64%|██████▍   | 224/348 [00:35<00:17,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  65%|██████▍   | 226/348 [00:35<00:18,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  65%|██████▌   | 227/348 [00:35<00:17,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  66%|██████▌   | 229/348 [00:35<00:18,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  66%|██████▋   | 231/348 [00:36<00:19,  6.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  67%|██████▋   | 232/348 [00:36<00:17,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  67%|██████▋   | 233/348 [00:36<00:16,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  68%|██████▊   | 235/348 [00:36<00:17,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  68%|██████▊   | 236/348 [00:36<00:16,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  68%|██████▊   | 238/348 [00:37<00:16,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  69%|██████▊   | 239/348 [00:37<00:15,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  69%|██████▉   | 241/348 [00:37<00:16,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  70%|██████▉   | 243/348 [00:38<00:17,  6.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  70%|███████   | 244/348 [00:38<00:15,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  70%|███████   | 245/348 [00:38<00:14,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  71%|███████   | 247/348 [00:38<00:15,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  71%|███████▏  | 248/348 [00:38<00:14,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  72%|███████▏  | 250/348 [00:39<00:14,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  72%|███████▏  | 251/348 [00:39<00:13,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  73%|███████▎  | 253/348 [00:39<00:14,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  73%|███████▎  | 254/348 [00:39<00:13,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  74%|███████▎  | 256/348 [00:40<00:14,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  74%|███████▍  | 257/348 [00:40<00:13,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  74%|███████▍  | 259/348 [00:40<00:13,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  75%|███████▍  | 260/348 [00:40<00:12,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  75%|███████▌  | 262/348 [00:41<00:13,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  76%|███████▌  | 263/348 [00:41<00:12,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  76%|███████▌  | 265/348 [00:41<00:12,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  76%|███████▋  | 266/348 [00:41<00:11,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  77%|███████▋  | 268/348 [00:41<00:13,  6.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  78%|███████▊  | 270/348 [00:42<00:13,  5.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  78%|███████▊  | 271/348 [00:42<00:11,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  78%|███████▊  | 272/348 [00:42<00:11,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  79%|███████▊  | 274/348 [00:42<00:11,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  79%|███████▉  | 275/348 [00:43<00:10,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  80%|███████▉  | 277/348 [00:43<00:11,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  80%|███████▉  | 278/348 [00:43<00:10,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  80%|████████  | 280/348 [00:43<00:10,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  81%|████████  | 281/348 [00:43<00:09,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  81%|████████▏ | 283/348 [00:44<00:09,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  82%|████████▏ | 284/348 [00:44<00:09,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  82%|████████▏ | 286/348 [00:44<00:09,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  82%|████████▏ | 287/348 [00:44<00:08,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  83%|████████▎ | 289/348 [00:45<00:09,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  83%|████████▎ | 290/348 [00:45<00:08,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  84%|████████▍ | 292/348 [00:45<00:08,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  84%|████████▍ | 293/348 [00:45<00:08,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  85%|████████▍ | 295/348 [00:46<00:08,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  85%|████████▌ | 296/348 [00:46<00:07,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  86%|████████▌ | 298/348 [00:46<00:07,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  86%|████████▌ | 299/348 [00:46<00:07,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  86%|████████▋ | 301/348 [00:47<00:07,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  87%|████████▋ | 302/348 [00:47<00:06,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  87%|████████▋ | 304/348 [00:47<00:06,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  88%|████████▊ | 305/348 [00:47<00:06,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  88%|████████▊ | 307/348 [00:48<00:06,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  89%|████████▊ | 308/348 [00:48<00:05,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  89%|████████▉ | 310/348 [00:48<00:05,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  89%|████████▉ | 311/348 [00:48<00:05,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  90%|████████▉ | 313/348 [00:48<00:05,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  90%|█████████ | 314/348 [00:49<00:04,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  91%|█████████ | 316/348 [00:49<00:04,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  91%|█████████ | 317/348 [00:49<00:04,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  92%|█████████▏| 319/348 [00:49<00:04,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  92%|█████████▏| 320/348 [00:50<00:04,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  93%|█████████▎| 322/348 [00:50<00:04,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  93%|█████████▎| 323/348 [00:50<00:03,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  93%|█████████▎| 325/348 [00:50<00:03,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  94%|█████████▎| 326/348 [00:50<00:03,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  94%|█████████▍| 328/348 [00:51<00:03,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  95%|█████████▍| 329/348 [00:51<00:02,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  95%|█████████▌| 331/348 [00:51<00:02,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  95%|█████████▌| 332/348 [00:51<00:02,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  96%|█████████▌| 334/348 [00:52<00:02,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  96%|█████████▋| 335/348 [00:52<00:01,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  97%|█████████▋| 337/348 [00:52<00:01,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  97%|█████████▋| 339/348 [00:53<00:01,  6.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  98%|█████████▊| 340/348 [00:53<00:01,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  98%|█████████▊| 341/348 [00:53<00:01,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  99%|█████████▊| 343/348 [00:53<00:00,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  99%|█████████▉| 344/348 [00:53<00:00,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2:  99%|█████████▉| 346/348 [00:54<00:00,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2: 100%|█████████▉| 347/348 [00:54<00:00,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing T2: 100%|██████████| 348/348 [00:54<00:00,  6.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed T2: 348/348 files processed\n",
      "🖼️  Processing label: 348 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   0%|          | 1/348 [00:00<00:34,  9.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   1%|          | 3/348 [00:00<00:45,  7.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   1%|▏         | 5/348 [00:00<00:39,  8.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   2%|▏         | 8/348 [00:00<00:40,  8.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   3%|▎         | 11/348 [00:01<00:40,  8.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   4%|▎         | 13/348 [00:01<00:42,  7.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   5%|▍         | 17/348 [00:02<00:40,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   6%|▌         | 20/348 [00:02<00:39,  8.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   6%|▌         | 21/348 [00:02<00:45,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   7%|▋         | 23/348 [00:02<00:39,  8.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   7%|▋         | 26/348 [00:03<00:39,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   8%|▊         | 27/348 [00:03<00:46,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   8%|▊         | 29/348 [00:03<00:38,  8.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   9%|▉         | 31/348 [00:04<00:41,  7.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:   9%|▉         | 33/348 [00:04<00:43,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  10%|█         | 35/348 [00:04<00:38,  8.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  11%|█         | 37/348 [00:04<00:40,  7.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  11%|█▏        | 40/348 [00:05<00:40,  7.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  12%|█▏        | 42/348 [00:05<00:42,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  12%|█▏        | 43/348 [00:05<00:39,  7.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  14%|█▎        | 47/348 [00:06<00:36,  8.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  14%|█▍        | 49/348 [00:06<00:38,  7.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  15%|█▍        | 51/348 [00:06<00:42,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  15%|█▌        | 53/348 [00:06<00:36,  8.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  16%|█▌        | 55/348 [00:07<00:41,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  16%|█▋        | 57/348 [00:07<00:42,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  17%|█▋        | 59/348 [00:07<00:35,  8.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  18%|█▊        | 62/348 [00:08<00:35,  8.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  18%|█▊        | 63/348 [00:08<00:41,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  19%|█▊        | 65/348 [00:08<00:35,  8.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  19%|█▉        | 67/348 [00:08<00:37,  7.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  20%|█▉        | 69/348 [00:09<00:39,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  20%|██        | 71/348 [00:09<00:33,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  21%|██▏       | 74/348 [00:09<00:33,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  22%|██▏       | 77/348 [00:10<00:33,  8.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  22%|██▏       | 78/348 [00:10<00:37,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  23%|██▎       | 80/348 [00:10<00:33,  8.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  24%|██▍       | 83/348 [00:10<00:32,  8.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  24%|██▍       | 84/348 [00:11<00:38,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  24%|██▍       | 85/348 [00:11<00:35,  7.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  25%|██▌       | 87/348 [00:11<00:37,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  25%|██▌       | 88/348 [00:11<00:34,  7.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  26%|██▋       | 92/348 [00:12<00:31,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  27%|██▋       | 93/348 [00:12<00:36,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  27%|██▋       | 95/348 [00:12<00:31,  8.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  28%|██▊       | 98/348 [00:12<00:31,  8.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  28%|██▊       | 99/348 [00:13<00:34,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  29%|██▉       | 101/348 [00:13<00:30,  8.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  30%|██▉       | 104/348 [00:13<00:29,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  30%|███       | 106/348 [00:14<00:33,  7.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  31%|███       | 108/348 [00:14<00:35,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  32%|███▏      | 110/348 [00:14<00:29,  8.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  32%|███▏      | 112/348 [00:14<00:31,  7.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  33%|███▎      | 114/348 [00:15<00:33,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  33%|███▎      | 116/348 [00:15<00:28,  8.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  34%|███▍      | 119/348 [00:15<00:28,  8.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  34%|███▍      | 120/348 [00:15<00:32,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  35%|███▌      | 122/348 [00:16<00:27,  8.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  36%|███▌      | 125/348 [00:16<00:27,  8.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  36%|███▌      | 126/348 [00:16<00:31,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  37%|███▋      | 128/348 [00:16<00:26,  8.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  37%|███▋      | 130/348 [00:17<00:30,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  38%|███▊      | 132/348 [00:17<00:32,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  39%|███▊      | 134/348 [00:17<00:26,  8.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  39%|███▉      | 136/348 [00:18<00:27,  7.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  40%|███▉      | 138/348 [00:18<00:30,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  40%|████      | 140/348 [00:18<00:25,  8.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  41%|████      | 143/348 [00:18<00:25,  8.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  41%|████▏     | 144/348 [00:19<00:29,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  42%|████▏     | 146/348 [00:19<00:24,  8.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  43%|████▎     | 149/348 [00:19<00:24,  8.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  43%|████▎     | 150/348 [00:19<00:28,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  44%|████▎     | 152/348 [00:20<00:23,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  44%|████▍     | 154/348 [00:20<00:24,  7.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  45%|████▌     | 158/348 [00:20<00:23,  8.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  46%|████▋     | 161/348 [00:21<00:22,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  47%|████▋     | 164/348 [00:21<00:22,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  48%|████▊     | 166/348 [00:21<00:23,  7.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  48%|████▊     | 168/348 [00:22<00:25,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  49%|████▉     | 170/348 [00:22<00:22,  8.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  50%|████▉     | 173/348 [00:22<00:21,  8.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  50%|█████     | 174/348 [00:23<00:25,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  51%|█████     | 176/348 [00:23<00:21,  8.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  51%|█████▏    | 179/348 [00:23<00:20,  8.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  52%|█████▏    | 181/348 [00:23<00:21,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  53%|█████▎    | 183/348 [00:24<00:22,  7.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  53%|█████▎    | 184/348 [00:24<00:21,  7.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  54%|█████▍    | 188/348 [00:24<00:19,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  55%|█████▍    | 190/348 [00:25<00:20,  7.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  56%|█████▌    | 194/348 [00:25<00:18,  8.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  56%|█████▌    | 195/348 [00:25<00:21,  7.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  57%|█████▋    | 197/348 [00:25<00:18,  8.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  57%|█████▋    | 200/348 [00:26<00:18,  8.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  58%|█████▊    | 201/348 [00:26<00:21,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  58%|█████▊    | 203/348 [00:26<00:17,  8.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  59%|█████▉    | 205/348 [00:27<00:19,  7.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  59%|█████▉    | 207/348 [00:27<00:21,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  60%|█████▉    | 208/348 [00:27<00:19,  7.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  61%|██████    | 211/348 [00:27<00:18,  7.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  61%|██████    | 213/348 [00:28<00:19,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  62%|██████▏   | 215/348 [00:28<00:16,  8.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  63%|██████▎   | 218/348 [00:28<00:15,  8.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  63%|██████▎   | 219/348 [00:29<00:18,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  64%|██████▎   | 221/348 [00:29<00:15,  8.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  64%|██████▍   | 224/348 [00:29<00:15,  8.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  65%|██████▍   | 225/348 [00:29<00:18,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  65%|██████▍   | 226/348 [00:29<00:16,  7.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  66%|██████▌   | 228/348 [00:30<00:17,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  66%|██████▌   | 230/348 [00:30<00:14,  8.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  67%|██████▋   | 232/348 [00:30<00:15,  7.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  68%|██████▊   | 235/348 [00:31<00:14,  7.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  68%|██████▊   | 238/348 [00:31<00:14,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  70%|██████▉   | 242/348 [00:32<00:12,  8.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  70%|██████▉   | 243/348 [00:32<00:14,  7.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  70%|███████   | 245/348 [00:32<00:12,  8.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  71%|███████▏  | 248/348 [00:32<00:12,  8.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  72%|███████▏  | 251/348 [00:33<00:11,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  73%|███████▎  | 254/348 [00:33<00:11,  8.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  74%|███████▍  | 257/348 [00:33<00:11,  8.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  75%|███████▍  | 260/348 [00:34<00:10,  8.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  75%|███████▌  | 261/348 [00:34<00:12,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  75%|███████▌  | 262/348 [00:34<00:11,  7.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  76%|███████▋  | 266/348 [00:35<00:09,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  77%|███████▋  | 267/348 [00:35<00:11,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  77%|███████▋  | 269/348 [00:35<00:09,  8.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  78%|███████▊  | 272/348 [00:35<00:09,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  78%|███████▊  | 273/348 [00:36<00:10,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  79%|███████▉  | 275/348 [00:36<00:08,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  80%|███████▉  | 277/348 [00:36<00:09,  7.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  80%|████████  | 279/348 [00:36<00:09,  7.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  81%|████████  | 281/348 [00:37<00:08,  8.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  82%|████████▏ | 284/348 [00:37<00:08,  7.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  82%|████████▏ | 285/348 [00:37<00:09,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  82%|████████▏ | 287/348 [00:37<00:07,  7.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  83%|████████▎ | 289/348 [00:38<00:08,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  84%|████████▎ | 291/348 [00:38<00:08,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  84%|████████▍ | 293/348 [00:38<00:07,  7.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  85%|████████▌ | 296/348 [00:39<00:06,  8.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  85%|████████▌ | 297/348 [00:39<00:07,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  86%|████████▌ | 298/348 [00:39<00:06,  7.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  86%|████████▋ | 301/348 [00:39<00:06,  7.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  87%|████████▋ | 303/348 [00:40<00:06,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  88%|████████▊ | 305/348 [00:40<00:05,  8.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  88%|████████▊ | 307/348 [00:40<00:05,  7.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  89%|████████▉ | 311/348 [00:41<00:04,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  90%|████████▉ | 312/348 [00:41<00:05,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  90%|█████████ | 314/348 [00:41<00:04,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  91%|█████████ | 316/348 [00:41<00:04,  7.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  92%|█████████▏| 320/348 [00:42<00:03,  8.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  92%|█████████▏| 321/348 [00:42<00:03,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  93%|█████████▎| 323/348 [00:42<00:03,  8.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  93%|█████████▎| 325/348 [00:43<00:03,  7.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  94%|█████████▍| 327/348 [00:43<00:03,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  95%|█████████▍| 329/348 [00:43<00:02,  8.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  95%|█████████▌| 332/348 [00:43<00:01,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  96%|█████████▌| 333/348 [00:44<00:02,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  96%|█████████▋| 335/348 [00:44<00:01,  8.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  97%|█████████▋| 338/348 [00:44<00:01,  8.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  97%|█████████▋| 339/348 [00:44<00:01,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  98%|█████████▊| 341/348 [00:45<00:00,  8.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label:  99%|█████████▊| 343/348 [00:45<00:00,  7.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label: 100%|█████████▉| 347/348 [00:45<00:00,  8.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch T4 Processing label: 100%|██████████| 348/348 [00:46<00:00,  7.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ PyTorch T4 Processing scale 1.0: 1x1 patches\n",
      "🚀 PyTorch T4 Dual-GPU processing 1 patches...\n",
      "💾 Saving 1 patches...\n",
      "✅ Completed label: 348/348 files processed\n",
      "🎉 PyTorch T4 processing completed successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "import numpy as np\n",
    "import socket\n",
    "from PIL import Image\n",
    "import glob\n",
    "import argparse\n",
    "import tqdm\n",
    "import gc\n",
    "import threading\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn.functional as F\n",
    "    GPU_AVAILABLE = torch.cuda.is_available()\n",
    "    if GPU_AVAILABLE:\n",
    "        print(f\"✅ PyTorch GPU available\")\n",
    "        print(f\"🔢 Number of GPUs detected: {torch.cuda.device_count()}\")\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            gpu_name = torch.cuda.get_device_name(i)\n",
    "            gpu_memory = torch.cuda.get_device_properties(i).total_memory / (1024**3)\n",
    "            print(f\"🖥️  GPU {i}: {gpu_name} ({gpu_memory:.1f}GB)\")\n",
    "    else:\n",
    "        print(\"⚠️ PyTorch available but no GPU detected\")\n",
    "except ImportError:\n",
    "    GPU_AVAILABLE = False\n",
    "    print(\"⚠️ PyTorch not available. Install with: pip install torch\")\n",
    "\n",
    "try:\n",
    "    from osgeo import gdal, gdal_array\n",
    "    GDAL_AVAILABLE = True\n",
    "except ImportError:\n",
    "    GDAL_AVAILABLE = False\n",
    "    print(\"Warning: GDAL not available. Only PNG/JPG processing will work.\")\n",
    "\n",
    "# Multi-scale factors for slicing\n",
    "multiScale = [1.0]\n",
    "\n",
    "# T4 optimized settings\n",
    "T4_OPTIMAL_BATCH_SIZE = 32  # Optimized for T4's memory bandwidth\n",
    "T4_MAX_IMAGE_SIZE = 4096    # Maximum image size to process in single GPU operation\n",
    "\n",
    "def setup_gpu_devices():\n",
    "    \"\"\"Setup and configure available GPUs\"\"\"\n",
    "    if not GPU_AVAILABLE:\n",
    "        return []\n",
    "    \n",
    "    devices = []\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        gpu_props = torch.cuda.get_device_properties(i)\n",
    "        \n",
    "        # Get memory info\n",
    "        torch.cuda.set_device(i)\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        total_memory = gpu_props.total_memory / (1024**3)  # GB\n",
    "        allocated_memory = torch.cuda.memory_allocated(i) / (1024**3)  # GB\n",
    "        free_memory = total_memory - allocated_memory\n",
    "        \n",
    "        devices.append({\n",
    "            'id': i,\n",
    "            'name': gpu_props.name,\n",
    "            'free_memory': free_memory,\n",
    "            'total_memory': total_memory,\n",
    "            'compute_capability': f\"{gpu_props.major}.{gpu_props.minor}\"\n",
    "        })\n",
    "        \n",
    "        print(f\"🖥️  GPU {i}: {gpu_props.name}\")\n",
    "        print(f\"   💾 Memory: {free_memory:.1f}GB free / {total_memory:.1f}GB total\")\n",
    "        print(f\"   🔧 Compute Capability: {gpu_props.major}.{gpu_props.minor}\")\n",
    "    \n",
    "    return devices\n",
    "\n",
    "def clear_gpu_memory(device_id=None):\n",
    "    \"\"\"Clear GPU memory to prevent OOM errors\"\"\"\n",
    "    if GPU_AVAILABLE:\n",
    "        if device_id is not None:\n",
    "            torch.cuda.set_device(device_id)\n",
    "            torch.cuda.empty_cache()\n",
    "        else:\n",
    "            # Clear all devices\n",
    "            for i in range(torch.cuda.device_count()):\n",
    "                torch.cuda.set_device(i)\n",
    "                torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "def writeTiff(im_data, path, im_bands, im_height, im_width, im_geotrans, im_proj):\n",
    "    \"\"\"\n",
    "    Write image data to TIFF format\n",
    "    Note: This function requires GDAL which may not be available in Kaggle\n",
    "    \"\"\"\n",
    "    if not GDAL_AVAILABLE:\n",
    "        raise ImportError(\"GDAL is required for TIFF operations but not available\")\n",
    "    \n",
    "    # Convert from GPU to CPU if needed\n",
    "    if GPU_AVAILABLE and torch.is_tensor(im_data):\n",
    "        im_data = im_data.cpu().numpy()\n",
    "    \n",
    "    if 'int8' in im_data.dtype.name:\n",
    "        datatype = gdal.GDT_Byte\n",
    "    elif 'int16' in im_data.dtype.name:\n",
    "        datatype = gdal.GDT_UInt16\n",
    "    elif 'int32' in im_data.dtype.name:\n",
    "        datatype = gdal.GDT_UInt32\n",
    "    else:\n",
    "        datatype = gdal.GDT_Float32\n",
    "    \n",
    "    if len(im_data.shape) == 3:\n",
    "        im_bands, im_height, im_width = im_data.shape\n",
    "    elif len(im_data.shape) == 2:\n",
    "        im_data = np.array([im_data])\n",
    "    else:\n",
    "        im_bands, (im_height, im_width) = 1, im_data.shape\n",
    "    \n",
    "    # Create file\n",
    "    driver = gdal.GetDriverByName(\"GTiff\")\n",
    "    dataset = driver.Create(path, im_width, im_height, 1, datatype)\n",
    "    \n",
    "    if dataset is not None:\n",
    "        dataset.SetGeoTransform(im_geotrans)\n",
    "        dataset.SetProjection(im_proj)\n",
    "        for i in range(im_bands):\n",
    "            dataset.GetRasterBand(i + 1).WriteArray(im_data[i])\n",
    "    del dataset\n",
    "\n",
    "def readTiff(filename):\n",
    "    \"\"\"\n",
    "    Read TIFF image file\n",
    "    Note: This function requires GDAL which may not be available in Kaggle\n",
    "    \"\"\"\n",
    "    if not GDAL_AVAILABLE:\n",
    "        raise ImportError(\"GDAL is required for TIFF operations but not available\")\n",
    "    \n",
    "    img_ds = gdal.Open(filename, gdal.GA_ReadOnly)\n",
    "    im_width = img_ds.RasterXSize\n",
    "    im_height = img_ds.RasterYSize\n",
    "    im_bands = img_ds.RasterCount\n",
    "    im_geotrans = img_ds.GetGeoTransform()\n",
    "    im_proj = img_ds.GetProjection()\n",
    "    \n",
    "    im_data = np.zeros((img_ds.RasterYSize, img_ds.RasterXSize, img_ds.RasterCount), \n",
    "                       gdal_array.GDALTypeCodeToNumericTypeCode(img_ds.GetRasterBand(1).DataType))\n",
    "    \n",
    "    for b in range(im_data.shape[2]):\n",
    "        im_data[:, :, b] = img_ds.GetRasterBand(b + 1).ReadAsArray()\n",
    "    \n",
    "    return im_data, img_ds\n",
    "\n",
    "def torch_resize_image_t4_optimized(img_array, new_size, is_label=False, device_id=0):\n",
    "    \"\"\"\n",
    "    T4-optimized GPU image resize using PyTorch\n",
    "    \n",
    "    Args:\n",
    "        img_array: Input image as numpy array\n",
    "        new_size: (width, height) tuple for new size\n",
    "        is_label: Whether this is a label image (use nearest neighbor)\n",
    "        device_id: GPU device ID to use\n",
    "    \n",
    "    Returns:\n",
    "        Resized image array as numpy\n",
    "    \"\"\"\n",
    "    if not GPU_AVAILABLE:\n",
    "        # CPU fallback using OpenCV\n",
    "        interpolation = cv2.INTER_NEAREST if is_label else cv2.INTER_CUBIC\n",
    "        return cv2.resize(img_array, new_size, interpolation=interpolation)\n",
    "    \n",
    "    try:\n",
    "        device = torch.device(f'cuda:{device_id}')\n",
    "        torch.cuda.set_device(device_id)\n",
    "        \n",
    "        # For very large images, use tiled processing\n",
    "        if max(img_array.shape[:2]) > T4_MAX_IMAGE_SIZE:\n",
    "            return torch_resize_large_image(img_array, new_size, is_label, device_id)\n",
    "        \n",
    "        # Convert numpy to torch tensor\n",
    "        if len(img_array.shape) == 3:\n",
    "            # Convert HWC to NCHW format for PyTorch\n",
    "            img_tensor = torch.from_numpy(img_array).permute(2, 0, 1).unsqueeze(0).float()\n",
    "        else:\n",
    "            # Single channel: HW to NCHW\n",
    "            img_tensor = torch.from_numpy(img_array).unsqueeze(0).unsqueeze(0).float()\n",
    "        \n",
    "        # Transfer to GPU\n",
    "        img_tensor = img_tensor.to(device)\n",
    "        \n",
    "        # Resize using PyTorch\n",
    "        mode = 'nearest' if is_label else 'bicubic'\n",
    "        \n",
    "        # PyTorch expects (N, C, H, W) and size as (H, W)\n",
    "        resized_tensor = F.interpolate(\n",
    "            img_tensor, \n",
    "            size=(new_size[1], new_size[0]),  # PyTorch expects (H, W)\n",
    "            mode=mode,\n",
    "            align_corners=False if mode == 'bicubic' else None\n",
    "        )\n",
    "        \n",
    "        # Convert back to numpy\n",
    "        if len(img_array.shape) == 3:\n",
    "            # Convert NCHW back to HWC\n",
    "            result = resized_tensor.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "        else:\n",
    "            # Convert NCHW back to HW\n",
    "            result = resized_tensor.squeeze(0).squeeze(0).cpu().numpy()\n",
    "        \n",
    "        # Clean up GPU memory\n",
    "        del img_tensor, resized_tensor\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        # Ensure correct data type\n",
    "        if is_label:\n",
    "            result = result.astype(np.uint8)\n",
    "        else:\n",
    "            result = result.astype(img_array.dtype)\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ T4 GPU resize failed on device {device_id}, falling back to CPU: {e}\")\n",
    "        clear_gpu_memory(device_id)\n",
    "        interpolation = cv2.INTER_NEAREST if is_label else cv2.INTER_CUBIC\n",
    "        return cv2.resize(img_array, new_size, interpolation=interpolation)\n",
    "\n",
    "def torch_resize_large_image(img_array, new_size, is_label=False, device_id=0):\n",
    "    \"\"\"\n",
    "    Handle very large images by processing in tiles using PyTorch\n",
    "    \"\"\"\n",
    "    tile_size = T4_MAX_IMAGE_SIZE // 2\n",
    "    overlap = 64\n",
    "    \n",
    "    # Calculate scale factors\n",
    "    scale_h = new_size[1] / img_array.shape[0]\n",
    "    scale_w = new_size[0] / img_array.shape[1]\n",
    "    \n",
    "    # Create output array\n",
    "    if len(img_array.shape) == 3:\n",
    "        output = np.zeros((new_size[1], new_size[0], img_array.shape[2]), dtype=img_array.dtype)\n",
    "    else:\n",
    "        output = np.zeros((new_size[1], new_size[0]), dtype=img_array.dtype)\n",
    "    \n",
    "    for y in range(0, img_array.shape[0], tile_size - overlap):\n",
    "        for x in range(0, img_array.shape[1], tile_size - overlap):\n",
    "            # Extract tile\n",
    "            y_end = min(y + tile_size, img_array.shape[0])\n",
    "            x_end = min(x + tile_size, img_array.shape[1])\n",
    "            tile = img_array[y:y_end, x:x_end]\n",
    "            \n",
    "            # Calculate output coordinates\n",
    "            out_y = int(y * scale_h)\n",
    "            out_x = int(x * scale_w)\n",
    "            out_y_end = int(y_end * scale_h)\n",
    "            out_x_end = int(x_end * scale_w)\n",
    "            \n",
    "            # Resize tile\n",
    "            tile_new_size = (out_x_end - out_x, out_y_end - out_y)\n",
    "            resized_tile = torch_resize_image_t4_optimized(tile, tile_new_size, is_label, device_id)\n",
    "            \n",
    "            # Place in output\n",
    "            if len(img_array.shape) == 3:\n",
    "                output[out_y:out_y_end, out_x:out_x_end, :] = resized_tile\n",
    "            else:\n",
    "                output[out_y:out_y_end, out_x:out_x_end] = resized_tile\n",
    "    \n",
    "    return output\n",
    "\n",
    "def torch_process_patches_dual_t4(img_array, patch_coords, imgsize, is_label=False, batch_size=32):\n",
    "    \"\"\"\n",
    "    Process patches using dual T4 GPUs for maximum performance with PyTorch\n",
    "    \n",
    "    Args:\n",
    "        img_array: Input image array\n",
    "        patch_coords: List of (start_h, end_h, start_w, end_w) coordinates\n",
    "        imgsize: Size of patches\n",
    "        is_label: Whether processing labels\n",
    "        batch_size: Batch size per GPU\n",
    "    \n",
    "    Returns:\n",
    "        List of patch arrays\n",
    "    \"\"\"\n",
    "    if not GPU_AVAILABLE or len(patch_coords) < batch_size:\n",
    "        # Fallback to CPU for small batches\n",
    "        return cpu_process_patches(img_array, patch_coords, is_label)\n",
    "    \n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    \n",
    "    if num_gpus == 1:\n",
    "        return torch_process_patches_single(img_array, patch_coords, imgsize, is_label, 0, batch_size)\n",
    "    \n",
    "    # Dual GPU processing\n",
    "    patches = [None] * len(patch_coords)\n",
    "    \n",
    "    def process_gpu_batch(gpu_id, coords_batch, indices_batch):\n",
    "        try:\n",
    "            device = torch.device(f'cuda:{gpu_id}')\n",
    "            torch.cuda.set_device(gpu_id)\n",
    "            \n",
    "            # Convert image to tensor once per batch\n",
    "            if len(img_array.shape) == 3:\n",
    "                # HWC to CHW\n",
    "                img_tensor = torch.from_numpy(img_array).permute(2, 0, 1).float().to(device)\n",
    "            else:\n",
    "                # HW to CHW (add channel dimension)\n",
    "                img_tensor = torch.from_numpy(img_array).unsqueeze(0).float().to(device)\n",
    "            \n",
    "            for i, (start_h, end_h, start_w, end_w) in enumerate(coords_batch):\n",
    "                if len(img_array.shape) == 3 and not is_label:\n",
    "                    # Multi-channel patch: CHW format\n",
    "                    patch_tensor = img_tensor[:, start_h:end_h, start_w:end_w]\n",
    "                    # Convert back to HWC for saving\n",
    "                    cpu_patch = patch_tensor.permute(1, 2, 0).cpu().numpy()\n",
    "                else:\n",
    "                    # Single channel patch\n",
    "                    if len(img_array.shape) == 3:\n",
    "                        # Take first channel for labels\n",
    "                        patch_tensor = img_tensor[0, start_h:end_h, start_w:end_w]\n",
    "                    else:\n",
    "                        patch_tensor = img_tensor[0, start_h:end_h, start_w:end_w]\n",
    "                    cpu_patch = patch_tensor.cpu().numpy()\n",
    "                \n",
    "                # Ensure correct data type\n",
    "                if is_label:\n",
    "                    cpu_patch = cpu_patch.astype(np.uint8)\n",
    "                else:\n",
    "                    cpu_patch = cpu_patch.astype(img_array.dtype)\n",
    "                \n",
    "                patches[indices_batch[i]] = cpu_patch\n",
    "            \n",
    "            # Clean up GPU memory\n",
    "            del img_tensor\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ GPU {gpu_id} batch processing failed: {e}\")\n",
    "            # Fallback to CPU for this batch\n",
    "            for i, (start_h, end_h, start_w, end_w) in enumerate(coords_batch):\n",
    "                if len(img_array.shape) == 3 and not is_label:\n",
    "                    patch = img_array[start_h:end_h, start_w:end_w, :]\n",
    "                else:\n",
    "                    patch = img_array[start_h:end_h, start_w:end_w]\n",
    "                patches[indices_batch[i]] = patch\n",
    "    \n",
    "    # Split work between GPUs\n",
    "    total_batches = len(patch_coords)\n",
    "    batches_per_gpu = total_batches // num_gpus\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=num_gpus) as executor:\n",
    "        futures = []\n",
    "        \n",
    "        for gpu_id in range(num_gpus):\n",
    "            start_idx = gpu_id * batches_per_gpu\n",
    "            if gpu_id == num_gpus - 1:  # Last GPU gets remaining work\n",
    "                end_idx = total_batches\n",
    "            else:\n",
    "                end_idx = start_idx + batches_per_gpu\n",
    "            \n",
    "            coords_batch = patch_coords[start_idx:end_idx]\n",
    "            indices_batch = list(range(start_idx, end_idx))\n",
    "            \n",
    "            future = executor.submit(process_gpu_batch, gpu_id, coords_batch, indices_batch)\n",
    "            futures.append(future)\n",
    "        \n",
    "        # Wait for all GPUs to complete\n",
    "        for future in as_completed(futures):\n",
    "            future.result()\n",
    "    \n",
    "    return [p for p in patches if p is not None]\n",
    "\n",
    "def torch_process_patches_single(img_array, patch_coords, imgsize, is_label, device_id, batch_size):\n",
    "    \"\"\"Process patches on a single GPU using PyTorch\"\"\"\n",
    "    try:\n",
    "        device = torch.device(f'cuda:{device_id}')\n",
    "        torch.cuda.set_device(device_id)\n",
    "        \n",
    "        # Convert image to tensor\n",
    "        if len(img_array.shape) == 3:\n",
    "            img_tensor = torch.from_numpy(img_array).permute(2, 0, 1).float().to(device)\n",
    "        else:\n",
    "            img_tensor = torch.from_numpy(img_array).unsqueeze(0).float().to(device)\n",
    "        \n",
    "        patches = []\n",
    "        \n",
    "        for start_h, end_h, start_w, end_w in patch_coords:\n",
    "            if len(img_array.shape) == 3 and not is_label:\n",
    "                patch_tensor = img_tensor[:, start_h:end_h, start_w:end_w]\n",
    "                cpu_patch = patch_tensor.permute(1, 2, 0).cpu().numpy()\n",
    "            else:\n",
    "                if len(img_array.shape) == 3:\n",
    "                    patch_tensor = img_tensor[0, start_h:end_h, start_w:end_w]\n",
    "                else:\n",
    "                    patch_tensor = img_tensor[0, start_h:end_h, start_w:end_w]\n",
    "                cpu_patch = patch_tensor.cpu().numpy()\n",
    "            \n",
    "            if is_label:\n",
    "                cpu_patch = cpu_patch.astype(np.uint8)\n",
    "            else:\n",
    "                cpu_patch = cpu_patch.astype(img_array.dtype)\n",
    "            \n",
    "            patches.append(cpu_patch)\n",
    "        \n",
    "        # Clean up\n",
    "        del img_tensor\n",
    "        return patches\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Single GPU processing failed: {e}\")\n",
    "        return cpu_process_patches(img_array, patch_coords, is_label)\n",
    "\n",
    "def cpu_process_patches(img_array, patch_coords, is_label):\n",
    "    \"\"\"CPU fallback for patch processing\"\"\"\n",
    "    patches = []\n",
    "    for start_h, end_h, start_w, end_w in patch_coords:\n",
    "        if len(img_array.shape) == 3 and not is_label:\n",
    "            patch = img_array[start_h:end_h, start_w:end_w, :]\n",
    "        else:\n",
    "            patch = img_array[start_h:end_h, start_w:end_w]\n",
    "        patches.append(patch)\n",
    "    return patches\n",
    "\n",
    "def getAxisBoundary(Index, length, imgsize, totalNums):\n",
    "    \"\"\"\n",
    "    Calculate boundary indices for slicing\n",
    "    \n",
    "    Args:\n",
    "        Index: Current index\n",
    "        length: Total length of the dimension\n",
    "        imgsize: Size of each slice\n",
    "        totalNums: Total number of slices\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (start, end) indices\n",
    "    \"\"\"\n",
    "    if (Index + 1 == totalNums) and (length % imgsize != 0):\n",
    "        start = length - imgsize\n",
    "        end = length\n",
    "    else:\n",
    "        start = Index * imgsize\n",
    "        end = (Index + 1) * imgsize\n",
    "    return start, end\n",
    "\n",
    "def slicingSingleImg(imgDir, outputDir, imgsize=512, scales=[1.0], isLabel=False, batch_size=T4_OPTIMAL_BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    Slice a single large image into smaller patches using dual T4 GPU acceleration with PyTorch\n",
    "    \n",
    "    Args:\n",
    "        imgDir: Path to input image\n",
    "        outputDir: Path to output directory\n",
    "        imgsize: Size of output patches\n",
    "        scales: List of scale factors\n",
    "        isLabel: Whether the image is a label/mask\n",
    "        batch_size: Number of patches to process in GPU batch (optimized for T4)\n",
    "    \"\"\"\n",
    "    path, name = os.path.split(imgDir)\n",
    "    subpath, datasetName = os.path.split(path)\n",
    "    _, datasetName = os.path.split(subpath)\n",
    "    filename, extension = os.path.splitext(name)\n",
    "    outputPath = os.path.join(outputDir, f\"{datasetName}_{filename}\")\n",
    "    \n",
    "    save_extension = \".png\"\n",
    "    \n",
    "    try:\n",
    "        if extension.lower() in [\".png\", \".jpg\", \".jpeg\", \".bmp\"]:\n",
    "            sourceImg = Image.open(imgDir)\n",
    "        elif extension.lower() in [\".tiff\", \".tif\"] and GDAL_AVAILABLE:\n",
    "            sourceImg, img_ds1 = readTiff(imgDir)\n",
    "            sourceImg = Image.fromarray(sourceImg) if len(sourceImg.shape) == 3 else Image.fromarray(sourceImg.squeeze(axis=2))\n",
    "        else:\n",
    "            print(f\"⚠️ Skipping unsupported format: {extension}\")\n",
    "            return\n",
    "        \n",
    "        sourceW, sourceH = sourceImg.size[0], sourceImg.size[1]\n",
    "        sourceC = len(sourceImg.getbands())\n",
    "        \n",
    "        for singleScale in scales:\n",
    "            # Convert PIL to numpy for GPU processing\n",
    "            img_array = np.array(sourceImg)\n",
    "            \n",
    "            # Determine optimal GPU for this operation\n",
    "            device_id = 0\n",
    "            if GPU_AVAILABLE and torch.cuda.device_count() > 1:\n",
    "                # Simple load balancing - use GPU with more free memory\n",
    "                device_id = 0\n",
    "            \n",
    "            # GPU-accelerated resize optimized for T4 with PyTorch\n",
    "            new_size = (int(sourceW * singleScale), int(sourceH * singleScale))\n",
    "            img = torch_resize_image_t4_optimized(img_array, new_size, isLabel, device_id)\n",
    "            \n",
    "            # Process labels on GPU if available\n",
    "            if isLabel:\n",
    "                if GPU_AVAILABLE:\n",
    "                    try:\n",
    "                        device = torch.device(f'cuda:{device_id}')\n",
    "                        torch.cuda.set_device(device_id)\n",
    "                        \n",
    "                        # Convert to tensor\n",
    "                        if len(img.shape) == 3:\n",
    "                            img_tensor = torch.from_numpy(img).to(device)\n",
    "                        else:\n",
    "                            img_tensor = torch.from_numpy(img).to(device)\n",
    "                        \n",
    "                        # Binary thresholding\n",
    "                        img_tensor = torch.where(img_tensor != 0, 255, img_tensor).to(torch.uint8)\n",
    "                        \n",
    "                        # Convert RGB label to binary if needed\n",
    "                        if sourceC != 1 and len(img_tensor.shape) == 3:\n",
    "                            img_tensor = torch.max(img_tensor, dim=2)[0]\n",
    "                        \n",
    "                        img = img_tensor.cpu().numpy()\n",
    "                        \n",
    "                        # Clean up\n",
    "                        del img_tensor\n",
    "                        torch.cuda.empty_cache()\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"⚠️ GPU label processing failed, using CPU: {e}\")\n",
    "                        img[img != 0] = 255\n",
    "                        img = img.astype(np.uint8)\n",
    "                        if sourceC != 1 and len(img.shape) == 3:\n",
    "                            img = img.max(axis=2)\n",
    "                else:\n",
    "                    img[img != 0] = 255\n",
    "                    img = img.astype(np.uint8)\n",
    "                    if sourceC != 1 and len(img.shape) == 3:\n",
    "                        img = img.max(axis=2)\n",
    "            \n",
    "            img_h, img_w = img.shape[0], img.shape[1]\n",
    "            h_nums, w_nums = img.shape[0] // imgsize, img.shape[1] // imgsize\n",
    "            \n",
    "            if img_h % imgsize != 0:\n",
    "                h_nums = h_nums + 1\n",
    "            if img_w % imgsize != 0:\n",
    "                w_nums = w_nums + 1\n",
    "            \n",
    "            if img_h < imgsize or img_w < imgsize:\n",
    "                continue\n",
    "            \n",
    "            print(f\"⚡ PyTorch T4 Processing scale {singleScale}: {h_nums}x{w_nums} patches\")\n",
    "            \n",
    "            # Collect patch coordinates for batch processing\n",
    "            patch_coords = []\n",
    "            patch_filenames = []\n",
    "            \n",
    "            for hIndex in range(h_nums):\n",
    "                start_h, end_h = getAxisBoundary(hIndex, img_h, imgsize, h_nums)\n",
    "                \n",
    "                for wIndex in range(w_nums):\n",
    "                    start_w, end_w = getAxisBoundary(wIndex, img_w, imgsize, w_nums)\n",
    "                    \n",
    "                    outputPathTemp = (f\"{outputPath}_scale-{singleScale}_y-{start_h}\"\n",
    "                                    f\"_x-{start_w}_imgsize-{imgsize}{save_extension}\")\n",
    "                    \n",
    "                    if not os.path.exists(outputPathTemp):\n",
    "                        patch_coords.append((start_h, end_h, start_w, end_w))\n",
    "                        patch_filenames.append(outputPathTemp)\n",
    "            \n",
    "            # Process patches with dual T4 optimization using PyTorch\n",
    "            total_patches = len(patch_coords)\n",
    "            if total_patches == 0:\n",
    "                continue\n",
    "                \n",
    "            print(f\"🚀 PyTorch T4 Dual-GPU processing {total_patches} patches...\")\n",
    "            \n",
    "            # Process all patches at once with dual GPU\n",
    "            patches = torch_process_patches_dual_t4(img, patch_coords, imgsize, isLabel, batch_size)\n",
    "            \n",
    "            # Save patches\n",
    "            print(f\"💾 Saving {len(patches)} patches...\")\n",
    "            for patch, filename in zip(patches, patch_filenames):\n",
    "                temp_img = Image.fromarray(patch)\n",
    "                temp_img.save(filename)\n",
    "            \n",
    "            # Clear GPU memory after processing\n",
    "            clear_gpu_memory()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {imgDir}: {str(e)}\")\n",
    "        clear_gpu_memory()\n",
    "\n",
    "def process_levir_dataset(input_path, output_path, imgsize=256, batch_size=T4_OPTIMAL_BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    Process the entire LEVIR-CD dataset with dual T4 GPU acceleration using PyTorch\n",
    "    \n",
    "    Args:\n",
    "        input_path: Path to input dataset\n",
    "        output_path: Path to output directory\n",
    "        imgsize: Size of output patches\n",
    "        batch_size: GPU batch size optimized for T4\n",
    "    \"\"\"\n",
    "    # Setup GPUs\n",
    "    gpu_devices = setup_gpu_devices()\n",
    "    \n",
    "    splits = ['train', 'val', 'test']\n",
    "    image_types = ['T1', 'T2', 'label']\n",
    "    \n",
    "    print(f\"🚀 Starting PyTorch T4 Dual-GPU accelerated processing...\")\n",
    "    print(f\"🎯 Detected {len(gpu_devices)} GPU(s)\")\n",
    "    print(f\"📦 T4-Optimized Batch Size: {batch_size}\")\n",
    "    print(f\"🔧 Image Size: {imgsize}\")\n",
    "    \n",
    "    for split in splits:\n",
    "        print(f\"\\n📁 Processing {split} split...\")\n",
    "        \n",
    "        for img_type in image_types:\n",
    "            input_dir = os.path.join(input_path, split, img_type)\n",
    "            output_dir = os.path.join(output_path, split, img_type)\n",
    "            \n",
    "            if not os.path.exists(input_dir):\n",
    "                print(f\"⚠️  Input directory not found: {input_dir}\")\n",
    "                continue\n",
    "            \n",
    "            if not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir, exist_ok=True)\n",
    "            \n",
    "            # Get all files in input directory\n",
    "            fileList = glob.glob(os.path.join(input_dir, \"*\"))\n",
    "            \n",
    "            if not fileList:\n",
    "                print(f\"⚠️  No files found in {input_dir}\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"🖼️  Processing {img_type}: {len(fileList)} files\")\n",
    "            \n",
    "            isLabel = (img_type == 'label')\n",
    "            count = 0\n",
    "            \n",
    "            for singleImg in tqdm.tqdm(fileList, desc=f\"PyTorch T4 Processing {img_type}\"):\n",
    "                count += 1\n",
    "                slicingSingleImg(\n",
    "                    singleImg, \n",
    "                    output_dir, \n",
    "                    scales=multiScale, \n",
    "                    imgsize=imgsize, \n",
    "                    isLabel=isLabel,\n",
    "                    batch_size=batch_size\n",
    "                )\n",
    "                \n",
    "                # Clear memory every few files to prevent accumulation\n",
    "                if count % 3 == 0:\n",
    "                    clear_gpu_memory()\n",
    "            \n",
    "            print(f\"✅ Completed {img_type}: {count}/{len(fileList)} files processed\")\n",
    "            clear_gpu_memory()  # Clear memory after each type\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function for command line usage\"\"\"\n",
    "    parser = argparse.ArgumentParser(description='PyTorch T4 Dual-GPU accelerated image slicing for change detection')\n",
    "    parser.add_argument(\"-i\", \"--input_dir\", \n",
    "                       default=\"/kaggle/input/processed-levir-cd-dataset/LEVIR-CD+_256\", \n",
    "                       type=str, help=\"Path to input dataset directory\")\n",
    "    parser.add_argument(\"-o\", \"--output_dir\", \n",
    "                       default=\"/kaggle/working/processed_data\", \n",
    "                       type=str, help=\"Path to output directory\")\n",
    "    parser.add_argument(\"-is\", \"--img_size\", default=256, type=int, help=\"Output patch size\")\n",
    "    parser.add_argument(\"-bs\", \"--batch_size\", default=T4_OPTIMAL_BATCH_SIZE, type=int, \n",
    "                       help=f\"GPU batch size (T4 optimized default: {T4_OPTIMAL_BATCH_SIZE})\")\n",
    "    parser.add_argument(\"-ol\", \"--overlap_size\", default=512, type=int, help=\"Overlap size (not implemented)\")\n",
    "    parser.add_argument('-c', \"--multi_scale_slicing\", action='store_true', default=False)\n",
    "\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    \n",
    "    if args.output_dir is None:\n",
    "        print(\"❌ Error: No output directory specified!\")\n",
    "        exit(0)\n",
    "    \n",
    "    if not os.path.exists(args.output_dir):\n",
    "        os.makedirs(args.output_dir)\n",
    "    \n",
    "    # T4-specific optimizations\n",
    "    if not GPU_AVAILABLE:\n",
    "        print(\"⚠️  Warning: GPU not available, running on CPU\")\n",
    "        args.batch_size = 1\n",
    "    else:\n",
    "        print(f\"⚡ Using PyTorch with T4 GPU(s), optimized batch size: {args.batch_size}\")\n",
    "        \n",
    "        # Adjust batch size based on image size for T4's memory\n",
    "        if args.img_size > 512:\n",
    "            args.batch_size = max(8, args.batch_size // 2)\n",
    "            print(f\"🔧 Adjusted batch size for large images: {args.batch_size}\")\n",
    "    \n",
    "    # Process dataset with PyTorch T4 optimizations\n",
    "    process_levir_dataset(args.input_dir, args.output_dir, args.img_size, args.batch_size)\n",
    "    \n",
    "    print(\"🎉 PyTorch T4 processing completed successfully!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T04:23:34.306527Z",
     "iopub.status.busy": "2025-09-05T04:23:34.306280Z",
     "iopub.status.idle": "2025-09-05T04:23:35.691522Z",
     "shell.execute_reply": "2025-09-05T04:23:35.690766Z",
     "shell.execute_reply.started": "2025-09-05T04:23:34.306510Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Input files: 2955\n",
      "📤 Output files: 2955\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "input_dir = \"/kaggle/input/processed-levir-cd-dataset/LEVIR-CD+_256\"   # your input folder\n",
    "output_dir = \"/kaggle/working/processed_data\"                          # your output folder\n",
    "\n",
    "def count_files(path):\n",
    "    total = 0\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        total += len([f for f in files if not f.startswith('.')])  # ignore hidden files\n",
    "    return total\n",
    "\n",
    "input_files = count_files(input_dir)\n",
    "output_files = count_files(output_dir)\n",
    "\n",
    "print(f\"📥 Input files: {input_files}\")\n",
    "print(f\"📤 Output files: {output_files}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T04:23:43.344872Z",
     "iopub.status.busy": "2025-09-05T04:23:43.344341Z",
     "iopub.status.idle": "2025-09-05T04:23:43.352600Z",
     "shell.execute_reply": "2025-09-05T04:23:43.351875Z",
     "shell.execute_reply.started": "2025-09-05T04:23:43.344847Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Total processed files saved: 2955\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "output_dir = \"/kaggle/working/processed_data\"  # change if your output path is different\n",
    "\n",
    "file_count = 0\n",
    "for root, dirs, files in os.walk(output_dir):\n",
    "    file_count += len(files)\n",
    "\n",
    "print(f\"✅ Total processed files saved: {file_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T04:23:47.108622Z",
     "iopub.status.busy": "2025-09-05T04:23:47.108376Z",
     "iopub.status.idle": "2025-09-05T04:23:47.116238Z",
     "shell.execute_reply": "2025-09-05T04:23:47.115556Z",
     "shell.execute_reply.started": "2025-09-05T04:23:47.108605Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ data_loader.py created!\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Create data_loader.py  \n",
    "# Copy the data_loader.py code here (from the artifact above)\n",
    "with open('/kaggle/working/data_utils/data_loader.py', 'w') as f:\n",
    "    f.write('''import glob\n",
    "import os\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from data_utils.augment import Augmentation, mirrorPadding2D\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "class WSIDataset(Dataset):\n",
    "    def __init__(self, root_dir, mode, taskList=None, total_fold=5, valid_fold=2, miniScale=1):\n",
    "        \"\"\"\n",
    "        Dataset class for LEVIR-CD dataset\n",
    "        \n",
    "        Args:\n",
    "            root_dir: Dictionary or string path to dataset root\n",
    "            mode: 'train', 'val', or 'test'\n",
    "            taskList: Not used in current implementation\n",
    "            total_fold: Total number of folds for cross-validation\n",
    "            valid_fold: Validation fold number\n",
    "            miniScale: Scale factor for images\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.mode = mode\n",
    "        self.miniScale = miniScale\n",
    "        self.total_fold = total_fold\n",
    "        self.valid_fold = valid_fold\n",
    "        \n",
    "        # Initialize lists for image paths\n",
    "        self.all_png_dir_1 = []  # T1 images\n",
    "        self.all_png_dir_2 = []  # T2 images  \n",
    "        self.all_label_change = []  # Labels\n",
    "        \n",
    "        # Handle both dictionary and string inputs for root_dir\n",
    "        if isinstance(root_dir, dict):\n",
    "            # Original code logic for multiple datasets\n",
    "            for k, v in self.root_dir.items():\n",
    "                self.all_png_dir_1 += sorted(glob.glob(self.root_dir[k] + os.sep + self.mode + os.sep + \"T1\" + os.sep + '*'))\n",
    "                self.all_png_dir_2 += sorted(glob.glob(self.root_dir[k] + os.sep + self.mode + os.sep + \"T2\" + os.sep + '*'))\n",
    "                self.all_label_change += sorted(glob.glob(self.root_dir[k] + os.sep + self.mode + os.sep + \"label\" + os.sep + '*'))\n",
    "        else:\n",
    "            # Single dataset path (for Kaggle usage)\n",
    "            self.all_png_dir_1 = sorted(glob.glob(os.path.join(root_dir, mode, \"T1\", '*')))\n",
    "            self.all_png_dir_2 = sorted(glob.glob(os.path.join(root_dir, mode, \"T2\", '*')))\n",
    "            self.all_label_change = sorted(glob.glob(os.path.join(root_dir, mode, \"label\", '*')))\n",
    "        \n",
    "        # Extract filenames for matching\n",
    "        self.all_png_dir_1_name = [os.path.splitext(os.path.split(i)[1])[0] for i in self.all_label_change]\n",
    "        \n",
    "        print(f\"T1 patch numbers: {len(self.all_png_dir_1)}\")\n",
    "        print(f\"T2 patch numbers: {len(self.all_png_dir_2)}\")\n",
    "        print(f\"Label patch numbers: {len(self.all_label_change)}\")\n",
    "        \n",
    "        # Training parameters\n",
    "        self.isTrain = False\n",
    "        self.source_size = (256, 256)\n",
    "        self.randomImgSizeList = [(256, 256)]\n",
    "        self.randomImgSizeList = self.randomImgSizeList[::1]\n",
    "        self.randomImgSize = (256, 256)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Get a single item from the dataset\n",
    "        \n",
    "        Args:\n",
    "            index: Index of the item to retrieve\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (img1, img2, label1, label2, labelc, dir)\n",
    "        \"\"\"\n",
    "        dir_name = self.all_png_dir_1_name[index]\n",
    "        img1_path = self.all_png_dir_1[index]\n",
    "        img2_path = self.all_png_dir_2[index]\n",
    "        labelc_path = self.all_label_change[index]\n",
    "        \n",
    "        if self.mode == \"train\":\n",
    "            # Load and resize images for training\n",
    "            img1 = np.array(Image.open(img1_path).resize(self.randomImgSize))\n",
    "            img2 = np.array(Image.open(img2_path).resize(self.randomImgSize))\n",
    "            labelc = np.expand_dims(np.array(Image.open(labelc_path).resize(self.randomImgSize)), axis=2)\n",
    "            \n",
    "            # Apply mirror padding for augmentation\n",
    "            img1 = mirrorPadding2D(img1)\n",
    "            img2 = mirrorPadding2D(img2)\n",
    "            labelc = mirrorPadding2D(labelc)\n",
    "            \n",
    "            # Convert back to PIL Images\n",
    "            img1 = Image.fromarray(img1)\n",
    "            img2 = Image.fromarray(img2)\n",
    "            labelc = Image.fromarray(np.squeeze(labelc))\n",
    "            \n",
    "            # Apply geometric augmentations\n",
    "            aug = Augmentation()\n",
    "            img2_combine, bias_y, bias_x = aug.randomSpaceAugment(\n",
    "                [img1, img2, labelc], \n",
    "                source_size=self.randomImgSize, \n",
    "                unoverlap=None\n",
    "            )\n",
    "            \n",
    "            # Unpack augmented images\n",
    "            img1, img2, labelc = img2_combine\n",
    "            \n",
    "            # Apply photometric distortions\n",
    "            imgPhotometricDistortion1 = transforms.Compose([\n",
    "                transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.2, 0.1)], p=0.8),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "            ])\n",
    "            \n",
    "            imgPhotometricDistortion2 = transforms.Compose([\n",
    "                transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.2, 0.1)], p=0.8),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "            ])\n",
    "            \n",
    "            img1 = imgPhotometricDistortion1(img1)\n",
    "            img2 = imgPhotometricDistortion2(img2)\n",
    "            labelc = torch.FloatTensor(np.array(labelc)) / 255\n",
    "            \n",
    "        elif self.mode in [\"validation\", \"val\", \"test\"]:\n",
    "            # Load and process images for validation/test\n",
    "            img1 = Image.open(img1_path).resize(self.randomImgSize)\n",
    "            img2 = Image.open(img2_path).resize(self.randomImgSize)\n",
    "            \n",
    "            imgTransforms = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "            ])\n",
    "            \n",
    "            labelc = np.expand_dims(np.array(Image.open(labelc_path).resize(self.randomImgSize)), axis=2)\n",
    "            labelc = torch.FloatTensor(np.squeeze(labelc)) / 255\n",
    "            \n",
    "            img1 = imgTransforms(img1)\n",
    "            img2 = imgTransforms(img2)\n",
    "        \n",
    "        # Dummy labels (not used in current implementation)\n",
    "        label1 = torch.FloatTensor([0])\n",
    "        label2 = torch.FloatTensor([0])\n",
    "        \n",
    "        return img1, img2, label1, label2, labelc, dir_name\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Return the total number of samples\"\"\"\n",
    "        return len(self.all_png_dir_1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    dataset_path = \"/kaggle/working/processed_data\"\n",
    "    \n",
    "    # Test dataset creation\n",
    "    train_dataset = WSIDataset(root_dir=dataset_path, mode=\"train\")\n",
    "    val_dataset = WSIDataset(root_dir=dataset_path, mode=\"val\") \n",
    "    test_dataset = WSIDataset(root_dir=dataset_path, mode=\"test\")\n",
    "    \n",
    "    print(\"Dataset created successfully!\")\n",
    "    print(f\"Train samples: {len(train_dataset)}\")\n",
    "    print(f\"Val samples: {len(val_dataset)}\")\n",
    "    print(f\"Test samples: {len(test_dataset)}\")\n",
    "    \n",
    "    # Test loading a single sample\n",
    "    if len(train_dataset) > 0:\n",
    "        sample = train_dataset[0]\n",
    "        print(f\"Sample shapes: img1={sample[0].shape}, img2={sample[1].shape}, label={sample[4].shape}\")''')\n",
    "\n",
    "print(\"✅ data_loader.py created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implement data_loader.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T04:24:11.868209Z",
     "iopub.status.busy": "2025-09-05T04:24:11.867423Z",
     "iopub.status.idle": "2025-09-05T04:24:11.927572Z",
     "shell.execute_reply": "2025-09-05T04:24:11.926855Z",
     "shell.execute_reply.started": "2025-09-05T04:24:11.868183Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1 patch numbers: 510\n",
      "T2 patch numbers: 510\n",
      "Label patch numbers: 510\n",
      "T1 patch numbers: 127\n",
      "T2 patch numbers: 127\n",
      "Label patch numbers: 127\n",
      "T1 patch numbers: 348\n",
      "T2 patch numbers: 348\n",
      "Label patch numbers: 348\n",
      "Dataset created successfully!\n",
      "Train samples: 510\n",
      "Val samples: 127\n",
      "Test samples: 348\n",
      "Sample shapes: img1=torch.Size([3, 256, 256]), img2=torch.Size([3, 256, 256]), label=torch.Size([256, 256])\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from data_utils.augment import Augmentation, mirrorPadding2D\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "class WSIDataset(Dataset):\n",
    "    def __init__(self, root_dir, mode, taskList=None, total_fold=5, valid_fold=2, miniScale=1):\n",
    "        \"\"\"\n",
    "        Dataset class for LEVIR-CD dataset\n",
    "        \n",
    "        Args:\n",
    "            root_dir: Dictionary or string path to dataset root\n",
    "            mode: 'train', 'val', or 'test'\n",
    "            taskList: Not used in current implementation\n",
    "            total_fold: Total number of folds for cross-validation\n",
    "            valid_fold: Validation fold number\n",
    "            miniScale: Scale factor for images\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.mode = mode\n",
    "        self.miniScale = miniScale\n",
    "        self.total_fold = total_fold\n",
    "        self.valid_fold = valid_fold\n",
    "        \n",
    "        # Initialize lists for image paths\n",
    "        self.all_png_dir_1 = []  # T1 images\n",
    "        self.all_png_dir_2 = []  # T2 images  \n",
    "        self.all_label_change = []  # Labels\n",
    "        \n",
    "        # Handle both dictionary and string inputs for root_dir\n",
    "        if isinstance(root_dir, dict):\n",
    "            # Original code logic for multiple datasets\n",
    "            for k, v in self.root_dir.items():\n",
    "                self.all_png_dir_1 += sorted(glob.glob(self.root_dir[k] + os.sep + self.mode + os.sep + \"T1\" + os.sep + '*'))\n",
    "                self.all_png_dir_2 += sorted(glob.glob(self.root_dir[k] + os.sep + self.mode + os.sep + \"T2\" + os.sep + '*'))\n",
    "                self.all_label_change += sorted(glob.glob(self.root_dir[k] + os.sep + self.mode + os.sep + \"label\" + os.sep + '*'))\n",
    "        else:\n",
    "            # Single dataset path (for Kaggle usage)\n",
    "            self.all_png_dir_1 = sorted(glob.glob(os.path.join(root_dir, mode, \"T1\", '*')))\n",
    "            self.all_png_dir_2 = sorted(glob.glob(os.path.join(root_dir, mode, \"T2\", '*')))\n",
    "            self.all_label_change = sorted(glob.glob(os.path.join(root_dir, mode, \"label\", '*')))\n",
    "        \n",
    "        # Extract filenames for matching\n",
    "        self.all_png_dir_1_name = [os.path.splitext(os.path.split(i)[1])[0] for i in self.all_label_change]\n",
    "        \n",
    "        print(f\"T1 patch numbers: {len(self.all_png_dir_1)}\")\n",
    "        print(f\"T2 patch numbers: {len(self.all_png_dir_2)}\")\n",
    "        print(f\"Label patch numbers: {len(self.all_label_change)}\")\n",
    "        \n",
    "        # Training parameters\n",
    "        self.isTrain = False\n",
    "        self.source_size = (256, 256)\n",
    "        self.randomImgSizeList = [(256, 256)]\n",
    "        self.randomImgSizeList = self.randomImgSizeList[::1]\n",
    "        self.randomImgSize = (256, 256)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Get a single item from the dataset\n",
    "        \n",
    "        Args:\n",
    "            index: Index of the item to retrieve\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (img1, img2, label1, label2, labelc, dir)\n",
    "        \"\"\"\n",
    "        dir_name = self.all_png_dir_1_name[index]\n",
    "        img1_path = self.all_png_dir_1[index]\n",
    "        img2_path = self.all_png_dir_2[index]\n",
    "        labelc_path = self.all_label_change[index]\n",
    "        \n",
    "        if self.mode == \"train\":\n",
    "            # Load and resize images for training\n",
    "            img1 = np.array(Image.open(img1_path).resize(self.randomImgSize))\n",
    "            img2 = np.array(Image.open(img2_path).resize(self.randomImgSize))\n",
    "            labelc = np.expand_dims(np.array(Image.open(labelc_path).resize(self.randomImgSize)), axis=2)\n",
    "            \n",
    "            # Apply mirror padding for augmentation\n",
    "            img1 = mirrorPadding2D(img1)\n",
    "            img2 = mirrorPadding2D(img2)\n",
    "            labelc = mirrorPadding2D(labelc)\n",
    "            \n",
    "            # Convert back to PIL Images\n",
    "            img1 = Image.fromarray(img1)\n",
    "            img2 = Image.fromarray(img2)\n",
    "            labelc = Image.fromarray(np.squeeze(labelc))\n",
    "            \n",
    "            # Apply geometric augmentations\n",
    "            aug = Augmentation()\n",
    "            img2_combine, bias_y, bias_x = aug.randomSpaceAugment(\n",
    "                [img1, img2, labelc], \n",
    "                source_size=self.randomImgSize, \n",
    "                unoverlap=None\n",
    "            )\n",
    "            \n",
    "            # Unpack augmented images\n",
    "            img1, img2, labelc = img2_combine\n",
    "            \n",
    "            # Apply photometric distortions\n",
    "            imgPhotometricDistortion1 = transforms.Compose([\n",
    "                transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.2, 0.1)], p=0.8),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "            ])\n",
    "            \n",
    "            imgPhotometricDistortion2 = transforms.Compose([\n",
    "                transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.2, 0.1)], p=0.8),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "            ])\n",
    "            \n",
    "            img1 = imgPhotometricDistortion1(img1)\n",
    "            img2 = imgPhotometricDistortion2(img2)\n",
    "            labelc = torch.FloatTensor(np.array(labelc)) / 255\n",
    "            \n",
    "        elif self.mode in [\"validation\", \"val\", \"test\"]:\n",
    "            # Load and process images for validation/test\n",
    "            img1 = Image.open(img1_path).resize(self.randomImgSize)\n",
    "            img2 = Image.open(img2_path).resize(self.randomImgSize)\n",
    "            \n",
    "            imgTransforms = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "            ])\n",
    "            \n",
    "            labelc = np.expand_dims(np.array(Image.open(labelc_path).resize(self.randomImgSize)), axis=2)\n",
    "            labelc = torch.FloatTensor(np.squeeze(labelc)) / 255\n",
    "            \n",
    "            img1 = imgTransforms(img1)\n",
    "            img2 = imgTransforms(img2)\n",
    "        \n",
    "        # Dummy labels (not used in current implementation)\n",
    "        label1 = torch.FloatTensor([0])\n",
    "        label2 = torch.FloatTensor([0])\n",
    "        \n",
    "        return img1, img2, label1, label2, labelc, dir_name\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Return the total number of samples\"\"\"\n",
    "        return len(self.all_png_dir_1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    dataset_path = \"/kaggle/working/processed_data\"\n",
    "    \n",
    "    # Test dataset creation\n",
    "    train_dataset = WSIDataset(root_dir=dataset_path, mode=\"train\")\n",
    "    val_dataset = WSIDataset(root_dir=dataset_path, mode=\"val\") \n",
    "    test_dataset = WSIDataset(root_dir=dataset_path, mode=\"test\")\n",
    "    \n",
    "    print(\"Dataset created successfully!\")\n",
    "    print(f\"Train samples: {len(train_dataset)}\")\n",
    "    print(f\"Val samples: {len(val_dataset)}\")\n",
    "    print(f\"Test samples: {len(test_dataset)}\")\n",
    "    \n",
    "    # Test loading a single sample\n",
    "    if len(train_dataset) > 0:\n",
    "        sample = train_dataset[0]\n",
    "        print(f\"Sample shapes: img1={sample[0].shape}, img2={sample[1].shape}, label={sample[4].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-09-05T04:24:26.696056Z",
     "iopub.status.busy": "2025-09-05T04:24:26.695779Z",
     "iopub.status.idle": "2025-09-05T04:24:26.858201Z",
     "shell.execute_reply": "2025-09-05T04:24:26.857548Z",
     "shell.execute_reply.started": "2025-09-05T04:24:26.696031Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Running complete setup verification tests...\n",
      "\n",
      "🔍 Checking PyTorch version...\n",
      "   PyTorch version: 2.6.0+cu124\n",
      "   Torchvision version: 0.21.0+cu124\n",
      "   ✅ PyTorch 2.0+ detected\n",
      "\n",
      "🔍 Checking directory structure...\n",
      "   ✅ /kaggle/working/data_utils\n",
      "   ✅ /kaggle/working/processed_data/train/T1\n",
      "   ✅ /kaggle/working/processed_data/train/T2\n",
      "   ✅ /kaggle/working/processed_data/train/label\n",
      "   ✅ /kaggle/working/processed_data/val/T1\n",
      "   ✅ /kaggle/working/processed_data/val/T2\n",
      "   ✅ /kaggle/working/processed_data/val/label\n",
      "   ✅ /kaggle/working/processed_data/test/T1\n",
      "   ✅ /kaggle/working/processed_data/test/T2\n",
      "   ✅ /kaggle/working/processed_data/test/label\n",
      "   ✅ /kaggle/working/data_utils/__init__.py\n",
      "   ✅ /kaggle/working/data_utils/augment.py\n",
      "   ✅ /kaggle/working/data_utils/data_loader.py\n",
      "   ✅ /kaggle/working/data_utils/slicingPatch.py\n",
      "\n",
      "🔍 Testing imports...\n",
      "   ✅ augment.py imports successful\n",
      "   ✅ data_loader.py imports successful\n",
      "\n",
      "🔍 Testing dataset loading...\n",
      "T1 patch numbers: 510\n",
      "T2 patch numbers: 510\n",
      "Label patch numbers: 510\n",
      "T1 patch numbers: 127\n",
      "T2 patch numbers: 127\n",
      "Label patch numbers: 127\n",
      "T1 patch numbers: 348\n",
      "T2 patch numbers: 348\n",
      "Label patch numbers: 348\n",
      "   ✅ Datasets created successfully\n",
      "      Train samples: 510\n",
      "      Val samples: 127\n",
      "      Test samples: 348\n",
      "   ✅ Sample loaded successfully\n",
      "      img1 shape: torch.Size([3, 256, 256])\n",
      "      img2 shape: torch.Size([3, 256, 256])\n",
      "      label shape: torch.Size([256, 256])\n",
      "      filename: train_1\n",
      "\n",
      "🔍 Testing augmentation...\n",
      "   ✅ Spatial augmentation works\n",
      "   ✅ Mirror padding works\n",
      "\n",
      "🔍 Testing DataLoader...\n",
      "T1 patch numbers: 510\n",
      "T2 patch numbers: 510\n",
      "Label patch numbers: 510\n",
      "   ✅ DataLoader works\n",
      "      Batch size: 2\n",
      "      img1 batch shape: torch.Size([2, 3, 256, 256])\n",
      "      img2 batch shape: torch.Size([2, 3, 256, 256])\n",
      "      change_label batch shape: torch.Size([2, 256, 256])\n",
      "\n",
      "==================================================\n",
      "🧪 TEST RESULTS SUMMARY\n",
      "==================================================\n",
      "PyTorch Version      : ✅ PASS\n",
      "Directory Structure  : ✅ PASS\n",
      "Imports              : ✅ PASS\n",
      "Dataset Loading      : ✅ PASS\n",
      "Augmentation         : ✅ PASS\n",
      "DataLoader           : ✅ PASS\n",
      "--------------------------------------------------\n",
      "TOTAL: 6/6 tests passed\n",
      "🎉 All tests passed! Your setup is ready for use.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Quick test script to verify the complete setup works correctly\n",
    "Run this after setting up all the files to ensure everything is working\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def test_pytorch_version():\n",
    "    \"\"\"Test PyTorch version compatibility\"\"\"\n",
    "    print(\"🔍 Checking PyTorch version...\")\n",
    "    print(f\"   PyTorch version: {torch.__version__}\")\n",
    "    print(f\"   Torchvision version: {torchvision.__version__}\")\n",
    "    \n",
    "    # Check if it's 2.0+\n",
    "    version_parts = torch.__version__.split('.')\n",
    "    major_version = int(version_parts[0])\n",
    "    minor_version = int(version_parts[1]) if len(version_parts) > 1 else 0\n",
    "    \n",
    "    if major_version >= 2:\n",
    "        print(\"   ✅ PyTorch 2.0+ detected\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"   ⚠️  PyTorch version is less than 2.0\")\n",
    "        return False\n",
    "\n",
    "def test_directory_structure():\n",
    "    \"\"\"Test if directory structure is correct\"\"\"\n",
    "    print(\"\\n🔍 Checking directory structure...\")\n",
    "    \n",
    "    required_dirs = [\n",
    "        '/kaggle/working/data_utils',\n",
    "        '/kaggle/working/processed_data/train/T1',\n",
    "        '/kaggle/working/processed_data/train/T2',\n",
    "        '/kaggle/working/processed_data/train/label',\n",
    "        '/kaggle/working/processed_data/val/T1',\n",
    "        '/kaggle/working/processed_data/val/T2',\n",
    "        '/kaggle/working/processed_data/val/label',\n",
    "        '/kaggle/working/processed_data/test/T1',\n",
    "        '/kaggle/working/processed_data/test/T2',\n",
    "        '/kaggle/working/processed_data/test/label'\n",
    "    ]\n",
    "    \n",
    "    required_files = [\n",
    "        '/kaggle/working/data_utils/__init__.py',\n",
    "        '/kaggle/working/data_utils/augment.py',\n",
    "        '/kaggle/working/data_utils/data_loader.py',\n",
    "        '/kaggle/working/data_utils/slicingPatch.py'\n",
    "    ]\n",
    "    \n",
    "    all_good = True\n",
    "    \n",
    "    for dir_path in required_dirs:\n",
    "        if os.path.exists(dir_path):\n",
    "            print(f\"   ✅ {dir_path}\")\n",
    "        else:\n",
    "            print(f\"   ❌ {dir_path}\")\n",
    "            all_good = False\n",
    "    \n",
    "    for file_path in required_files:\n",
    "        if os.path.exists(file_path):\n",
    "            print(f\"   ✅ {file_path}\")\n",
    "        else:\n",
    "            print(f\"   ❌ {file_path}\")\n",
    "            all_good = False\n",
    "    \n",
    "    return all_good\n",
    "\n",
    "def test_imports():\n",
    "    \"\"\"Test if all imports work correctly\"\"\"\n",
    "    print(\"\\n🔍 Testing imports...\")\n",
    "    \n",
    "    try:\n",
    "        # Add to path\n",
    "        sys.path.append('/kaggle/working')\n",
    "        \n",
    "        from data_utils.augment import Augmentation, mirrorPadding2D\n",
    "        print(\"   ✅ augment.py imports successful\")\n",
    "        \n",
    "        from data_utils.data_loader import WSIDataset\n",
    "        print(\"   ✅ data_loader.py imports successful\")\n",
    "        \n",
    "        return True\n",
    "    except ImportError as e:\n",
    "        print(f\"   ❌ Import error: {e}\")\n",
    "        return False\n",
    "\n",
    "def test_dataset_loading():\n",
    "    \"\"\"Test dataset loading functionality\"\"\"\n",
    "    print(\"\\n🔍 Testing dataset loading...\")\n",
    "    \n",
    "    # Check if original dataset exists\n",
    "    dataset_path = \"/kaggle/input/processed-levir-cd-dataset/LEVIR-CD+_256\"\n",
    "    \n",
    "    if not os.path.exists(dataset_path):\n",
    "        print(f\"   ⚠️  Original dataset not found at {dataset_path}\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        from data_utils.data_loader import WSIDataset\n",
    "        \n",
    "        # Test dataset creation\n",
    "        train_dataset = WSIDataset(root_dir=dataset_path, mode=\"train\")\n",
    "        val_dataset = WSIDataset(root_dir=dataset_path, mode=\"val\")\n",
    "        test_dataset = WSIDataset(root_dir=dataset_path, mode=\"test\")\n",
    "        \n",
    "        print(f\"   ✅ Datasets created successfully\")\n",
    "        print(f\"      Train samples: {len(train_dataset)}\")\n",
    "        print(f\"      Val samples: {len(val_dataset)}\")\n",
    "        print(f\"      Test samples: {len(test_dataset)}\")\n",
    "        \n",
    "        # Test loading a sample\n",
    "        if len(train_dataset) > 0:\n",
    "            sample = train_dataset[0]\n",
    "            print(f\"   ✅ Sample loaded successfully\")\n",
    "            print(f\"      img1 shape: {sample[0].shape}\")\n",
    "            print(f\"      img2 shape: {sample[1].shape}\")\n",
    "            print(f\"      label shape: {sample[4].shape}\")\n",
    "            print(f\"      filename: {sample[5]}\")\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Dataset loading error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "def test_augmentation():\n",
    "    \"\"\"Test augmentation functionality\"\"\"\n",
    "    print(\"\\n🔍 Testing augmentation...\")\n",
    "    \n",
    "    try:\n",
    "        from data_utils.augment import Augmentation, mirrorPadding2D\n",
    "        \n",
    "        # Create dummy images\n",
    "        img1 = Image.new('RGB', (256, 256), color='red')\n",
    "        img2 = Image.new('RGB', (256, 256), color='green')\n",
    "        label = Image.new('L', (256, 256), color='white')\n",
    "        \n",
    "        aug = Augmentation()\n",
    "        \n",
    "        # Test augmentation\n",
    "        augmented, bias_y, bias_x = aug.randomSpaceAugment([img1, img2, label])\n",
    "        \n",
    "        print(\"   ✅ Spatial augmentation works\")\n",
    "        \n",
    "        # Test mirror padding\n",
    "        test_array = np.random.randint(0, 255, (64, 64, 3), dtype=np.uint8)\n",
    "        padded = mirrorPadding2D(test_array)\n",
    "        \n",
    "        expected_shape = (128, 128, 3)\n",
    "        if padded.shape == expected_shape:\n",
    "            print(\"   ✅ Mirror padding works\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"   ❌ Mirror padding shape mismatch: {padded.shape} != {expected_shape}\")\n",
    "            return False\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Augmentation error: {e}\")\n",
    "        return False\n",
    "\n",
    "def test_dataloader():\n",
    "    \"\"\"Test PyTorch DataLoader functionality\"\"\"\n",
    "    print(\"\\n🔍 Testing DataLoader...\")\n",
    "    \n",
    "    try:\n",
    "        from data_utils.data_loader import WSIDataset\n",
    "        from torch.utils.data import DataLoader\n",
    "        \n",
    "        dataset_path = \"/kaggle/input/processed-levir-cd-dataset/LEVIR-CD+_256\"\n",
    "        \n",
    "        if not os.path.exists(dataset_path):\n",
    "            print(\"   ⚠️  Original dataset not available, skipping DataLoader test\")\n",
    "            return True\n",
    "        \n",
    "        # Create dataset and dataloader\n",
    "        dataset = WSIDataset(root_dir=dataset_path, mode=\"train\")\n",
    "        \n",
    "        if len(dataset) == 0:\n",
    "            print(\"   ⚠️  No samples in dataset, skipping DataLoader test\")\n",
    "            return True\n",
    "        \n",
    "        dataloader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=0)\n",
    "        \n",
    "        # Test loading a batch\n",
    "        for batch_idx, (img1, img2, label1, label2, change_label, filenames) in enumerate(dataloader):\n",
    "            print(f\"   ✅ DataLoader works\")\n",
    "            print(f\"      Batch size: {img1.shape[0]}\")\n",
    "            print(f\"      img1 batch shape: {img1.shape}\")\n",
    "            print(f\"      img2 batch shape: {img2.shape}\")\n",
    "            print(f\"      change_label batch shape: {change_label.shape}\")\n",
    "            break\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ DataLoader error: {e}\")\n",
    "        return False\n",
    "\n",
    "def main():\n",
    "    \"\"\"Run all tests\"\"\"\n",
    "    print(\"🧪 Running complete setup verification tests...\\n\")\n",
    "    \n",
    "    tests = [\n",
    "        (\"PyTorch Version\", test_pytorch_version),\n",
    "        (\"Directory Structure\", test_directory_structure),\n",
    "        (\"Imports\", test_imports),\n",
    "        (\"Dataset Loading\", test_dataset_loading),\n",
    "        (\"Augmentation\", test_augmentation),\n",
    "        (\"DataLoader\", test_dataloader)\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for test_name, test_func in tests:\n",
    "        try:\n",
    "            result = test_func()\n",
    "            results.append((test_name, result))\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ {test_name} failed with exception: {e}\")\n",
    "            results.append((test_name, False))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"🧪 TEST RESULTS SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    passed = 0\n",
    "    total = len(results)\n",
    "    \n",
    "    for test_name, result in results:\n",
    "        status = \"✅ PASS\" if result else \"❌ FAIL\"\n",
    "        print(f\"{test_name:20} : {status}\")\n",
    "        if result:\n",
    "            passed += 1\n",
    "    \n",
    "    print(\"-\"*50)\n",
    "    print(f\"TOTAL: {passed}/{total} tests passed\")\n",
    "    \n",
    "    if passed == total:\n",
    "        print(\"🎉 All tests passed! Your setup is ready for use.\")\n",
    "    else:\n",
    "        print(\"⚠️  Some tests failed. Please check the errors above.\")\n",
    "    \n",
    "    return passed == total\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the models folder and init.py file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- let's create the models directory and add an __init__.py file to make it a proper Python package.\n",
    "- Run this script first to create the models folder structure. This will:\n",
    "\n",
    "    - Create the /kaggle/working/models directory\n",
    "    - Add an __init__.py file to make it a proper Python package with all the necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T04:24:40.484996Z",
     "iopub.status.busy": "2025-09-05T04:24:40.484299Z",
     "iopub.status.idle": "2025-09-05T04:24:40.490579Z",
     "shell.execute_reply": "2025-09-05T04:24:40.489964Z",
     "shell.execute_reply.started": "2025-09-05T04:24:40.484970Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created models directory at: /kaggle/working/models\n",
      "Created __init__.py file\n",
      "\n",
      "Next step: We'll implement layers.py first since other files depend on it.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create the models directory\n",
    "models_dir = \"/kaggle/working/models\"\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Create __init__.py to make it a Python package\n",
    "init_content = '''\"\"\"\n",
    "Models package for CDNeXt implementation\n",
    "Contains ConvNeXt, ResNet, and custom layer implementations compatible with PyTorch 2.0\n",
    "\"\"\"\n",
    "\n",
    "from .cdnext import CDNeXt, get_cdnext\n",
    "from .convnext import ConvNeXt, convnext_tiny, convnext_small, convnext_base, convnext_large, convnext_xlarge, get_convnext\n",
    "from .layers import *\n",
    "from .resnet import ResNet, resnet18, resnet34, resnet50, resnet101, resnet152\n",
    "\n",
    "__all__ = [\n",
    "    'CDNeXt', 'get_cdnext',\n",
    "    'ConvNeXt', 'convnext_tiny', 'convnext_small', 'convnext_base', \n",
    "    'convnext_large', 'convnext_xlarge', 'get_convnext',\n",
    "    'ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152'\n",
    "]\n",
    "'''\n",
    "\n",
    "with open(os.path.join(models_dir, \"__init__.py\"), \"w\") as f:\n",
    "    f.write(init_content)\n",
    "\n",
    "print(f\"Created models directory at: {models_dir}\")\n",
    "print(\"Created __init__.py file\")\n",
    "print(\"\\nNext step: We'll implement layers.py first since other files depend on it.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I've created the layers.py file with all the custom layer classes needed for the CDNeXt implementation. Here are the key improvements I made for PyTorch 2.0 compatibility:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T04:24:53.469366Z",
     "iopub.status.busy": "2025-09-05T04:24:53.469073Z",
     "iopub.status.idle": "2025-09-05T04:24:53.480769Z",
     "shell.execute_reply": "2025-09-05T04:24:53.480231Z",
     "shell.execute_reply.started": "2025-09-05T04:24:53.469346Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /kaggle/working/models/layers.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/models/layers.py\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from einops import rearrange\n",
    "from timm.models.layers import trunc_normal_, DropPath\n",
    "\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "\n",
    "class SqueezeDoubleConvOld(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(SqueezeDoubleConvOld, self).__init__()\n",
    "        self.squeeze = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "        self.acfun = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.squeeze(x)\n",
    "        block_x = self.double_conv(x)\n",
    "        x = self.acfun(x + block_x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_planes, ratio=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc(self.avg_pool(x))\n",
    "        max_out = self.fc(self.max_pool(x))\n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, in_planes, CAon=True, SAon=True, ratio=16, kernel_size=7):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.CAon = CAon\n",
    "        self.SAon = SAon\n",
    "        if self.CAon:\n",
    "            self.ca = ChannelAttention(in_planes, ratio)\n",
    "        if self.SAon:\n",
    "            self.sa = SpatialAttention(kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.CAon:\n",
    "            x = self.ca(x) * x\n",
    "        if self.SAon:\n",
    "            x = self.sa(x) * x\n",
    "        return x\n",
    "\n",
    "\n",
    "class NonLocal2D(nn.Module):\n",
    "    def __init__(self, in_channels, inter_channels=None, dimension=2, sub_sample=False, bn_layer=True):\n",
    "        \"\"\"\n",
    "        :param in_channels:\n",
    "        :param inter_channels:\n",
    "        :param dimension:\n",
    "        :param sub_sample:\n",
    "        :param bn_layer:\n",
    "        \"\"\"\n",
    "        super(NonLocal2D, self).__init__()\n",
    "        assert dimension in [2]\n",
    "        self.dimension = dimension\n",
    "        self.sub_sample = sub_sample\n",
    "        self.in_channels = in_channels\n",
    "        self.inter_channels = inter_channels\n",
    "\n",
    "        if self.inter_channels is None:\n",
    "            self.inter_channels = in_channels // 2\n",
    "        if self.inter_channels == 0:\n",
    "            self.inter_channels = 1\n",
    "\n",
    "        if dimension == 2:\n",
    "            conv_nd = nn.Conv2d\n",
    "            max_pool_layer = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "            bn = nn.BatchNorm2d\n",
    "\n",
    "        self.g = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                         kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "        self.W = nn.Sequential(\n",
    "            conv_nd(in_channels=self.inter_channels, out_channels=self.in_channels,\n",
    "                    kernel_size=1, stride=1, padding=0),\n",
    "            bn(self.in_channels)\n",
    "        )\n",
    "\n",
    "        nn.init.constant_(self.W[1].weight, 0)\n",
    "        nn.init.constant_(self.W[1].bias, 0)\n",
    "\n",
    "        self.theta = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                     kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(self.inter_channels)\n",
    "        )\n",
    "        self.phi = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                     kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(self.inter_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, return_nl_map=False):\n",
    "        \"\"\"\n",
    "        :param x: (b, c, h, w)\n",
    "        :param return_nl_map: if True return z, nl_map, else only return z.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        g_x = self.g(x).view(batch_size, self.inter_channels, -1)\n",
    "        g_x = g_x.permute(0, 2, 1)\n",
    "\n",
    "        theta_x = self.theta(x).view(batch_size, self.inter_channels, -1)\n",
    "        theta_x = theta_x.permute(0, 2, 1)\n",
    "        phi_x = self.phi(x).view(batch_size, self.inter_channels, -1)\n",
    "\n",
    "        f = torch.matmul(theta_x, phi_x)\n",
    "        f_div_C = F.softmax(f, dim=-1)\n",
    "\n",
    "        y = torch.matmul(f_div_C, g_x)\n",
    "        y = y.permute(0, 2, 1).contiguous()\n",
    "        y = y.view(batch_size, self.inter_channels, *x.size()[2:])\n",
    "        W_y = self.W(y)\n",
    "        z = W_y + x\n",
    "\n",
    "        if return_nl_map:\n",
    "            return z, f_div_C\n",
    "        return z\n",
    "\n",
    "\n",
    "class SpatiotemporalAttentionFull(nn.Module):\n",
    "    def __init__(self, in_channels, inter_channels=None, dimension=2, sub_sample=False, bn_layer=True):\n",
    "        \"\"\"\n",
    "        :param in_channels:\n",
    "        :param inter_channels:\n",
    "        :param dimension:\n",
    "        :param sub_sample:\n",
    "        :param bn_layer:\n",
    "        \"\"\"\n",
    "        super(SpatiotemporalAttentionFull, self).__init__()\n",
    "        assert dimension in [2]\n",
    "        self.dimension = dimension\n",
    "        self.sub_sample = sub_sample\n",
    "        self.in_channels = in_channels\n",
    "        self.inter_channels = inter_channels\n",
    "\n",
    "        if self.inter_channels is None:\n",
    "            self.inter_channels = in_channels // 2\n",
    "        if self.inter_channels == 0:\n",
    "            self.inter_channels = 1\n",
    "\n",
    "        self.g = nn.Sequential(\n",
    "            nn.BatchNorm2d(self.in_channels),\n",
    "            nn.Conv2d(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                     kernel_size=1, stride=1, padding=0)\n",
    "        )\n",
    "\n",
    "        self.W = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=self.inter_channels, out_channels=self.in_channels,\n",
    "                     kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(self.in_channels)\n",
    "        )\n",
    "\n",
    "        self.theta = nn.Sequential(\n",
    "            nn.BatchNorm2d(self.in_channels),\n",
    "            nn.Conv2d(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                     kernel_size=1, stride=1, padding=0),\n",
    "        )\n",
    "        self.phi = nn.Sequential(\n",
    "            nn.BatchNorm2d(self.in_channels),\n",
    "            nn.Conv2d(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                     kernel_size=1, stride=1, padding=0),\n",
    "        )\n",
    "\n",
    "        self.energy_time_1_sf = nn.Softmax(dim=-1)\n",
    "        self.energy_time_2_sf = nn.Softmax(dim=-1)\n",
    "        self.energy_space_2s_sf = nn.Softmax(dim=-2)\n",
    "        self.energy_space_1s_sf = nn.Softmax(dim=-2)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        \"\"\"\n",
    "        :param x1, x2: (b, c, h, w)\n",
    "        :return: attended features\n",
    "        \"\"\"\n",
    "        batch_size = x1.size(0)\n",
    "\n",
    "        g_x11 = self.g(x1).reshape(batch_size, self.inter_channels, -1)\n",
    "        g_x12 = g_x11.permute(0, 2, 1)\n",
    "        g_x21 = self.g(x2).reshape(batch_size, self.inter_channels, -1)\n",
    "        g_x22 = g_x21.permute(0, 2, 1)\n",
    "\n",
    "        theta_x1 = self.theta(x1).reshape(batch_size, self.inter_channels, -1)\n",
    "        theta_x2 = theta_x1.permute(0, 2, 1)\n",
    "        phi_x1 = self.phi(x2).reshape(batch_size, self.inter_channels, -1)\n",
    "        phi_x2 = phi_x1.permute(0, 2, 1)\n",
    "\n",
    "        energy_time_1 = torch.matmul(theta_x1, phi_x2)\n",
    "        energy_time_2 = energy_time_1.permute(0, 2, 1)\n",
    "        energy_space_1 = torch.matmul(theta_x2, phi_x1)\n",
    "        energy_space_2 = energy_space_1.permute(0, 2, 1)\n",
    "\n",
    "        energy_time_1s = self.energy_time_1_sf(energy_time_1)\n",
    "        energy_time_2s = self.energy_time_2_sf(energy_time_2)\n",
    "        energy_space_2s = self.energy_space_2s_sf(energy_space_1)\n",
    "        energy_space_1s = self.energy_space_1s_sf(energy_space_2)\n",
    "\n",
    "        y1 = torch.matmul(torch.matmul(energy_time_2s, g_x11), energy_space_2s).contiguous()\n",
    "        y2 = torch.matmul(torch.matmul(energy_time_1s, g_x21), energy_space_1s).contiguous()\n",
    "\n",
    "        y1 = y1.reshape(batch_size, self.inter_channels, *x2.size()[2:])\n",
    "        y2 = y2.reshape(batch_size, self.inter_channels, *x1.size()[2:])\n",
    "\n",
    "        return x1 + self.W(y1), x2 + self.W(y2)\n",
    "\n",
    "\n",
    "class SpatiotemporalAttentionBase(nn.Module):\n",
    "    def __init__(self, in_channels, inter_channels=None, dimension=2, sub_sample=False, bn_layer=True):\n",
    "        \"\"\"\n",
    "        :param in_channels:\n",
    "        :param inter_channels:\n",
    "        :param dimension:\n",
    "        :param sub_sample:\n",
    "        :param bn_layer:\n",
    "        \"\"\"\n",
    "        super(SpatiotemporalAttentionBase, self).__init__()\n",
    "        assert dimension in [2]\n",
    "        self.dimension = dimension\n",
    "        self.sub_sample = sub_sample\n",
    "        self.in_channels = in_channels\n",
    "        self.inter_channels = inter_channels\n",
    "\n",
    "        if self.inter_channels is None:\n",
    "            self.inter_channels = in_channels // 2\n",
    "        if self.inter_channels == 0:\n",
    "            self.inter_channels = 1\n",
    "\n",
    "        self.g = nn.Sequential(\n",
    "            nn.BatchNorm2d(self.in_channels),\n",
    "            nn.Conv2d(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                     kernel_size=1, stride=1, padding=0)\n",
    "        )\n",
    "\n",
    "        self.W = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=self.inter_channels, out_channels=self.in_channels,\n",
    "                     kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(self.in_channels)\n",
    "        )\n",
    "\n",
    "        self.theta = nn.Sequential(\n",
    "            nn.BatchNorm2d(self.in_channels),\n",
    "            nn.Conv2d(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                     kernel_size=1, stride=1, padding=0),\n",
    "        )\n",
    "        self.phi = nn.Sequential(\n",
    "            nn.BatchNorm2d(self.in_channels),\n",
    "            nn.Conv2d(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                     kernel_size=1, stride=1, padding=0),\n",
    "        )\n",
    "\n",
    "        self.energy_space_2s_sf = nn.Softmax(dim=-2)\n",
    "        self.energy_space_1s_sf = nn.Softmax(dim=-2)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        \"\"\"\n",
    "        :param x1, x2: (b, c, h, w)\n",
    "        :return: attended features\n",
    "        \"\"\"\n",
    "        batch_size = x1.size(0)\n",
    "\n",
    "        g_x11 = self.g(x1).reshape(batch_size, self.inter_channels, -1)\n",
    "        g_x21 = self.g(x2).reshape(batch_size, self.inter_channels, -1)\n",
    "\n",
    "        theta_x1 = self.theta(x1).reshape(batch_size, self.inter_channels, -1)\n",
    "        theta_x2 = theta_x1.permute(0, 2, 1)\n",
    "        phi_x1 = self.phi(x2).reshape(batch_size, self.inter_channels, -1)\n",
    "\n",
    "        energy_space_1 = torch.matmul(theta_x2, phi_x1)\n",
    "        energy_space_2 = energy_space_1.permute(0, 2, 1)\n",
    "\n",
    "        energy_space_2s = self.energy_space_2s_sf(energy_space_1)\n",
    "        energy_space_1s = self.energy_space_1s_sf(energy_space_2)\n",
    "\n",
    "        y1 = torch.matmul(g_x11, energy_space_2s).contiguous()\n",
    "        y2 = torch.matmul(g_x21, energy_space_1s).contiguous()\n",
    "\n",
    "        y1 = y1.reshape(batch_size, self.inter_channels, *x2.size()[2:])\n",
    "        y2 = y2.reshape(batch_size, self.inter_channels, *x1.size()[2:])\n",
    "\n",
    "        return x1 + self.W(y1), x2 + self.W(y2)\n",
    "\n",
    "\n",
    "class SpatiotemporalAttentionFullNotWeightShared(nn.Module):\n",
    "    def __init__(self, in_channels, inter_channels=None, dimension=2, sub_sample=False, bn_layer=True):\n",
    "        \"\"\"\n",
    "        :param in_channels:\n",
    "        :param inter_channels:\n",
    "        :param dimension:\n",
    "        :param sub_sample:\n",
    "        :param bn_layer:\n",
    "        \"\"\"\n",
    "        super(SpatiotemporalAttentionFullNotWeightShared, self).__init__()\n",
    "        assert dimension in [2]\n",
    "        self.dimension = dimension\n",
    "        self.sub_sample = sub_sample\n",
    "        self.in_channels = in_channels\n",
    "        self.inter_channels = inter_channels\n",
    "\n",
    "        if self.inter_channels is None:\n",
    "            self.inter_channels = in_channels // 2\n",
    "        if self.inter_channels == 0:\n",
    "            self.inter_channels = 1\n",
    "\n",
    "        self.g1 = nn.Sequential(\n",
    "            nn.BatchNorm2d(self.in_channels),\n",
    "            nn.Conv2d(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                     kernel_size=1, stride=1, padding=0)\n",
    "        )\n",
    "        self.g2 = nn.Sequential(\n",
    "            nn.BatchNorm2d(self.in_channels),\n",
    "            nn.Conv2d(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                     kernel_size=1, stride=1, padding=0),\n",
    "        )\n",
    "\n",
    "        self.W1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=self.inter_channels, out_channels=self.in_channels,\n",
    "                     kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(self.in_channels)\n",
    "        )\n",
    "        self.W2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=self.inter_channels, out_channels=self.in_channels,\n",
    "                     kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(self.in_channels)\n",
    "        )\n",
    "\n",
    "        self.theta = nn.Sequential(\n",
    "            nn.BatchNorm2d(self.in_channels),\n",
    "            nn.Conv2d(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                     kernel_size=1, stride=1, padding=0),\n",
    "        )\n",
    "        self.phi = nn.Sequential(\n",
    "            nn.BatchNorm2d(self.in_channels),\n",
    "            nn.Conv2d(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                     kernel_size=1, stride=1, padding=0),\n",
    "        )\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        \"\"\"\n",
    "        :param x1, x2: (b, c, h, w)\n",
    "        :return: attended features\n",
    "        \"\"\"\n",
    "        batch_size = x1.size(0)\n",
    "\n",
    "        g_x11 = self.g1(x1).reshape(batch_size, self.inter_channels, -1)\n",
    "        g_x12 = g_x11.permute(0, 2, 1)\n",
    "        g_x21 = self.g2(x2).reshape(batch_size, self.inter_channels, -1)\n",
    "        g_x22 = g_x21.permute(0, 2, 1)\n",
    "\n",
    "        theta_x1 = self.theta(x1).reshape(batch_size, self.inter_channels, -1)\n",
    "        theta_x2 = theta_x1.permute(0, 2, 1)\n",
    "        phi_x1 = self.phi(x2).reshape(batch_size, self.inter_channels, -1)\n",
    "        phi_x2 = phi_x1.permute(0, 2, 1)\n",
    "\n",
    "        energy_time_1 = torch.matmul(theta_x1, phi_x2)\n",
    "        energy_time_2 = energy_time_1.permute(0, 2, 1)\n",
    "        energy_space_1 = torch.matmul(theta_x2, phi_x1)\n",
    "        energy_space_2 = energy_space_1.permute(0, 2, 1)\n",
    "\n",
    "        energy_time_1s = F.softmax(energy_time_1, dim=-1)\n",
    "        energy_time_2s = F.softmax(energy_time_2, dim=-1)\n",
    "        energy_space_2s = F.softmax(energy_space_1, dim=-2)\n",
    "        energy_space_1s = F.softmax(energy_space_2, dim=-2)\n",
    "\n",
    "        y1 = torch.matmul(torch.matmul(energy_time_2s, g_x11), energy_space_2s).contiguous()\n",
    "        y2 = torch.matmul(torch.matmul(energy_time_1s, g_x21), energy_space_1s).contiguous()\n",
    "\n",
    "        y1 = y1.reshape(batch_size, self.inter_channels, *x2.size()[2:])\n",
    "        y2 = y2.reshape(batch_size, self.inter_channels, *x1.size()[2:])\n",
    "\n",
    "        return x1 + self.W1(y1), x2 + self.W2(y2)\n",
    "\n",
    "\n",
    "class DANetModule(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super(DANetModule, self).__init__()\n",
    "        self.chanel_in = in_dim\n",
    "        self.sa = PAM_Module(in_dim)\n",
    "        self.sc = CAM_Module(in_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        sa_feat = self.sa(x)\n",
    "        sc_feat = self.sc(x)\n",
    "        return sa_feat + sc_feat\n",
    "\n",
    "\n",
    "class PAM_Module(nn.Module):\n",
    "    \"\"\" Position attention module\"\"\"\n",
    "    # Ref from SAGAN\n",
    "    def __init__(self, in_dim):\n",
    "        super(PAM_Module, self).__init__()\n",
    "        self.chanel_in = in_dim\n",
    "\n",
    "        self.query_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_dim, out_channels=in_dim//8, kernel_size=1),\n",
    "            nn.BatchNorm2d(in_dim//8),\n",
    "        )\n",
    "        self.key_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_dim, out_channels=in_dim//8, kernel_size=1),\n",
    "            nn.BatchNorm2d(in_dim//8),\n",
    "        )\n",
    "        self.value_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_dim, out_channels=in_dim, kernel_size=1),\n",
    "            nn.BatchNorm2d(in_dim),\n",
    "        )\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        inputs :\n",
    "            x : input feature maps( B X C X H X W)\n",
    "        returns :\n",
    "            out : attention value + input feature\n",
    "            attention: B X (HxW) X (HxW)\n",
    "        \"\"\"\n",
    "        m_batchsize, C, height, width = x.size()\n",
    "        proj_query = self.query_conv(x).view(m_batchsize, -1, width*height).permute(0, 2, 1)\n",
    "        proj_key = self.key_conv(x).view(m_batchsize, -1, width*height)\n",
    "        energy = torch.bmm(proj_query, proj_key)\n",
    "        attention = self.softmax(energy)\n",
    "        proj_value = self.value_conv(x).view(m_batchsize, -1, width*height)\n",
    "\n",
    "        out = torch.bmm(proj_value, attention.permute(0, 2, 1))\n",
    "        out = out.view(m_batchsize, C, height, width)\n",
    "\n",
    "        out = self.gamma*out + x\n",
    "        return out\n",
    "\n",
    "\n",
    "class CAM_Module(nn.Module):\n",
    "    \"\"\" Channel attention module\"\"\"\n",
    "    def __init__(self, in_dim):\n",
    "        super(CAM_Module, self).__init__()\n",
    "        self.chanel_in = in_dim\n",
    "\n",
    "        self.query_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_dim, out_channels=in_dim//8, kernel_size=1),\n",
    "            nn.BatchNorm2d(in_dim//8),\n",
    "        )\n",
    "        self.key_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_dim, out_channels=in_dim//8, kernel_size=1),\n",
    "            nn.BatchNorm2d(in_dim//8),\n",
    "        )\n",
    "        self.value_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_dim, out_channels=in_dim, kernel_size=1),\n",
    "            nn.BatchNorm2d(in_dim),\n",
    "        )\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        inputs :\n",
    "            x : input feature maps( B X C X H X W)\n",
    "        returns :\n",
    "            out : attention value + input feature\n",
    "            attention: B X C X C\n",
    "        \"\"\"\n",
    "        m_batchsize, C, height, width = x.size()\n",
    "        proj_query = self.query_conv(x).view(m_batchsize, C, -1)\n",
    "        proj_key = self.key_conv(x).view(m_batchsize, C, -1).permute(0, 2, 1)\n",
    "        energy = torch.bmm(proj_query, proj_key)\n",
    "        energy_new = torch.max(energy, -1, keepdim=True)[0].expand_as(energy) - energy\n",
    "        attention = self.softmax(energy_new)\n",
    "        proj_value = self.value_conv(x).view(m_batchsize, C, -1)\n",
    "\n",
    "        out = torch.bmm(attention, proj_value)\n",
    "        out = out.view(m_batchsize, C, height, width)\n",
    "\n",
    "        out = self.gamma*out + x\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I've created the resnet.py file with all the ResNet implementations. Here are the key improvements I made for PyTorch 2.0 compatibility:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T04:28:02.607249Z",
     "iopub.status.busy": "2025-09-05T04:28:02.606505Z",
     "iopub.status.idle": "2025-09-05T04:28:02.616870Z",
     "shell.execute_reply": "2025-09-05T04:28:02.616362Z",
     "shell.execute_reply.started": "2025-09-05T04:28:02.607222Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /kaggle/working/models/resnet.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/models/resnet.py\n",
    "\n",
    "from typing import Type, Any, Callable, Union, List, Optional\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "\n",
    "try:\n",
    "    from torch.hub import load_state_dict_from_url\n",
    "except ImportError:\n",
    "    from torch.utils.model_zoo import load_url as load_state_dict_from_url\n",
    "\n",
    "__all__ = [\n",
    "    \"ResNet\",\n",
    "    \"resnet18\",\n",
    "    \"resnet34\",\n",
    "    \"resnet50\",\n",
    "    \"resnet101\",\n",
    "    \"resnet152\",\n",
    "    \"resnext50_32x4d\",\n",
    "    \"resnext101_32x8d\",\n",
    "    \"wide_resnet50_2\",\n",
    "    \"wide_resnet101_2\",\n",
    "]\n",
    "\n",
    "# The model_urls are copied from https://pytorch.org/docs/1.6.0/_modules/torchvision/models/resnet.html#resnet18\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "    'resnext50_32x4d': 'https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth',\n",
    "    'resnext101_32x8d': 'https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth',\n",
    "    'wide_resnet50_2': 'https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth',\n",
    "    'wide_resnet101_2': 'https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth',\n",
    "}\n",
    "\n",
    "\n",
    "def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(\n",
    "        in_planes,\n",
    "        out_planes,\n",
    "        kernel_size=3,\n",
    "        stride=stride,\n",
    "        padding=dilation,\n",
    "        groups=groups,\n",
    "        bias=False,\n",
    "        dilation=dilation,\n",
    "    )\n",
    "\n",
    "\n",
    "def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion: int = 1\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: int,\n",
    "        planes: int,\n",
    "        stride: int = 1,\n",
    "        downsample: Optional[nn.Module] = None,\n",
    "        groups: int = 1,\n",
    "        base_width: int = 64,\n",
    "        dilation: int = 1,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError(\"BasicBlock only supports groups=1 and base_width=64\")\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\n",
    "    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\n",
    "    # according to \"Deep residual learning for image recognition\"https://arxiv.org/abs/1512.03385.\n",
    "    # This variant is also known as ResNet V1.5 and improves accuracy according to\n",
    "    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n",
    "\n",
    "    expansion: int = 4\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: int,\n",
    "        planes: int,\n",
    "        stride: int = 1,\n",
    "        downsample: Optional[nn.Module] = None,\n",
    "        groups: int = 1,\n",
    "        base_width: int = 64,\n",
    "        dilation: int = 1,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.0)) * groups\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        block: Type[Union[BasicBlock, Bottleneck]],\n",
    "        layers: List[int],\n",
    "        num_classes: int = 1000,\n",
    "        zero_init_residual: bool = False,\n",
    "        groups: int = 1,\n",
    "        width_per_group: int = 64,\n",
    "        replace_stride_with_dilation: Optional[List[bool]] = None,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "        strides: List[int] = [1, 1, 2, 2, 2]\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\n",
    "                \"replace_stride_with_dilation should be None \"\n",
    "                f\"or a 3-element tuple, got {replace_stride_with_dilation}\"\n",
    "            )\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=strides[0], padding=3, bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], stride=strides[1])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=strides[2], dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=strides[3], dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=strides[4], dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]\n",
    "\n",
    "    def _make_layer(\n",
    "        self,\n",
    "        block: Type[Union[BasicBlock, Bottleneck]],\n",
    "        planes: int,\n",
    "        blocks: int,\n",
    "        stride: int = 1,\n",
    "        dilate: bool = False,\n",
    "    ) -> nn.Sequential:\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(\n",
    "                self.inplanes, planes, stride, downsample, self.groups,\n",
    "                self.base_width, previous_dilation, norm_layer\n",
    "            )\n",
    "        )\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(\n",
    "                block(\n",
    "                    self.inplanes,\n",
    "                    planes,\n",
    "                    groups=self.groups,\n",
    "                    base_width=self.base_width,\n",
    "                    dilation=self.dilation,\n",
    "                    norm_layer=norm_layer,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self._forward_impl(x)\n",
    "\n",
    "\n",
    "def _resnet(\n",
    "    arch: str,\n",
    "    block: Type[Union[BasicBlock, Bottleneck]],\n",
    "    layers: List[int],\n",
    "    pretrained: bool,\n",
    "    progress: bool,\n",
    "    **kwargs: Any,\n",
    ") -> ResNet:\n",
    "    model = ResNet(block, layers, **kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = load_state_dict_from_url(model_urls[arch], progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet18(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> ResNet:\n",
    "    r\"\"\"ResNet-18 model from\n",
    "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet(\"resnet18\", BasicBlock, [2, 2, 2, 2], pretrained, progress, **kwargs)\n",
    "\n",
    "\n",
    "def resnet34(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> ResNet:\n",
    "    r\"\"\"ResNet-34 model from\n",
    "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet(\"resnet34\", BasicBlock, [3, 4, 6, 3], pretrained, progress, **kwargs)\n",
    "\n",
    "\n",
    "def resnet50(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> ResNet:\n",
    "    r\"\"\"ResNet-50 model from\n",
    "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet(\"resnet50\", Bottleneck, [3, 4, 6, 3], pretrained, progress, **kwargs)\n",
    "\n",
    "\n",
    "def resnet101(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> ResNet:\n",
    "    r\"\"\"ResNet-101 model from\n",
    "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet(\"resnet101\", Bottleneck, [3, 4, 23, 3], pretrained, progress, **kwargs)\n",
    "\n",
    "\n",
    "def resnet152(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> ResNet:\n",
    "    r\"\"\"ResNet-152 model from\n",
    "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet(\"resnet152\", Bottleneck, [3, 8, 36, 3], pretrained, progress, **kwargs)\n",
    "\n",
    "\n",
    "def resnext50_32x4d(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> ResNet:\n",
    "    r\"\"\"ResNeXt-50 32x4d model from\n",
    "    `\"Aggregated Residual Transformation for Deep Neural Networks\" <https://arxiv.org/pdf/1611.05431.pdf>`_.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    kwargs[\"groups\"] = 32\n",
    "    kwargs[\"width_per_group\"] = 4\n",
    "    return _resnet(\"resnext50_32x4d\", Bottleneck, [3, 4, 6, 3], pretrained, progress, **kwargs)\n",
    "\n",
    "\n",
    "def resnext101_32x8d(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> ResNet:\n",
    "    r\"\"\"ResNeXt-101 32x8d model from\n",
    "    `\"Aggregated Residual Transformation for Deep Neural Networks\" <https://arxiv.org/pdf/1611.05431.pdf>`_.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    kwargs[\"groups\"] = 32\n",
    "    kwargs[\"width_per_group\"] = 8\n",
    "    return _resnet(\"resnext101_32x8d\", Bottleneck, [3, 4, 23, 3], pretrained, progress, **kwargs)\n",
    "\n",
    "\n",
    "def wide_resnet50_2(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> ResNet:\n",
    "    r\"\"\"Wide ResNet-50-2 model from\n",
    "    `\"Wide Residual Networks\" <https://arxiv.org/pdf/1605.07146.pdf>`_.\n",
    "    The model is the same as ResNet except for the bottleneck number of channels\n",
    "    which is twice larger in every block. The number of channels in outer 1x1\n",
    "    convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048\n",
    "    channels, and in Wide ResNet-50-2 has 2048-1024-2048.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    kwargs[\"width_per_group\"] = 64 * 2\n",
    "    return _resnet(\"wide_resnet50_2\", Bottleneck, [3, 4, 6, 3], pretrained, progress, **kwargs)\n",
    "\n",
    "\n",
    "def wide_resnet101_2(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> ResNet:\n",
    "    r\"\"\"Wide ResNet-101-2 model from\n",
    "    `\"Wide Residual Networks\" <https://arxiv.org/pdf/1605.07146.pdf>`_.\n",
    "    The model is the same as ResNet except for the bottleneck number of channels\n",
    "    which is twice larger in every block. The number of channels in outer 1x1\n",
    "    convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048\n",
    "    channels, and in Wide ResNet-50-2 has 2048-1024-2048.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    kwargs[\"width_per_group\"] = 64 * 2\n",
    "    return _resnet(\"wide_resnet101_2\", Bottleneck, [3, 4, 23, 3], pretrained, progress, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I've created the convnext.py file with the ConvNeXt implementation. Here are the key improvements I made for PyTorch 2.0 compatibility:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T04:28:08.320693Z",
     "iopub.status.busy": "2025-09-05T04:28:08.320410Z",
     "iopub.status.idle": "2025-09-05T04:28:08.329774Z",
     "shell.execute_reply": "2025-09-05T04:28:08.329169Z",
     "shell.execute_reply.started": "2025-09-05T04:28:08.320671Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /kaggle/working/models/convnext.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/models/convnext.py\n",
    "\n",
    "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
    "# All rights reserved.\n",
    "# This source code is licensed under the license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from timm.models.layers import trunc_normal_, DropPath\n",
    "from timm.models.registry import register_model\n",
    "from .resnet import resnet18\n",
    "\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    r\"\"\" LayerNorm that supports two data formats: channels_last (default) or channels_first.\n",
    "    The ordering of the dimensions in the inputs. channels_last corresponds to inputs with\n",
    "    shape (batch_size, height, width, channels) while channels_first corresponds to inputs\n",
    "    with shape (batch_size, channels, height, width).\n",
    "    \"\"\"\n",
    "    def __init__(self, normalized_shape, eps=1e-6, data_format=\"channels_last\"):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(normalized_shape))\n",
    "        self.bias = nn.Parameter(torch.zeros(normalized_shape))\n",
    "        self.eps = eps\n",
    "        self.data_format = data_format\n",
    "        if self.data_format not in [\"channels_last\", \"channels_first\"]:\n",
    "            raise NotImplementedError\n",
    "        self.normalized_shape = (normalized_shape, )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.data_format == \"channels_last\":\n",
    "            return F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n",
    "        elif self.data_format == \"channels_first\":\n",
    "            u = x.mean(1, keepdim=True)\n",
    "            s = (x - u).pow(2).mean(1, keepdim=True)\n",
    "            x = (x - u) / torch.sqrt(s + self.eps)\n",
    "            x = self.weight[:, None, None] * x + self.bias[:, None, None]\n",
    "            return x\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    r\"\"\" ConvNeXt Block. There are two equivalent implementations:\n",
    "    (1) DwConv -> LayerNorm (channels_first) -> 1x1 Conv -> GELU -> 1x1 Conv; all in (N, C, H, W)\n",
    "    (2) DwConv -> Permute to (N, H, W, C); LayerNorm (channels_last) -> Linear -> GELU -> Linear; Permute back\n",
    "    We use (2) as we find it slightly faster in PyTorch\n",
    "    \n",
    "    Args:\n",
    "        dim (int): Number of input channels.\n",
    "        drop_path (float): Stochastic depth rate. Default: 0.0\n",
    "        layer_scale_init_value (float): Init value for Layer Scale. Default: 1e-6.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, drop_path=0., layer_scale_init_value=1e-6):\n",
    "        super().__init__()\n",
    "        self.dwconv = nn.Conv2d(dim, dim, kernel_size=7, padding=3, groups=dim)  # depthwise conv\n",
    "        self.norm = LayerNorm(dim, eps=1e-6)\n",
    "        self.pwconv1 = nn.Linear(dim, 4 * dim)  # pointwise/1x1 convs, implemented with linear layers\n",
    "        self.act = nn.GELU()\n",
    "        self.pwconv2 = nn.Linear(4 * dim, dim)\n",
    "        self.gamma = nn.Parameter(layer_scale_init_value * torch.ones((dim)), \n",
    "                                 requires_grad=True) if layer_scale_init_value > 0 else None\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        input = x\n",
    "        x = self.dwconv(x)\n",
    "        x = x.permute(0, 2, 3, 1)  # (N, C, H, W) -> (N, H, W, C)\n",
    "        x = self.norm(x)\n",
    "        x = self.pwconv1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pwconv2(x)\n",
    "        if self.gamma is not None:\n",
    "            x = self.gamma * x\n",
    "        x = x.permute(0, 3, 1, 2)  # (N, H, W, C) -> (N, C, H, W)\n",
    "\n",
    "        x = input + self.drop_path(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ConvNeXt(nn.Module):\n",
    "    r\"\"\" ConvNeXt\n",
    "        A PyTorch impl of : `A ConvNet for the 2020s`  -\n",
    "          https://arxiv.org/pdf/2201.03545.pdf\n",
    "\n",
    "    Args:\n",
    "        in_chans (int): Number of input image channels. Default: 3\n",
    "        num_classes (int): Number of classes for classification head. Default: 1000\n",
    "        depths (tuple(int)): Number of blocks at each stage. Default: [3, 3, 9, 3]\n",
    "        dims (int): Feature dimension at each stage. Default: [96, 192, 384, 768]\n",
    "        drop_path_rate (float): Stochastic depth rate. Default: 0.\n",
    "        layer_scale_init_value (float): Init value for Layer Scale. Default: 1e-6.\n",
    "        head_init_scale (float): Init scaling value for classifier weights and biases. Default: 1.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_chans=3, num_classes=1000,\n",
    "                 depths=[3, 3, 9, 3], dims=[96, 192, 384, 768], drop_path_rate=0.,\n",
    "                 layer_scale_init_value=1e-6, head_init_scale=1.,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.downsample_layers = nn.ModuleList()  # stem and 3 intermediate downsampling conv layers\n",
    "        stem = nn.Sequential(\n",
    "            nn.Conv2d(in_chans, dims[0], kernel_size=4, stride=4),\n",
    "            LayerNorm(dims[0], eps=1e-6, data_format=\"channels_first\")\n",
    "        )\n",
    "        self.downsample_layers.append(stem)\n",
    "        for i in range(3):\n",
    "            downsample_layer = nn.Sequential(\n",
    "                LayerNorm(dims[i], eps=1e-6, data_format=\"channels_first\"),\n",
    "                nn.Conv2d(dims[i], dims[i+1], kernel_size=2, stride=2),\n",
    "            )\n",
    "            self.downsample_layers.append(downsample_layer)\n",
    "\n",
    "        self.stages = nn.ModuleList()  # 4 feature resolution stages, each consisting of multiple residual blocks\n",
    "        dp_rates = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))]\n",
    "        cur = 0\n",
    "        for i in range(4):\n",
    "            stage = nn.Sequential(\n",
    "                *[Block(dim=dims[i], drop_path=dp_rates[cur + j], \n",
    "                        layer_scale_init_value=layer_scale_init_value) for j in range(depths[i])]\n",
    "            )\n",
    "            self.stages.append(stage)\n",
    "            cur += depths[i]\n",
    "\n",
    "        self.norm = nn.LayerNorm(dims[-1], eps=1e-6)  # final norm layer\n",
    "        self.head = nn.Linear(dims[-1], num_classes)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "        self.head.weight.data.mul_(head_init_scale)\n",
    "        self.head.bias.data.mul_(head_init_scale)\n",
    "\n",
    "        self.feature = []\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        for i in range(4):\n",
    "            x = self.downsample_layers[i](x)\n",
    "            x = self.stages[i](x)\n",
    "        return self.norm(x.mean([-2, -1]))  # global average pooling, (N, C, H, W) -> (N, C)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    \"convnext_tiny_1k\": \"https://dl.fbaipublicfiles.com/convnext/convnext_tiny_1k_224_ema.pth\",\n",
    "    \"convnext_small_1k\": \"https://dl.fbaipublicfiles.com/convnext/convnext_small_1k_224_ema.pth\",\n",
    "    \"convnext_base_1k\": \"https://dl.fbaipublicfiles.com/convnext/convnext_base_1k_224_ema.pth\",\n",
    "    \"convnext_large_1k\": \"https://dl.fbaipublicfiles.com/convnext/convnext_large_1k_224_ema.pth\",\n",
    "    \"convnext_tiny_22k\": \"https://dl.fbaipublicfiles.com/convnext/convnext_tiny_22k_224.pth\",\n",
    "    \"convnext_small_22k\": \"https://dl.fbaipublicfiles.com/convnext/convnext_small_22k_224.pth\",\n",
    "    \"convnext_base_22k\": \"https://dl.fbaipublicfiles.com/convnext/convnext_base_22k_224.pth\",\n",
    "    \"convnext_large_22k\": \"https://dl.fbaipublicfiles.com/convnext/convnext_large_22k_224.pth\",\n",
    "    \"convnext_xlarge_22k\": \"https://dl.fbaipublicfiles.com/convnext/convnext_xlarge_22k_224.pth\",\n",
    "    \"convnext_tiny_22k_384\": \"https://dl.fbaipublicfiles.com/convnext/convnext_tiny_22k_1k_384.pth\",\n",
    "    \"convnext_small_22k_384\": \"https://dl.fbaipublicfiles.com/convnext/convnext_small_22k_1k_384.pth\",\n",
    "    \"convnext_base_22k_384\": \"https://dl.fbaipublicfiles.com/convnext/convnext_base_22k_1k_384.pth\",\n",
    "    \"convnext_large_22k_384\": \"https://dl.fbaipublicfiles.com/convnext/convnext_large_22k_1k_384.pth\",\n",
    "    \"convnext_xlarge_22k_384\": \"https://dl.fbaipublicfiles.com/convnext/convnext_xlarge_22k_1k_384_ema.pth\",\n",
    "}\n",
    "\n",
    "\n",
    "@register_model\n",
    "def convnext_tiny(pretrained=False, in_22k=False, classes=1000, resolution=None, **kwargs):\n",
    "    # 1k is 1000, 22k is 21841\n",
    "    model = ConvNeXt(num_classes=classes, depths=[3, 3, 9, 3], dims=[96, 192, 384, 768], **kwargs)\n",
    "    \n",
    "    resolution_suffix = \"_\"+str(resolution) if resolution == 384 else \"\"\n",
    "    if pretrained:\n",
    "        url = model_urls['convnext_tiny_22k'+resolution_suffix] if in_22k else model_urls['convnext_tiny_1k']\n",
    "        checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location=\"cpu\", check_hash=True)\n",
    "        if classes != 1000 and classes != 21841:\n",
    "            random_state_dict = model.state_dict()\n",
    "            checkpoint['model']['head.weight'] = random_state_dict['head.weight']\n",
    "            checkpoint['model']['head.bias'] = random_state_dict['head.bias']\n",
    "        model.load_state_dict(checkpoint[\"model\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "@register_model\n",
    "def convnext_small(pretrained=False, in_22k=False, classes=1000, resolution=None, **kwargs):\n",
    "    model = ConvNeXt(num_classes=classes, depths=[3, 3, 27, 3], dims=[96, 192, 384, 768], **kwargs)\n",
    "    \n",
    "    resolution_suffix = \"_\"+str(resolution) if resolution == 384 else \"\"\n",
    "    if pretrained:\n",
    "        url = model_urls['convnext_small_22k'+resolution_suffix] if in_22k else model_urls['convnext_small_1k']\n",
    "        checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location=\"cpu\")\n",
    "        if classes != 1000 and classes != 21841:\n",
    "            random_state_dict = model.state_dict()\n",
    "            checkpoint['model']['head.weight'] = random_state_dict['head.weight']\n",
    "            checkpoint['model']['head.bias'] = random_state_dict['head.bias']\n",
    "        model.load_state_dict(checkpoint[\"model\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "@register_model\n",
    "def convnext_base(pretrained=False, in_22k=False, classes=1000, resolution=None, **kwargs):\n",
    "    model = ConvNeXt(num_classes=classes, depths=[3, 3, 27, 3], dims=[128, 256, 512, 1024], **kwargs)\n",
    "    \n",
    "    resolution_suffix = \"_\"+str(resolution) if resolution == 384 else \"\"\n",
    "    if pretrained:\n",
    "        url = model_urls['convnext_base_22k'+resolution_suffix] if in_22k else model_urls['convnext_base_1k']\n",
    "        checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location=\"cpu\")\n",
    "        if classes != 1000 and classes != 21841:\n",
    "            random_state_dict = model.state_dict()\n",
    "            checkpoint['model']['head.weight'] = random_state_dict['head.weight']\n",
    "            checkpoint['model']['head.bias'] = random_state_dict['head.bias']\n",
    "        model.load_state_dict(checkpoint[\"model\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "@register_model\n",
    "def convnext_large(pretrained=False, in_22k=False, classes=1000, resolution=None, **kwargs):\n",
    "    model = ConvNeXt(num_classes=classes, depths=[3, 3, 27, 3], dims=[192, 384, 768, 1536], **kwargs)\n",
    "    \n",
    "    resolution_suffix = \"_\"+str(resolution) if resolution == 384 else \"\"\n",
    "    if pretrained:\n",
    "        url = model_urls['convnext_large_22k'+resolution_suffix] if in_22k else model_urls['convnext_large_1k']\n",
    "        checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location=\"cpu\")\n",
    "        if classes != 1000 and classes != 21841:\n",
    "            random_state_dict = model.state_dict()\n",
    "            checkpoint['model']['head.weight'] = random_state_dict['head.weight']\n",
    "            checkpoint['model']['head.bias'] = random_state_dict['head.bias']\n",
    "        model.load_state_dict(checkpoint[\"model\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "@register_model\n",
    "def convnext_xlarge(pretrained=False, in_22k=False, classes=1000, resolution=None, **kwargs):\n",
    "    model = ConvNeXt(num_classes=classes, depths=[3, 3, 27, 3], dims=[256, 512, 1024, 2048], **kwargs)\n",
    "    \n",
    "    resolution_suffix = \"_\"+str(resolution) if resolution == 384 else \"\"\n",
    "    if pretrained:\n",
    "        assert in_22k, \"only ImageNet-22K pre-trained ConvNeXt-XL is available; please set in_22k=True\"\n",
    "        url = model_urls['convnext_xlarge_22k'+resolution_suffix]\n",
    "        checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location=\"cpu\")\n",
    "        if classes != 1000 and classes != 21841:\n",
    "            random_state_dict = model.state_dict()\n",
    "            checkpoint['model']['head.weight'] = random_state_dict['head.weight']\n",
    "            checkpoint['model']['head.bias'] = random_state_dict['head.bias']\n",
    "        model.load_state_dict(checkpoint[\"model\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "@register_model\n",
    "def get_convnext(pretrained=False, backbone_scale='tiny', in_22k=True, classes=1000, resolution=224, **kwargs):\n",
    "    if backbone_scale == \"tiny\":\n",
    "        depths, dims = [3, 3, 9, 3], [96, 192, 384, 768]\n",
    "    elif backbone_scale == \"small\":\n",
    "        depths, dims = [3, 3, 27, 3], [96, 192, 384, 768]\n",
    "    elif backbone_scale == \"base\":\n",
    "        depths, dims = [3, 3, 27, 3], [128, 256, 512, 1024]\n",
    "    elif backbone_scale == \"large\":\n",
    "        depths, dims = [3, 3, 27, 3], [192, 384, 768, 1536]\n",
    "    elif backbone_scale == \"xlarge\":\n",
    "        depths, dims = [3, 3, 27, 3], [256, 512, 1024, 2048]\n",
    "    elif backbone_scale == \"resnet18\":\n",
    "        model = resnet18(pretrained=pretrained, **kwargs)\n",
    "        return model\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown backbone_scale: {backbone_scale}\")\n",
    "\n",
    "    model = ConvNeXt(num_classes=classes, depths=depths, dims=dims, **kwargs)\n",
    "    \n",
    "    if pretrained:\n",
    "        clsNums = \"22k\" if in_22k else \"1k\"\n",
    "        resolution_suffix = \"_\"+str(resolution) if resolution == 384 else \"\"\n",
    "        url = model_urls[\"convnext_\"+backbone_scale+\"_\"+clsNums+resolution_suffix]\n",
    "        checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location=\"cpu\")\n",
    "        \n",
    "        if classes != 1000 and classes != 21841:\n",
    "            random_state_dict = model.state_dict()\n",
    "            checkpoint['model']['head.weight'] = random_state_dict['head.weight']\n",
    "            checkpoint['model']['head.bias'] = random_state_dict['head.bias']\n",
    "        model.load_state_dict(checkpoint[\"model\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T04:28:13.141900Z",
     "iopub.status.busy": "2025-09-05T04:28:13.141354Z",
     "iopub.status.idle": "2025-09-05T04:28:13.149829Z",
     "shell.execute_reply": "2025-09-05T04:28:13.149150Z",
     "shell.execute_reply.started": "2025-09-05T04:28:13.141877Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /kaggle/working/models/cdnext.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/models/cdnext.py\n",
    "\n",
    "from collections import OrderedDict\n",
    "from .layers import *\n",
    "import copy\n",
    "from .convnext import convnext_tiny, convnext_small, convnext_base, convnext_large, convnext_xlarge, get_convnext\n",
    "from .resnet import resnet18\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange\n",
    "\n",
    "__all__ = ['CDNeXt', 'get_cdnext']\n",
    "\n",
    "\n",
    "class CDNeXt(nn.Module):\n",
    "    def __init__(self, encoder, backbone_scale=\"tiny\", out_channels=2, \n",
    "                 isTemporalAttention=[1, 2, 3, 4], isCBAM=[0, 0, 0, 0], \n",
    "                 isNonlocal=[0, 0, 0, 0], **kwargs):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.isFeatureFusion = True\n",
    "        self.CAon = False\n",
    "        self.SAon = False\n",
    "        self.isCBAMconcat = False\n",
    "        self.isNonlocalConcat = False\n",
    "        self.AttentionModule = DANetModule  # NonLocal2D, DANetModule\n",
    "        \n",
    "        self.isTemporalAttention = isTemporalAttention\n",
    "        self.SpatiotemporalAttentionModule = SpatiotemporalAttentionFull  # SpatiotemporalAttentionBase, SpatiotemporalAttentionFull, SpatiotemporalAttentionFullNotWeightShared\n",
    "        self.isCBAM = isCBAM\n",
    "        self.isNonlocal = isNonlocal\n",
    "        self.encoderName = backbone_scale\n",
    "        \n",
    "        if \"resnet\" in self.encoderName:\n",
    "            self.encoderNameScale = 2\n",
    "        else:\n",
    "            self.encoderNameScale = 4\n",
    "            \n",
    "        self.AdvSupResult = []\n",
    "        self.downScale = [16, 8, 4, 0]\n",
    "        self.stageNumber = 4\n",
    "        \n",
    "        self.backbone_depth = {\n",
    "            'tiny': [3, 3, 9, 3],\n",
    "            'small': [3, 3, 27, 3],\n",
    "            'base': [3, 3, 27, 3],\n",
    "            'large': [3, 3, 27, 3],\n",
    "            'xlarge': [3, 3, 27, 3],\n",
    "            \"resnet18\": [2, 2, 2, 2]\n",
    "        }\n",
    "        \n",
    "        self.backbone_dims = {\n",
    "            'tiny': [96, 192, 384, 768],\n",
    "            'small': [96, 192, 384, 768],\n",
    "            'base': [128, 256, 512, 1024],\n",
    "            'large': [192, 384, 768, 1536],\n",
    "            'xlarge': [256, 512, 1024, 2048],\n",
    "            \"resnet18\": [64, 128, 256, 512]\n",
    "        }\n",
    "        \n",
    "        self.size_dict = {\n",
    "            'tiny': [96, 192, 384, 768],\n",
    "            'small': [96, 192, 384, 768],\n",
    "            'base': [128, 256, 512, 1024],\n",
    "            'large': [192, 384, 768, 1536],\n",
    "            'xlarge': [256, 512, 1024, 2048],\n",
    "            \"resnet18\": [64, 128, 256, 512]\n",
    "        }\n",
    "\n",
    "        # source constructor\n",
    "        # init attention module\n",
    "        self.CBAMs = []\n",
    "        self.TemporalAttentions = []\n",
    "        self.Nonlocals = []\n",
    "        self.ChangeSqueezeConv = []\n",
    "        \n",
    "        # module sequence: F.interpolate, TemporalAttention, AdversialSupervised, concat feature, conv\n",
    "        for index in range(self.stageNumber):\n",
    "            if index == 0:\n",
    "                if self.isCBAM[index] != 0:\n",
    "                    if self.isCBAMconcat:\n",
    "                        self.CBAMs.append(CBAM(self.n_channels*2, CAon=self.CAon, SAon=self.SAon))\n",
    "                    else:\n",
    "                        self.CBAMs.append(CBAM(self.n_channels, CAon=self.CAon, SAon=self.SAon))\n",
    "                \n",
    "                if self.isTemporalAttention[index] != 0:\n",
    "                    self.TemporalAttentions.append(self.SpatiotemporalAttentionModule(self.size_change[index]))\n",
    "                \n",
    "                if self.isNonlocal[index] != 0:\n",
    "                    if self.isNonlocalConcat:\n",
    "                        self.Nonlocals.append(self.AttentionModule(self.n_channels*2))\n",
    "                    else:\n",
    "                        self.Nonlocals.append(self.AttentionModule(self.n_channels))\n",
    "                \n",
    "                self.ChangeSqueezeConv.append(SqueezeDoubleConvOld(self.n_channels*2, self.n_channels))\n",
    "            else:\n",
    "                if self.isCBAM[index] != 0:\n",
    "                    if self.isCBAMconcat:\n",
    "                        self.CBAMs.append(CBAM(self.size_change[index]*2, CAon=self.CAon, SAon=self.SAon))\n",
    "                    else:\n",
    "                        self.CBAMs.append(CBAM(self.size_change[index], CAon=self.CAon, SAon=self.SAon))\n",
    "                \n",
    "                if self.isTemporalAttention[index] != 0:\n",
    "                    self.TemporalAttentions.append(self.SpatiotemporalAttentionModule(self.size_change[index]))\n",
    "                \n",
    "                if self.isNonlocal[index] != 0:\n",
    "                    if self.isNonlocalConcat:\n",
    "                        self.Nonlocals.append(self.AttentionModule(self.size_change[index]*2))\n",
    "                    else:\n",
    "                        self.Nonlocals.append(self.AttentionModule(self.size_change[index]))\n",
    "                \n",
    "                self.ChangeSqueezeConv.append(SqueezeDoubleConvOld(self.size_change[index]*4, self.size_change[index]))\n",
    "\n",
    "        self.CBAMs = nn.ModuleList(self.CBAMs)\n",
    "        self.TemporalAttentions = nn.ModuleList(self.TemporalAttentions)\n",
    "        self.Nonlocals = nn.ModuleList(self.Nonlocals)\n",
    "        self.ChangeSqueezeConv = nn.ModuleList(self.ChangeSqueezeConv)\n",
    "\n",
    "        if self.isFeatureFusion == True:\n",
    "            self.ChangeFinalSqueezeConv = SqueezeDoubleConvOld(sum(self.size_change), self.size_change[-1]*self.encoderNameScale)\n",
    "            self.ChangeFinalConv = nn.Sequential(\n",
    "                SqueezeDoubleConvOld(self.size_change[-1]*self.encoderNameScale, self.size_change[-1]),\n",
    "                nn.Conv2d(self.size_change[-1], out_channels, kernel_size=1)\n",
    "            )\n",
    "        else:\n",
    "            self.ChangeFinalSqueezeConv = SqueezeDoubleConvOld(self.size_change[-2], self.size_change[-1]*self.encoderNameScale)\n",
    "            self.ChangeFinalConv = nn.Sequential(\n",
    "                SqueezeDoubleConvOld(self.size_change[-1]*self.encoderNameScale, self.size_change[-1]),\n",
    "                nn.Conv2d(self.size_change[-1], out_channels, kernel_size=1)\n",
    "            )\n",
    "\n",
    "        # self.softmax = nn.Softmax(dim=1)\n",
    "        self.register_hook(self.encoder)\n",
    "        self.backboneFeatures = []\n",
    "\n",
    "    def register_hook(self, backbone):\n",
    "        if \"resnet\" in self.encoderName:\n",
    "            def hook(module, input, output):\n",
    "                self.backboneFeatures.append(output)\n",
    "            depth = self.backbone_depth[self.encoderName]\n",
    "            for index, depth_num in enumerate(depth):\n",
    "                getattr(backbone, \"layer\"+str(index+1)).register_forward_hook(hook)\n",
    "        else:\n",
    "            def hook(module, input, output):\n",
    "                self.backboneFeatures.append(output)\n",
    "            depth = self.backbone_depth[self.encoderName]\n",
    "            for index, depth_num in enumerate(depth):\n",
    "                backbone.stages[index][depth_num-1].register_forward_hook(hook)\n",
    "\n",
    "    @property\n",
    "    def n_channels(self):\n",
    "        return self.backbone_dims[self.encoderName][-1]\n",
    "\n",
    "    @property\n",
    "    def size_change(self):\n",
    "        size_dict = copy.deepcopy(self.size_dict)\n",
    "        size_dict = size_dict[self.encoderName]\n",
    "        size_dict.reverse() # Remove the [:-1] slice\n",
    "        return size_dict\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        input_1 = x1\n",
    "        input_2 = x2\n",
    "        \n",
    "        _ = self.encoder(x1)\n",
    "        _ = self.encoder(x2)\n",
    "        \n",
    "        blocks1 = self.backboneFeatures[0:self.stageNumber]\n",
    "        blocks2 = self.backboneFeatures[self.stageNumber:]\n",
    "        self.backboneFeatures = []\n",
    "        \n",
    "        FusionFeatures = []\n",
    "        change = None\n",
    "        \n",
    "        for stage in range(self.stageNumber):\n",
    "            moduleIdx = stage\n",
    "            eff_last_1 = blocks1.pop()  # .permute(0, 3, 1, 2)\n",
    "            eff_last_2 = blocks2.pop()  # .permute(0, 3, 1, 2)\n",
    "            \n",
    "            if self.isTemporalAttention[stage] != 0:\n",
    "                moduleRealIdx = self.isTemporalAttention[stage] - 1\n",
    "                eff_last_1, eff_last_2 = self.TemporalAttentions[moduleRealIdx](eff_last_1, eff_last_2)\n",
    "            \n",
    "            if self.isNonlocal[stage] != 0:\n",
    "                moduleIdx = self.isNonlocal[stage] - 1\n",
    "                if self.isNonlocalConcat:\n",
    "                    eff_last = self.Nonlocals[moduleIdx](torch.cat([eff_last_1, eff_last_2], dim=1))\n",
    "                    sliceNum = eff_last.shape[1]//2\n",
    "                    eff_last_1, eff_last_2 = eff_last[:, 0:sliceNum], eff_last[:, sliceNum:]\n",
    "                else:\n",
    "                    eff_last_1, eff_last_2 = self.Nonlocals[moduleIdx](eff_last_1), self.Nonlocals[moduleIdx](eff_last_2)\n",
    "            \n",
    "            if self.isCBAM[stage] != 0:\n",
    "                moduleIdx = self.isCBAM[stage] - 1\n",
    "                if self.isCBAMconcat:\n",
    "                    eff_last = self.CBAMs[moduleIdx](torch.cat([eff_last_1, eff_last_2], dim=1))\n",
    "                    sliceNum = eff_last.shape[1]//2\n",
    "                    eff_last_1, eff_last_2 = eff_last[:, 0:sliceNum], eff_last[:, sliceNum:]\n",
    "                else:\n",
    "                    eff_last_1, eff_last_2 = self.CBAMs[moduleIdx](eff_last_1), self.CBAMs[moduleIdx](eff_last_2)\n",
    "            \n",
    "            if stage == 0:\n",
    "                change = torch.cat([eff_last_1, eff_last_2], dim=1)\n",
    "            else:\n",
    "                change = torch.cat([eff_last_1, eff_last_2, change], dim=1)\n",
    "            \n",
    "            if stage == self.stageNumber-1:\n",
    "                change = self.ChangeSqueezeConv[stage](change)\n",
    "                FusionFeatures.append(change)\n",
    "            else:\n",
    "                change = self.ChangeSqueezeConv[stage](change)\n",
    "                FusionFeatures.append(change)\n",
    "                change = F.interpolate(change, scale_factor=2., mode='bilinear', align_corners=True)\n",
    "\n",
    "        if self.isFeatureFusion == True:\n",
    "            for index, down in enumerate(self.downScale):\n",
    "                FusionFeatures[index] = F.interpolate(FusionFeatures[index], \n",
    "                                                     scale_factor=2**(self.stageNumber-index-1), \n",
    "                                                     mode='bilinear', align_corners=True)\n",
    "            fusion = torch.cat(FusionFeatures, dim=1)\n",
    "            # ADD THESE DEBUG PRINTS\n",
    "            print(f\"=== FEATURE FUSION DEBUG ===\")\n",
    "            print(f\"FusionFeatures shapes: {[f.shape for f in FusionFeatures]}\")\n",
    "            print(f\"fusion shape: {fusion.shape}\")\n",
    "            print(f\"size_change: {self.size_change}\")\n",
    "            print(f\"sum(size_change[:-1]): {sum(self.size_change[:-1])}\")\n",
    "            print(f\"Expected channels: {sum(self.size_change[:-1])}\")\n",
    "            print(f\"Actual channels: {fusion.shape[1]}\")\n",
    "        else:\n",
    "            fusion = change\n",
    "\n",
    "        change = self.ChangeFinalSqueezeConv(fusion)\n",
    "        change = F.interpolate(change, scale_factor=self.encoderNameScale, mode='bilinear', align_corners=True)\n",
    "        change = self.ChangeFinalConv(change)\n",
    "        \n",
    "        return change\n",
    "\n",
    "\n",
    "def get_cdnext(out_channels=2, backbone_scale=\"tiny\", pretrained=True, in_22k=True, \n",
    "               resolution=384, backbone_trainable=False, **kwargs):\n",
    "    print(\"is pretrained: \", pretrained)\n",
    "    encoder = get_convnext(pretrained=pretrained, backbone_scale=backbone_scale, \n",
    "                          classes=out_channels, in_22k=in_22k, resolution=resolution, **kwargs)\n",
    "    model = CDNeXt(encoder, backbone_scale=backbone_scale, out_channels=out_channels, **kwargs)\n",
    "    \n",
    "    if \"resnet\" in backbone_scale:\n",
    "        pass\n",
    "    else:\n",
    "        if backbone_trainable == False:\n",
    "            for name, value in model.named_parameters():\n",
    "                if \"encoder\" in name:\n",
    "                    value.requires_grad = False\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T04:28:18.318443Z",
     "iopub.status.busy": "2025-09-05T04:28:18.317930Z",
     "iopub.status.idle": "2025-09-05T04:28:18.329243Z",
     "shell.execute_reply": "2025-09-05T04:28:18.328545Z",
     "shell.execute_reply.started": "2025-09-05T04:28:18.318418Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /kaggle/working/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/train.py\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.utils import data as data_\n",
    "from tqdm import tqdm\n",
    "from models.cdnext import get_cdnext\n",
    "from data_utils.data_loader import WSIDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Process\n",
    "from prettytable import PrettyTable\n",
    "import random\n",
    "\n",
    "labelNameList = [\"change\"]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Dataset path setting - updated for Kaggle structure\n",
    "ROOTDIR = {\n",
    "    \"LEVIRCD\": \"/kaggle/working/processed_data\",\n",
    "}\n",
    "\n",
    "backboneName = \"tiny\"  # 'tiny','small','base','resnet18'\n",
    "isPretrained = True\n",
    "SIMULATE_BATCH_SIZE = 32\n",
    "BATCH_SIZE = 16\n",
    "accumulate_steps = SIMULATE_BATCH_SIZE // BATCH_SIZE\n",
    "train_num_workers = 4\n",
    "test_num_workers = 4\n",
    "saveDatasetName = \"-\".join(ROOTDIR.keys())\n",
    "save_dir = \"checkpoint/\" + saveDatasetName\n",
    "total_epoch = 100\n",
    "use_cuda = True\n",
    "num_classes = len(labelNameList)\n",
    "result_dir = \"checkpoint/\" + saveDatasetName\n",
    "lossType = \"balance ce\"\n",
    "learning_rate = 4e-5\n",
    "itersDisplayMetrics = [\"Acc\", \"Pre\", \"Rec\", \"IoU\", \"TNR\", \"Loss\"]\n",
    "epochsDisplayMetrics = [\"Acc\", \"Pre\", \"Rec\", \"IoU\", \"TNR\", \"F1\", \"Kappa\", \"Loss\"]\n",
    "plot_metrics = [\"F1\", \"IoU\", \"Loss\"]\n",
    "plot_metrics.sort()\n",
    "stage = [\"train\", \"val\"]\n",
    "stage.sort()\n",
    "use_amp = True\n",
    "\n",
    "\n",
    "def setup_seed(seed):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    # torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "def data_loader(ROOTDIR, mode=\"train\", taskList=labelNameList,\n",
    "                miniScale=1, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, \n",
    "                total_fold=5, valid_fold=5):\n",
    "    dataset = WSIDataset(root_dir=ROOTDIR, mode=mode, taskList=taskList, \n",
    "                        total_fold=total_fold, valid_fold=valid_fold, miniScale=miniScale)\n",
    "    dataloader = data_.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=train_num_workers,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    return dataset, dataloader\n",
    "\n",
    "\n",
    "def save_checkpoints(model, step):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    filename = \"CDNet_\" + str(step) + \"_\" + \"-\".join(labelNameList) + \".pth\"\n",
    "    torch.save(model.state_dict(), os.path.join(save_dir, filename))\n",
    "    print(f\" Save checkpoint {step.split('_')[0]} to {filename}. \\n\")\n",
    "\n",
    "\n",
    "def train(model, optimizer, index, trainDataLoader, criterion, scaler, dataSetClass, loss_branch=None):\n",
    "    showRowLen = num_classes + 1\n",
    "    tempMetricsList = [\"TP\", \"FP\", \"TN\", \"FN\", \"Acc\", \"Pre\", \"Rec\", \"IoU\", \"TNR\", \"Loss\"]\n",
    "    epochMetricsList = [\"TP\", \"FP\", \"TN\", \"FN\", \"Acc\", \"Pre\", \"Rec\", \"IoU\", \"TNR\", \"F1\", \"Kappa\", \"Loss\"]\n",
    "    \n",
    "    tempMetrics = {key: [0] * showRowLen for key in tempMetricsList}\n",
    "    epochMetrics = {key: [0] * showRowLen for key in epochMetricsList}\n",
    "    \n",
    "    model.train()\n",
    "    skipIdx = len(trainDataLoader) // accumulate_steps * accumulate_steps\n",
    "    \n",
    "    for batch_idx, (img1, img2, label1, label2, img_change, dir_name) in tqdm(enumerate(trainDataLoader)):\n",
    "        img1, img2, label1, label2, img_change = img1.float(), img2.float(), label1.float(), label2.float(), img_change.float()\n",
    "        \n",
    "        # ADD THESE DEBUG PRINTS\n",
    "        if batch_idx == 0:  # Only print for first batch to avoid spam\n",
    "            print(f\"=== TRAINING BATCH DEBUG ===\")\n",
    "            print(f\"img1 shape: {img1.shape}\")\n",
    "            print(f\"img2 shape: {img2.shape}\")\n",
    "            print(f\"img_change shape: {img_change.shape}\")\n",
    "            print(f\"img_change dtype: {img_change.dtype}\")\n",
    "            print(f\"img_change unique values: {torch.unique(img_change)}\")\n",
    "            print(f\"img_change min/max: {img_change.min()}/{img_change.max()}\")\n",
    "\n",
    "\n",
    "\n",
    "        if batch_idx >= skipIdx:\n",
    "            continue\n",
    "            \n",
    "        if use_cuda:\n",
    "            img1 = img1.to(device)\n",
    "            img2 = img2.to(device)\n",
    "            img_change = img_change.to(device)\n",
    "        \n",
    "        if scaler is None:\n",
    "            output_change = model(img1, img2)\n",
    "            # Add this right after the model forward pass\n",
    "            if batch_idx == 0:\n",
    "                print(f\"=== MODEL OUTPUT DEBUG ===\")\n",
    "                print(f\"output_change shape: {output_change.shape}\")\n",
    "                print(f\"output_change dtype: {output_change.dtype}\")\n",
    "                print(f\"output_change min/max: {output_change.min()}/{output_change.max()}\")\n",
    "            loss = criterion_N_with_AdvSup([output_change], [img_change], model.AdvSupResult, criterion)\n",
    "            (loss / accumulate_steps).backward()\n",
    "        else:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                output_change = model(img1, img2)\n",
    "                if batch_idx == 0:\n",
    "                    print(f\"=== MODEL OUTPUT DEBUG ===\")\n",
    "                    print(f\"output_change shape: {output_change.shape}\")\n",
    "                    print(f\"output_change dtype: {output_change.dtype}\")\n",
    "                    print(f\"output_change min/max: {output_change.min()}/{output_change.max()}\")\n",
    "                \n",
    "                loss = criterion_N_with_AdvSup([output_change], [img_change], model.AdvSupResult, criterion)\n",
    "            scaler.scale(loss / accumulate_steps).backward()\n",
    "        \n",
    "        if (batch_idx + 1) % accumulate_steps == 0:\n",
    "            if scaler is None:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            else:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "        \n",
    "        output_change = F.softmax(output_change, dim=1)\n",
    "        confusionMatrix(epochMetrics, [output_change[:, 1, :, :].detach()], [img_change.detach()])\n",
    "        epochMetrics[\"Loss\"][0] += loss.detach().cpu().item()\n",
    "    \n",
    "    epochMetrics[\"Loss\"][0] = round(epochMetrics[\"Loss\"][0] / len(trainDataLoader), 5)\n",
    "    calculateMatrix(epochMetrics)\n",
    "    printTable(epochMetrics, epochsDisplayMetrics, labelNameList)\n",
    "    returnMetrics = {key: epochMetrics[key][-1] for key in plot_metrics}\n",
    "    return returnMetrics\n",
    "\n",
    "\n",
    "def validate(model, index, valDataLoader, criterion, scaler, minival=False):\n",
    "    showRowLen = num_classes + 1\n",
    "    epochMetricsList = [\"TP\", \"FP\", \"TN\", \"FN\", \"Acc\", \"Pre\", \"Rec\", \"IoU\", \"TNR\", \"F1\", \"Kappa\", \"Loss\"]\n",
    "    epochMetrics = {key: [0] * showRowLen for key in epochMetricsList}\n",
    "    \n",
    "    dir_fold = result_dir + os.sep + str(index)\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (img1, img2, label1, label2, img_change, dir_name) in tqdm(enumerate(valDataLoader)):\n",
    "            img1, img2, img_change = img1.float(), img2.float(), img_change.float()\n",
    "            \n",
    "            if use_cuda:\n",
    "                img1 = img1.to(device)\n",
    "                img2 = img2.to(device)\n",
    "                img_change = img_change.to(device)\n",
    "            \n",
    "            if scaler is None:\n",
    "                output_change = model(img1, img2)\n",
    "                loss = criterion_N_with_AdvSup([output_change], [img_change], model.AdvSupResult, criterion)\n",
    "            else:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    output_change = model(img1, img2)\n",
    "                    loss = criterion_N_with_AdvSup([output_change], [img_change], model.AdvSupResult, criterion)\n",
    "            \n",
    "            output_change = F.softmax(output_change, dim=1)\n",
    "            confusionMatrix(epochMetrics, [output_change[:, 1, :, :].detach()], [img_change.detach()])\n",
    "            epochMetrics[\"Loss\"][0] += loss.detach().cpu().item()\n",
    "            \n",
    "            result_change = [result_dir + os.sep + str(index) + os.sep + i + '_change.png' for i in dir_name]\n",
    "            output_change = output_change[:, 1, :, :].detach().float()\n",
    "            output_change[output_change >= 0.5] = 255\n",
    "            output_change[output_change < 0.5] = 0\n",
    "            output_change = output_change.cpu().numpy()\n",
    "    \n",
    "    epochMetrics[\"Loss\"][0] = round(epochMetrics[\"Loss\"][0] / len(valDataLoader), 5)\n",
    "    calculateMatrix(epochMetrics)\n",
    "    printTable(epochMetrics, epochsDisplayMetrics, labelNameList)\n",
    "    returnMetrics = {key: epochMetrics[key][-1] for key in plot_metrics}\n",
    "    return returnMetrics\n",
    "\n",
    "\n",
    "def criterion_N_with_AdvSup(pred, label, AdvSupResult, criterion):\n",
    "    # ADD THIS DEBUG BLOCK\n",
    "    print(f\"=== LOSS FUNCTION DEBUG ===\")\n",
    "    print(f\"pred[0] shape: {pred[0].shape}\")\n",
    "    print(f\"label[0] shape: {label[0].shape}\")\n",
    "    print(f\"label[0] dtype: {label[0].dtype}\")\n",
    "    print(f\"label[0].long() shape: {label[0].long().shape}\")\n",
    "    print(f\"label[0] unique values: {torch.unique(label[0])}\")\n",
    "    count = 0\n",
    "    loss = 0.0\n",
    "    for name, func in criterion.items():\n",
    "        if func is not None:\n",
    "            count += 1\n",
    "            loss_temp = 0.0\n",
    "            if name == \"focalloss\":\n",
    "                loss_temp = func(pred[0], label[0].long())\n",
    "            elif name == \"adversialsupervised\" and len(AdvSupResult) != 0:\n",
    "                batch_size = label[0].size(0)\n",
    "                for i in AdvSupResult:\n",
    "                    unchange = func(i[:, 0], 1 - label[0].view(batch_size, -1).mean(dim=1)).mean()\n",
    "                    change = func(i[:, 1], label[0].view(batch_size, -1).mean(dim=1)).mean()\n",
    "                    loss_temp += (unchange + change) / 2\n",
    "                loss_temp = loss_temp / len(AdvSupResult)\n",
    "                loss_temp = 0.1 * loss_temp\n",
    "            elif name == \"bce\":\n",
    "                loss_temp = func(pred[0], label[0].long()).mean()\n",
    "            elif name == \"diceloss\":\n",
    "                loss_temp = 0.1 * func(pred[0][:, 1, :, :], label[0]).mean()\n",
    "            loss += loss_temp\n",
    "    return loss / count if count > 0 else loss\n",
    "\n",
    "\n",
    "def criterion_N(pred, label, criterion):\n",
    "    loss_c = criterion[0](pred[0].permute(0, 2, 3, 1).reshape(-1, 2), label[0].reshape(-1).long()).mean()\n",
    "    for i in range(1, 2):\n",
    "        loss_c += criterion[i](pred[0], label[0].long())\n",
    "    loss = loss_c\n",
    "    return loss / len(criterion)\n",
    "\n",
    "\n",
    "def confusionMatrix(metrics, pred, label, threshold=0.5):\n",
    "    for i in range(len(label)):\n",
    "        singlePred = (pred[i] >= threshold).byte()\n",
    "        singleLabel = (label[i] > threshold).byte()\n",
    "        plus = singlePred + singleLabel\n",
    "        FN = (singlePred < singleLabel).sum()\n",
    "        FP = (singlePred > singleLabel).sum()\n",
    "        TP = (plus == 2).sum()\n",
    "        TN = (plus == 0).sum()\n",
    "        \n",
    "        metrics[\"TN\"][i] = metrics[\"TN\"][i] + TN.cpu().item()\n",
    "        metrics[\"FP\"][i] = metrics[\"FP\"][i] + FP.cpu().item()\n",
    "        metrics[\"FN\"][i] = metrics[\"FN\"][i] + FN.cpu().item()\n",
    "        metrics[\"TP\"][i] = metrics[\"TP\"][i] + TP.cpu().item()\n",
    "    return\n",
    "\n",
    "\n",
    "def calculateMatrix(metrics):\n",
    "    for i in range(len(metrics[\"Acc\"]) - 1):\n",
    "        TN = metrics[\"TN\"][i]\n",
    "        FP = metrics[\"FP\"][i]\n",
    "        FN = metrics[\"FN\"][i]\n",
    "        TP = metrics[\"TP\"][i]\n",
    "        \n",
    "        metrics[\"Acc\"][i] = (TP + TN) / (TP + TN + FP + FN)\n",
    "        metrics[\"Pre\"][i] = round(TP / (TP + FP + 0.0001) * 100, 3)\n",
    "        metrics[\"Rec\"][i] = round(TP / (TP + FN + 0.0001) * 100, 3)\n",
    "        metrics[\"IoU\"][i] = round(TP / (TP + FP + FN) * 100, 3)\n",
    "        metrics[\"TNR\"][i] = round(TN / (TN + FP) * 100, 3)\n",
    "        metrics[\"F1\"][i] = round(2 * TP / (2 * TP + FP + FN) * 100, 3)\n",
    "        \n",
    "        Pe = ((TP + FP) * (TP + FN) + (TN + FN) * (TN + FP)) / ((TP + FP + TN + FN) ** 2)\n",
    "        metrics[\"Kappa\"][i] = round((metrics[\"Acc\"][i] - Pe) / (1 - Pe) * 100, 3)\n",
    "        metrics[\"Acc\"][i] = round(metrics[\"Acc\"][i] * 100, 3)\n",
    "    \n",
    "    for k, v in metrics.items():\n",
    "        if len(metrics[\"Acc\"]) > 1:\n",
    "            metrics[k][-1] = sum(metrics[k][:-1]) / (len(metrics[\"Acc\"]) - 1)\n",
    "\n",
    "\n",
    "def printTable(metrics, displayMetrics, labelName):\n",
    "    labelNameCopy = labelName + [\"average\"]\n",
    "    table = PrettyTable([\"\"] + displayMetrics)\n",
    "    for i in range(len(metrics[\"Acc\"]) - 1):\n",
    "        row = [labelNameCopy[i]] + [metrics[key][i] for key in displayMetrics]\n",
    "        table.add_row(row)\n",
    "    print(table)\n",
    "\n",
    "\n",
    "def saveMetricsPlot(metrics, plot_metrics, stage):\n",
    "    stage_name = list(metrics.keys())\n",
    "    stage_name.sort()\n",
    "    epochs = len(list(metrics.values())[0])\n",
    "    \n",
    "    # Draw plot\n",
    "    x = range(epochs)\n",
    "    len_stage = 1\n",
    "    len_metric = len(plot_metrics)\n",
    "    fig, axs = plt.subplots(len_metric, len_stage, dpi=600, figsize=(10, 10))\n",
    "    \n",
    "    if len_metric == 1:\n",
    "        axs = [axs]\n",
    "    \n",
    "    for index, each_subplot in enumerate(plot_metrics):\n",
    "        if each_subplot == \"Loss\":\n",
    "            axs[index].set_ylim(0, 0.1)\n",
    "        else:\n",
    "            axs[index].set_ylim(0, 100)\n",
    "        \n",
    "        color = ['b', 'r', 'g', 'c', 'm', 'y', 'k', 'w']\n",
    "        for each_stage in stage:\n",
    "            axs[index].plot(x, metrics[each_subplot + \" \" + each_stage], label=each_stage)\n",
    "        axs[index].set_title(each_subplot)\n",
    "        axs[index].legend()\n",
    "    \n",
    "    fig.savefig(save_dir + os.sep + \"results.png\", bbox_inches=\"tight\")\n",
    "    plt.close(\"all\")\n",
    "\n",
    "\n",
    "def creatPlotProcess(metric_record, plot_metrics, stage):\n",
    "    plotProcess = Process(target=saveMetricsPlot, args=(metric_record, plot_metrics, stage))\n",
    "    plotProcess.start()\n",
    "    plotProcess.join()\n",
    "\n",
    "\n",
    "def main():\n",
    "    setup_seed(42)\n",
    "    model = get_cdnext(out_channels=2, backbone_scale=backboneName, \n",
    "                      pretrained=isPretrained, backbone_trainable=True).cuda()\n",
    "    modelParams = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    print(model)\n",
    "    model.to(device)\n",
    "    model.zero_grad()\n",
    "    \n",
    "    optimizer = optim.AdamW(modelParams, lr=learning_rate, weight_decay=0.05, amsgrad=True)\n",
    "    \n",
    "    if use_amp == True:\n",
    "        scaler = GradScaler()\n",
    "    else:\n",
    "        scaler = None\n",
    "    \n",
    "    trainDataset, trainDataLoader = data_loader(ROOTDIR, mode=\"train\", taskList=labelNameList,\n",
    "                                               miniScale=1, batch_size=BATCH_SIZE,\n",
    "                                               shuffle=True, drop_last=True, \n",
    "                                               total_fold=5, valid_fold=5)\n",
    "    \n",
    "    valDataset, valDataloader = data_loader(ROOTDIR, mode=\"val\", taskList=labelNameList, \n",
    "                                          miniScale=1, batch_size=BATCH_SIZE * 2, \n",
    "                                          shuffle=False, drop_last=False,\n",
    "                                          total_fold=5, valid_fold=5)\n",
    "    \n",
    "    if lossType == \"balance ce\":\n",
    "        criterion = {\n",
    "            \"focalloss\": None,  # FocalLoss().to(device),\n",
    "            \"adversialsupervised\": None,  # nn.L1Loss().to(device),\n",
    "            \"bce\": nn.CrossEntropyLoss().to(device),  # None,\n",
    "            \"diceloss\": None,  # DiceLoss().to(device),\n",
    "        }\n",
    "    \n",
    "    start_i = 0\n",
    "    metric_record = {(plot_metrics[i // len(stage)] + \" \" + stage[i % len(stage)]): [] \n",
    "                    for i in range(len(stage) * len(plot_metrics))}\n",
    "    \n",
    "    for i in range(start_i, total_epoch + 1):\n",
    "        print(f\" ====> epoch: {i}, learning:{optimizer.state_dict()['param_groups'][0]['lr']:.7f}, train and valid metrics: \")\n",
    "        \n",
    "        train_avg_metric = train(model, optimizer, i, trainDataLoader, criterion, scaler, trainDataset)\n",
    "        for key in train_avg_metric.keys():\n",
    "            metric_record[key + \" train\"].append(train_avg_metric[key])\n",
    "        \n",
    "        val_avg_metric = validate(model, i, valDataloader, criterion, scaler, minival=False)\n",
    "        for key in val_avg_metric.keys():\n",
    "            metric_record[key + \" val\"].append(val_avg_metric[key])\n",
    "        \n",
    "        cp_filename = f\"epoch-{i}_trainF1{train_avg_metric['F1']:.2f}_valF1{val_avg_metric['F1']:.2f}\"\n",
    "        save_checkpoints(model, cp_filename)\n",
    "        \n",
    "        creatPlotProcess(metric_record, plot_metrics, stage)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# list_kaggle_working.py\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def get_tree(path: Path, max_depth: int = 4, _depth=0, include_hidden=False):\n",
    "    \"\"\"Return nested dict representing directory tree of `path` up to max_depth.\"\"\"\n",
    "    if _depth > max_depth:\n",
    "        return None\n",
    "    node = {\"type\": \"dir\" if path.is_dir() else \"file\", \"name\": path.name}\n",
    "    if path.is_dir():\n",
    "        node[\"children\"] = []\n",
    "        try:\n",
    "            entries = sorted(path.iterdir(), key=lambda p: (not p.is_dir(), p.name.lower()))\n",
    "        except PermissionError:\n",
    "            return {\"type\": \"dir\", \"name\": path.name, \"error\": \"PermissionError\"}\n",
    "        for e in entries:\n",
    "            if not include_hidden and e.name.startswith(\".\"):\n",
    "                continue\n",
    "            child = get_tree(e, max_depth=max_depth, _depth=_depth+1, include_hidden=include_hidden)\n",
    "            if child is not None:\n",
    "                node[\"children\"].append(child)\n",
    "    else:\n",
    "        node[\"size_bytes\"] = path.stat().st_size\n",
    "    return node\n",
    "\n",
    "def print_tree(node, prefix=\"\"):\n",
    "    \"\"\"Pretty-print the tree structure returned by get_tree.\"\"\"\n",
    "    if node is None:\n",
    "        return\n",
    "    marker = \"📁\" if node[\"type\"] == \"dir\" else \"📄\"\n",
    "    print(f\"{prefix}{marker} {node['name']}\", end=\"\")\n",
    "    if node[\"type\"] == \"file\":\n",
    "        print(f\"  ({node.get('size_bytes', 0)} bytes)\")\n",
    "    else:\n",
    "        if node.get(\"error\"):\n",
    "            print(f\"  -- {node['error']}\")\n",
    "        else:\n",
    "            print()\n",
    "            for i, child in enumerate(node.get(\"children\", [])):\n",
    "                is_last = (i == len(node[\"children\"]) - 1)\n",
    "                new_prefix = prefix + (\"    \" if is_last else \"│   \")\n",
    "                print_tree(child, prefix + (\"└── \" if is_last else \"├── \"))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = Path(\"/kaggle/working\")  # change if you want another path\n",
    "    tree = get_tree(root, max_depth=3, include_hidden=False)  # adjust max_depth\n",
    "    print_tree(tree)\n",
    "\n",
    "    # optional: save JSON\n",
    "    out_json = \"/kaggle/working/working_tree.json\"\n",
    "    with open(out_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(tree, f, indent=2)\n",
    "    print(f\"\\nSaved tree JSON to: {out_json}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Don't upload this file (Don't run the below cell)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T01:06:53.037533Z",
     "iopub.status.busy": "2025-09-05T01:06:53.037294Z",
     "iopub.status.idle": "2025-09-05T01:06:53.047491Z",
     "shell.execute_reply": "2025-09-05T01:06:53.046706Z",
     "shell.execute_reply.started": "2025-09-05T01:06:53.037515Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /kaggle/working/eval.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/eval.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data as data_\n",
    "from tqdm import tqdm\n",
    "from models.cdnext import get_cdnext\n",
    "from PIL import Image\n",
    "from data_utils.data_loader import WSIDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Process\n",
    "from prettytable import PrettyTable\n",
    "import glob\n",
    "import random\n",
    "\n",
    "labelNameList = [\"change\"]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Dataset path setting - updated for Kaggle structure\n",
    "ROOTDIR = {\n",
    "    \"LEVIRCD\": \"/kaggle/working/processed_data\",\n",
    "}\n",
    "\n",
    "backboneName = \"tiny\"  # 'tiny','small','base','resnet18'\n",
    "SIMULATE_BATCH_SIZE = 32\n",
    "BATCH_SIZE = 16\n",
    "accumulate_steps = SIMULATE_BATCH_SIZE // BATCH_SIZE\n",
    "train_num_workers = 2\n",
    "test_num_workers = 2\n",
    "saveDatasetName = \"-\".join(ROOTDIR.keys())\n",
    "save_dir = \"checkpoint/\" + saveDatasetName\n",
    "total_epoch = 400\n",
    "use_cuda = True\n",
    "num_classes = len(labelNameList)\n",
    "result_dir = \"results/\" + saveDatasetName\n",
    "lossType = \"balance ce\"  # \"ce\" means cross entropy, \"focal\" means focal loss, \"balance ce\" means no parameters ce\n",
    "learning_rate = 4e-5\n",
    "itersDisplayMetrics = [\"Acc\", \"Pre\", \"Rec\", \"IoU\", \"TNR\", \"Loss\"]\n",
    "epochsDisplayMetrics = [\"Acc\", \"Pre\", \"Rec\", \"IoU\", \"TNR\", \"F1\", \"Kappa\", \"Loss\"]\n",
    "plot_metrics = [\"F1\", \"IoU\", \"Loss\"]\n",
    "plot_metrics.sort()\n",
    "stage = [\"train\", \"val\"]\n",
    "stage.sort()\n",
    "use_amp = True\n",
    "model_path = \"checkpoint/LEVIRCD/*.pth\"  # Updated for Kaggle structure\n",
    "\n",
    "\n",
    "def setup_seed(seed):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    # torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "def data_loader(ROOTDIR, mode=\"train\", taskList=labelNameList,\n",
    "                miniScale=1, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, \n",
    "                total_fold=5, valid_fold=5):\n",
    "    dataset = WSIDataset(root_dir=ROOTDIR, mode=mode, taskList=taskList, \n",
    "                        total_fold=total_fold, valid_fold=valid_fold, miniScale=miniScale)\n",
    "    dataloader = data_.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=train_num_workers,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        pin_memory=True  # Load into memory to improve speed\n",
    "    )\n",
    "    return dataset, dataloader\n",
    "\n",
    "\n",
    "def save_checkpoints(model, step):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    filename = \"CDNet_\" + str(step) + \"_\" + \"-\".join(labelNameList) + \".pth\"\n",
    "    torch.save(model.state_dict(), os.path.join(save_dir, filename))\n",
    "    print(f\" Save checkpoint {step.split('_')[0]} to {filename}. \\n\")\n",
    "\n",
    "\n",
    "def validate(model, index, valDataLoader, criterion, scaler, minival=False):\n",
    "    showRowLen = num_classes + 1\n",
    "    epochMetricsList = [\"TP\", \"FP\", \"TN\", \"FN\", \"Acc\", \"Pre\", \"Rec\", \"IoU\", \"TNR\", \"F1\", \"Kappa\", \"Loss\"]\n",
    "    epochMetrics = {key: [0] * showRowLen for key in epochMetricsList}\n",
    "    \n",
    "    dir_fold = result_dir + os.sep + str(index)\n",
    "    if not os.path.exists(dir_fold):\n",
    "        os.makedirs(dir_fold, exist_ok=True)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (img1, img2, label1, label2, img_change, dir_name) in tqdm(enumerate(valDataLoader)):\n",
    "            img1, img2, img_change = img1.float(), img2.float(), img_change.float()\n",
    "            \n",
    "            if use_cuda:\n",
    "                img1 = img1.to(device)\n",
    "                img2 = img2.to(device)\n",
    "                img_change = img_change.to(device)\n",
    "            \n",
    "            # Reset gradients\n",
    "            if scaler is None:\n",
    "                output_change = model(img1, img2)\n",
    "                loss = criterion_N_with_AdvSup([output_change], [img_change], model.AdvSupResult, criterion)\n",
    "            else:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    output_change = model(img1, img2)\n",
    "                    loss = criterion_N_with_AdvSup([output_change], [img_change], model.AdvSupResult, criterion)\n",
    "            \n",
    "            output_change = F.softmax(output_change, dim=1)\n",
    "            confusionMatrix(epochMetrics, [output_change[:, 1, :, :].detach()], [img_change.detach()])\n",
    "            epochMetrics[\"Loss\"][0] += loss.detach().cpu().item()\n",
    "            \n",
    "            result_change = [result_dir + os.sep + str(index) + os.sep + i + '_change.png' for i in dir_name]\n",
    "            output_change = output_change[:, 1, :, :].detach().float()\n",
    "            output_change[output_change >= 0.5] = 255\n",
    "            output_change[output_change < 0.5] = 0\n",
    "            output_change = output_change.cpu().numpy()\n",
    "            \n",
    "            # Save prediction images\n",
    "            for i in range(output_change.shape[0]):\n",
    "                temp_output_change = Image.fromarray(output_change[i].astype(np.uint8))\n",
    "                temp_output_change.convert(\"RGB\").save(result_change[i])\n",
    "    \n",
    "    epochMetrics[\"Loss\"][0] = round(epochMetrics[\"Loss\"][0] / len(valDataLoader), 5)\n",
    "    calculateMatrix(epochMetrics)\n",
    "    printTable(epochMetrics, epochsDisplayMetrics, labelNameList)\n",
    "    returnMetrics = {key: epochMetrics[key][-1] for key in plot_metrics}\n",
    "    return returnMetrics\n",
    "\n",
    "\n",
    "def criterion_N_with_AdvSup(pred, label, AdvSupResult, criterion):\n",
    "    count = 0\n",
    "    loss = 0.0\n",
    "    for name, func in criterion.items():\n",
    "        if func is not None:\n",
    "            count += 1\n",
    "            loss_temp = 0.0\n",
    "            if name == \"focalloss\":\n",
    "                loss_temp = func(pred[0], label[0].long())\n",
    "            elif name == \"adversialsupervised\" and len(AdvSupResult) != 0:\n",
    "                batch_size = label[0].size(0)\n",
    "                for i in AdvSupResult:\n",
    "                    unchange = func(i[:, 0], 1 - label[0].view(batch_size, -1).mean(dim=1)).mean()\n",
    "                    change = func(i[:, 1], label[0].view(batch_size, -1).mean(dim=1)).mean()\n",
    "                    loss_temp += (unchange + change) / 2\n",
    "                loss_temp = loss_temp / len(AdvSupResult)\n",
    "                loss_temp = 0.1 * loss_temp\n",
    "            elif name == \"bce\":\n",
    "                loss_temp = func(pred[0], label[0].long()).mean()\n",
    "            elif name == \"diceloss\":\n",
    "                loss_temp = 0.1 * func(pred[0][:, 1, :, :], label[0]).mean()\n",
    "            loss += loss_temp\n",
    "    return loss / count if count > 0 else loss\n",
    "\n",
    "\n",
    "def criterion_N(pred, label, criterion):\n",
    "    loss_c = criterion[0](pred[0].permute(0, 2, 3, 1).reshape(-1, 2), label[0].reshape(-1).long()).mean()\n",
    "    for i in range(1, 2):\n",
    "        loss_c += criterion[i](pred[0], label[0].long())\n",
    "    loss = loss_c\n",
    "    return loss / len(criterion)\n",
    "\n",
    "\n",
    "def confusionMatrix(metrics, pred, label, threshold=0.5):\n",
    "    for i in range(len(label)):\n",
    "        singlePred = (pred[i] >= threshold).byte()\n",
    "        singleLabel = (label[i] > threshold).byte()\n",
    "        plus = singlePred + singleLabel\n",
    "        FN = (singlePred < singleLabel).sum()\n",
    "        FP = (singlePred > singleLabel).sum()\n",
    "        TP = (plus == 2).sum()\n",
    "        TN = (plus == 0).sum()\n",
    "        \n",
    "        metrics[\"TN\"][i] = metrics[\"TN\"][i] + TN.cpu().item()\n",
    "        metrics[\"FP\"][i] = metrics[\"FP\"][i] + FP.cpu().item()\n",
    "        metrics[\"FN\"][i] = metrics[\"FN\"][i] + FN.cpu().item()\n",
    "        metrics[\"TP\"][i] = metrics[\"TP\"][i] + TP.cpu().item()\n",
    "    return\n",
    "\n",
    "\n",
    "def calculateMatrix(metrics):\n",
    "    for i in range(len(metrics[\"Acc\"]) - 1):\n",
    "        TN = metrics[\"TN\"][i]\n",
    "        FP = metrics[\"FP\"][i]\n",
    "        FN = metrics[\"FN\"][i]\n",
    "        TP = metrics[\"TP\"][i]\n",
    "        \n",
    "        metrics[\"Acc\"][i] = (TP + TN) / (TP + TN + FP + FN)\n",
    "        metrics[\"Pre\"][i] = round(TP / (TP + FP + 0.0001) * 100, 3)\n",
    "        metrics[\"Rec\"][i] = round(TP / (TP + FN + 0.0001) * 100, 3)\n",
    "        metrics[\"IoU\"][i] = round(TP / (TP + FP + FN) * 100, 3)\n",
    "        metrics[\"TNR\"][i] = round(TN / (TN + FP) * 100, 3)\n",
    "        metrics[\"F1\"][i] = round(2 * TP / (2 * TP + FP + FN) * 100, 3)\n",
    "        \n",
    "        Pe = ((TP + FP) * (TP + FN) + (TN + FN) * (TN + FP)) / ((TP + FP + TN + FN) ** 2)\n",
    "        metrics[\"Kappa\"][i] = round((metrics[\"Acc\"][i] - Pe) / (1 - Pe) * 100, 3)\n",
    "        metrics[\"Acc\"][i] = round(metrics[\"Acc\"][i] * 100, 3)\n",
    "    \n",
    "    for k, v in metrics.items():\n",
    "        if len(metrics[\"Acc\"]) > 1:\n",
    "            metrics[k][-1] = sum(metrics[k][:-1]) / (len(metrics[\"Acc\"]) - 1)\n",
    "\n",
    "\n",
    "def printTable(metrics, displayMetrics, labelName):\n",
    "    labelNameCopy = labelName + [\"average\"]\n",
    "    table = PrettyTable([\"\"] + displayMetrics)\n",
    "    for i in range(len(metrics[\"Acc\"]) - 1):\n",
    "        row = [labelNameCopy[i]] + [metrics[key][i] for key in displayMetrics]\n",
    "        table.add_row(row)\n",
    "    print(table)\n",
    "\n",
    "\n",
    "def saveMetricsPlot(metrics, plot_metrics, stage):\n",
    "    stage_name = list(metrics.keys())\n",
    "    stage_name.sort()\n",
    "    epochs = len(list(metrics.values())[0])\n",
    "    \n",
    "    x = range(epochs)\n",
    "    len_stage = 1\n",
    "    len_metric = len(plot_metrics)\n",
    "    fig, axs = plt.subplots(len_metric, len_stage, dpi=600, figsize=(10, 10))\n",
    "    \n",
    "    if len_metric == 1:\n",
    "        axs = [axs]\n",
    "    \n",
    "    for index, each_subplot in enumerate(plot_metrics):\n",
    "        if each_subplot == \"Loss\":\n",
    "            axs[index].set_ylim(0, 0.05)\n",
    "        else:\n",
    "            axs[index].set_ylim(70, 100)\n",
    "        \n",
    "        color = ['b', 'r', 'g', 'c', 'm', 'y', 'k', 'w']\n",
    "        for each_stage in stage:\n",
    "            axs[index].plot(x, metrics[each_subplot + \" \" + each_stage], label=each_stage)\n",
    "        axs[index].set_title(each_subplot)\n",
    "        axs[index].legend()\n",
    "    \n",
    "    fig.savefig(save_dir + os.sep + \"results.png\", bbox_inches=\"tight\")\n",
    "    plt.close(\"all\")\n",
    "\n",
    "\n",
    "def creatPlotProcess(metric_record, plot_metrics, stage):\n",
    "    plotProcess = Process(target=saveMetricsPlot, args=(metric_record, plot_metrics, stage))\n",
    "    plotProcess.start()\n",
    "    plotProcess.join()\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Find all checkpoint models\n",
    "    ckmodels = glob.glob(model_path)\n",
    "    if not ckmodels:\n",
    "        print(f\"No checkpoint models found at: {model_path}\")\n",
    "        print(\"Please ensure you have trained models in the checkpoint directory.\")\n",
    "        return\n",
    "    \n",
    "    for model_file in ckmodels:\n",
    "        print(f\"Evaluating model: {model_file}\")\n",
    "        \n",
    "        setup_seed(42)\n",
    "        model = get_cdnext(out_channels=2, backbone_scale=backboneName, \n",
    "                          pretrained=True, backbone_trainable=True).cuda()\n",
    "        modelParams = filter(lambda p: p.requires_grad, model.parameters())\n",
    "        \n",
    "        # Load the trained model weights\n",
    "        try:\n",
    "            model.load_state_dict(torch.load(model_file, map_location=device))\n",
    "            print(f\"Successfully loaded model from: {model_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model {model_file}: {str(e)}\")\n",
    "            continue\n",
    "            \n",
    "        model.to(device).eval()\n",
    "        \n",
    "        optimizer = optim.AdamW(modelParams, lr=learning_rate, weight_decay=0.05, amsgrad=True)\n",
    "        \n",
    "        if use_amp == True:\n",
    "            scaler = GradScaler()\n",
    "        else:\n",
    "            scaler = None\n",
    "        \n",
    "        # Load test dataset\n",
    "        valDataset, valDataloader = data_loader(ROOTDIR, mode=\"test\", taskList=labelNameList, \n",
    "                                              miniScale=1, batch_size=BATCH_SIZE * 2, \n",
    "                                              shuffle=False, drop_last=False,\n",
    "                                              total_fold=5, valid_fold=5)\n",
    "        \n",
    "        if lossType == \"balance ce\":\n",
    "            criterion = {\n",
    "                \"focalloss\": None,  # FocalLoss().to(device),\n",
    "                \"adversialsupervised\": None,  # nn.L1Loss().to(device),\n",
    "                \"bce\": nn.CrossEntropyLoss().to(device),  # None,\n",
    "                \"diceloss\": None,  # DiceLoss().to(device),\n",
    "            }\n",
    "        \n",
    "        start_i = 0\n",
    "        metric_record = {(plot_metrics[i // len(stage)] + \" \" + stage[i % len(stage)]): [] \n",
    "                        for i in range(len(stage) * len(plot_metrics))}\n",
    "        \n",
    "        print(f\" ====> Evaluating model: {os.path.basename(model_file)}, learning: {optimizer.state_dict()['param_groups'][0]['lr']:.7f}\")\n",
    "        \n",
    "        val_avg_metric = validate(model, 90, valDataloader, criterion, scaler, minival=False)\n",
    "        for key in val_avg_metric.keys():\n",
    "            metric_record[key + \" val\"].append(val_avg_metric[key])\n",
    "        \n",
    "        print(f\"Evaluation completed for {os.path.basename(model_file)}\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "\n",
    "def criterion_N_with_AdvSup(pred, label, AdvSupResult, criterion):\n",
    "    count = 0\n",
    "    loss = 0.0\n",
    "    for name, func in criterion.items():\n",
    "        if func is not None:\n",
    "            count += 1\n",
    "            loss_temp = 0.0\n",
    "            if name == \"focalloss\":\n",
    "                loss_temp = func(pred[0], label[0].long())\n",
    "            elif name == \"adversialsupervised\" and len(AdvSupResult) != 0:\n",
    "                batch_size = label[0].size(0)\n",
    "                for i in AdvSupResult:\n",
    "                    unchange = func(i[:, 0], 1 - label[0].view(batch_size, -1).mean(dim=1)).mean()\n",
    "                    change = func(i[:, 1], label[0].view(batch_size, -1).mean(dim=1)).mean()\n",
    "                    loss_temp += (unchange + change) / 2\n",
    "                loss_temp = loss_temp / len(AdvSupResult)\n",
    "                loss_temp = 0.1 * loss_temp\n",
    "            elif name == \"bce\":\n",
    "                loss_temp = func(pred[0], label[0].long()).mean()\n",
    "            elif name == \"diceloss\":\n",
    "                loss_temp = 0.1 * func(pred[0][:, 1, :, :], label[0]).mean()\n",
    "            loss += loss_temp\n",
    "    return loss / count if count > 0 else loss\n",
    "\n",
    "\n",
    "def criterion_N(pred, label, criterion):\n",
    "    loss_c = criterion[0](pred[0].permute(0, 2, 3, 1).reshape(-1, 2), label[0].reshape(-1).long()).mean()\n",
    "    for i in range(1, 2):\n",
    "        loss_c += criterion[i](pred[0], label[0].long())\n",
    "    loss = loss_c\n",
    "    return loss / len(criterion)\n",
    "\n",
    "\n",
    "def confusionMatrix(metrics, pred, label, threshold=0.5):\n",
    "    for i in range(len(label)):\n",
    "        singlePred = (pred[i] >= threshold).byte()\n",
    "        singleLabel = (label[i] > threshold).byte()\n",
    "        plus = singlePred + singleLabel\n",
    "        FN = (singlePred < singleLabel).sum()\n",
    "        FP = (singlePred > singleLabel).sum()\n",
    "        TP = (plus == 2).sum()\n",
    "        TN = (plus == 0).sum()\n",
    "        \n",
    "        metrics[\"TN\"][i] = metrics[\"TN\"][i] + TN.cpu().item()\n",
    "        metrics[\"FP\"][i] = metrics[\"FP\"][i] + FP.cpu().item()\n",
    "        metrics[\"FN\"][i] = metrics[\"FN\"][i] + FN.cpu().item()\n",
    "        metrics[\"TP\"][i] = metrics[\"TP\"][i] + TP.cpu().item()\n",
    "    return\n",
    "\n",
    "\n",
    "def calculateMatrix(metrics):\n",
    "    for i in range(len(metrics[\"Acc\"]) - 1):\n",
    "        TN = metrics[\"TN\"][i]\n",
    "        FP = metrics[\"FP\"][i]\n",
    "        FN = metrics[\"FN\"][i]\n",
    "        TP = metrics[\"TP\"][i]\n",
    "        \n",
    "        metrics[\"Acc\"][i] = (TP + TN) / (TP + TN + FP + FN)\n",
    "        metrics[\"Pre\"][i] = round(TP / (TP + FP + 0.0001) * 100, 3)\n",
    "        metrics[\"Rec\"][i] = round(TP / (TP + FN + 0.0001) * 100, 3)\n",
    "        metrics[\"IoU\"][i] = round(TP / (TP + FP + FN) * 100, 3)\n",
    "        metrics[\"TNR\"][i] = round(TN / (TN + FP) * 100, 3)\n",
    "        metrics[\"F1\"][i] = round(2 * TP / (2 * TP + FP + FN) * 100, 3)\n",
    "        \n",
    "        Pe = ((TP + FP) * (TP + FN) + (TN + FN) * (TN + FP)) / ((TP + FP + TN + FN) ** 2)\n",
    "        metrics[\"Kappa\"][i] = round((metrics[\"Acc\"][i] - Pe) / (1 - Pe) * 100, 3)\n",
    "        metrics[\"Acc\"][i] = round(metrics[\"Acc\"][i] * 100, 3)\n",
    "    \n",
    "    for k, v in metrics.items():\n",
    "        if len(metrics[\"Acc\"]) > 1:\n",
    "            metrics[k][-1] = sum(metrics[k][:-1]) / (len(metrics[\"Acc\"]) - 1)\n",
    "\n",
    "\n",
    "def printTable(metrics, displayMetrics, labelName):\n",
    "    labelNameCopy = labelName + [\"average\"]\n",
    "    table = PrettyTable([\"\"] + displayMetrics)\n",
    "    for i in range(len(metrics[\"Acc\"]) - 1):\n",
    "        row = [labelNameCopy[i]] + [metrics[key][i] for key in displayMetrics]\n",
    "        table.add_row(row)\n",
    "    print(table)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the given below cell for uplaoding eval.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T05:04:31.621915Z",
     "iopub.status.busy": "2025-09-05T05:04:31.621566Z",
     "iopub.status.idle": "2025-09-05T05:04:31.633968Z",
     "shell.execute_reply": "2025-09-05T05:04:31.633162Z",
     "shell.execute_reply.started": "2025-09-05T05:04:31.621886Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /kaggle/working/eval.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/eval.py\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data as data_\n",
    "from tqdm import tqdm\n",
    "from models.cdnext import get_cdnext\n",
    "from PIL import Image\n",
    "from data_utils.data_loader import WSIDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Process\n",
    "from prettytable import PrettyTable\n",
    "import glob\n",
    "import random\n",
    "\n",
    "labelNameList = [\"change\"]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Dataset path setting - updated for Kaggle structure\n",
    "ROOTDIR = {\n",
    "    \"LEVIRCD\": \"/kaggle/working/processed_data\",\n",
    "}\n",
    "\n",
    "backboneName = \"tiny\"  # 'tiny','small','base','resnet18'\n",
    "SIMULATE_BATCH_SIZE = 32\n",
    "BATCH_SIZE = 16\n",
    "accumulate_steps = SIMULATE_BATCH_SIZE // BATCH_SIZE\n",
    "train_num_workers = 2\n",
    "test_num_workers = 2\n",
    "saveDatasetName = \"-\".join(ROOTDIR.keys())\n",
    "save_dir = \"checkpoint/\" + saveDatasetName\n",
    "total_epoch = 400\n",
    "use_cuda = True\n",
    "num_classes = len(labelNameList)\n",
    "result_dir = \"results/\" + saveDatasetName\n",
    "lossType = \"balance ce\"  # \"ce\" means cross entropy, \"focal\" means focal loss, \"balance ce\" means no parameters ce\n",
    "learning_rate = 4e-5\n",
    "itersDisplayMetrics = [\"Acc\", \"Pre\", \"Rec\", \"IoU\", \"TNR\", \"Loss\"]\n",
    "epochsDisplayMetrics = [\"Acc\", \"Pre\", \"Rec\", \"IoU\", \"TNR\", \"F1\", \"Kappa\", \"Loss\"]\n",
    "plot_metrics = [\"F1\", \"IoU\", \"Loss\"]\n",
    "plot_metrics.sort()\n",
    "stage = [\"train\", \"val\"]\n",
    "stage.sort()\n",
    "use_amp = True\n",
    "\n",
    "# MODIFIED: Single model path - specify your .pth file path here\n",
    "MODEL_PATH = \"/kaggle/input/best_model_f1_79/pytorch/default/1/CDNet_epoch-100_trainF177.71_valF179.30_change.pth\"  # Update this path to your .pth file\n",
    "\n",
    "\n",
    "def setup_seed(seed):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    # torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "def data_loader(ROOTDIR, mode=\"train\", taskList=labelNameList,\n",
    "                miniScale=1, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, \n",
    "                total_fold=5, valid_fold=5):\n",
    "    dataset = WSIDataset(root_dir=ROOTDIR, mode=mode, taskList=taskList, \n",
    "                        total_fold=total_fold, valid_fold=valid_fold, miniScale=miniScale)\n",
    "    dataloader = data_.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=train_num_workers,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        pin_memory=True  # Load into memory to improve speed\n",
    "    )\n",
    "    return dataset, dataloader\n",
    "\n",
    "\n",
    "def save_checkpoints(model, step):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    filename = \"CDNet_\" + str(step) + \"_\" + \"-\".join(labelNameList) + \".pth\"\n",
    "    torch.save(model.state_dict(), os.path.join(save_dir, filename))\n",
    "    print(f\" Save checkpoint {step.split('_')[0]} to {filename}. \\n\")\n",
    "\n",
    "\n",
    "def validate(model, index, valDataLoader, criterion, scaler, minival=False):\n",
    "    showRowLen = num_classes + 1\n",
    "    epochMetricsList = [\"TP\", \"FP\", \"TN\", \"FN\", \"Acc\", \"Pre\", \"Rec\", \"IoU\", \"TNR\", \"F1\", \"Kappa\", \"Loss\"]\n",
    "    epochMetrics = {key: [0] * showRowLen for key in epochMetricsList}\n",
    "    \n",
    "    dir_fold = result_dir + os.sep + str(index)\n",
    "    if not os.path.exists(dir_fold):\n",
    "        os.makedirs(dir_fold, exist_ok=True)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (img1, img2, label1, label2, img_change, dir_name) in tqdm(enumerate(valDataLoader)):\n",
    "            img1, img2, img_change = img1.float(), img2.float(), img_change.float()\n",
    "            \n",
    "            if use_cuda:\n",
    "                img1 = img1.to(device)\n",
    "                img2 = img2.to(device)\n",
    "                img_change = img_change.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            if scaler is None:\n",
    "                output_change = model(img1, img2)\n",
    "                loss = criterion_N_with_AdvSup([output_change], [img_change], model.AdvSupResult, criterion)\n",
    "            else:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    output_change = model(img1, img2)\n",
    "                    loss = criterion_N_with_AdvSup([output_change], [img_change], model.AdvSupResult, criterion)\n",
    "            \n",
    "            output_change = F.softmax(output_change, dim=1)\n",
    "            confusionMatrix(epochMetrics, [output_change[:, 1, :, :].detach()], [img_change.detach()])\n",
    "            epochMetrics[\"Loss\"][0] += loss.detach().cpu().item()\n",
    "            \n",
    "            # Save predictions + inputs + GT\n",
    "            result_change = [dir_fold + os.sep + i + '_comparison.png' for i in dir_name]\n",
    "            output_change_bin = output_change[:, 1, :, :].detach().float()\n",
    "            output_change_bin[output_change_bin >= 0.5] = 255\n",
    "            output_change_bin[output_change_bin < 0.5] = 0\n",
    "            output_change_bin = output_change_bin.cpu().numpy()\n",
    "            \n",
    "            for i in range(output_change_bin.shape[0]):\n",
    "                # Convert tensors to numpy images\n",
    "                t1 = img1[i].cpu().permute(1, 2, 0).numpy()\n",
    "                t2 = img2[i].cpu().permute(1, 2, 0).numpy()\n",
    "                gt = img_change[i].cpu().numpy() * 255\n",
    "                pred = output_change_bin[i]\n",
    "\n",
    "                # Normalize T1, T2 to [0,255]\n",
    "                t1 = (t1 - t1.min()) / (t1.max() - t1.min() + 1e-5)\n",
    "                t2 = (t2 - t2.min()) / (t2.max() - t2.min() + 1e-5)\n",
    "                t1_img = Image.fromarray((t1 * 255).astype(np.uint8))\n",
    "                t2_img = Image.fromarray((t2 * 255).astype(np.uint8))\n",
    "                gt_img = Image.fromarray(gt.astype(np.uint8))\n",
    "                pred_img = Image.fromarray(pred.astype(np.uint8))\n",
    "\n",
    "                # Make 3-channel\n",
    "                gt_img = gt_img.convert(\"RGB\")\n",
    "                pred_img = pred_img.convert(\"RGB\")\n",
    "\n",
    "                # Concatenate horizontally (T1 | T2 | GT | Prediction)\n",
    "                combined = Image.new(\"RGB\", (t1_img.width * 4, t1_img.height))\n",
    "                combined.paste(t1_img, (0, 0))\n",
    "                combined.paste(t2_img, (t1_img.width, 0))\n",
    "                combined.paste(gt_img, (t1_img.width * 2, 0))\n",
    "                combined.paste(pred_img, (t1_img.width * 3, 0))\n",
    "\n",
    "                combined.save(result_change[i])\n",
    "    \n",
    "    epochMetrics[\"Loss\"][0] = round(epochMetrics[\"Loss\"][0] / len(valDataLoader), 5)\n",
    "    calculateMatrix(epochMetrics)\n",
    "    printTable(epochMetrics, epochsDisplayMetrics, labelNameList)\n",
    "    returnMetrics = {key: epochMetrics[key][-1] for key in plot_metrics}\n",
    "    return returnMetrics\n",
    "\n",
    "\n",
    "def criterion_N_with_AdvSup(pred, label, AdvSupResult, criterion):\n",
    "    count = 0\n",
    "    loss = 0.0\n",
    "    for name, func in criterion.items():\n",
    "        if func is not None:\n",
    "            count += 1\n",
    "            loss_temp = 0.0\n",
    "            if name == \"focalloss\":\n",
    "                loss_temp = func(pred[0], label[0].long())\n",
    "            elif name == \"adversialsupervised\" and len(AdvSupResult) != 0:\n",
    "                batch_size = label[0].size(0)\n",
    "                for i in AdvSupResult:\n",
    "                    unchange = func(i[:, 0], 1 - label[0].view(batch_size, -1).mean(dim=1)).mean()\n",
    "                    change = func(i[:, 1], label[0].view(batch_size, -1).mean(dim=1)).mean()\n",
    "                    loss_temp += (unchange + change) / 2\n",
    "                loss_temp = loss_temp / len(AdvSupResult)\n",
    "                loss_temp = 0.1 * loss_temp\n",
    "            elif name == \"bce\":\n",
    "                loss_temp = func(pred[0], label[0].long()).mean()\n",
    "            elif name == \"diceloss\":\n",
    "                loss_temp = 0.1 * func(pred[0][:, 1, :, :], label[0]).mean()\n",
    "            loss += loss_temp\n",
    "    return loss / count if count > 0 else loss\n",
    "\n",
    "\n",
    "def criterion_N(pred, label, criterion):\n",
    "    loss_c = criterion[0](pred[0].permute(0, 2, 3, 1).reshape(-1, 2), label[0].reshape(-1).long()).mean()\n",
    "    for i in range(1, 2):\n",
    "        loss_c += criterion[i](pred[0], label[0].long())\n",
    "    loss = loss_c\n",
    "    return loss / len(criterion)\n",
    "\n",
    "\n",
    "def confusionMatrix(metrics, pred, label, threshold=0.5):\n",
    "    for i in range(len(label)):\n",
    "        singlePred = (pred[i] >= threshold).byte()\n",
    "        singleLabel = (label[i] > threshold).byte()\n",
    "        plus = singlePred + singleLabel\n",
    "        FN = (singlePred < singleLabel).sum()\n",
    "        FP = (singlePred > singleLabel).sum()\n",
    "        TP = (plus == 2).sum()\n",
    "        TN = (plus == 0).sum()\n",
    "        \n",
    "        metrics[\"TN\"][i] = metrics[\"TN\"][i] + TN.cpu().item()\n",
    "        metrics[\"FP\"][i] = metrics[\"FP\"][i] + FP.cpu().item()\n",
    "        metrics[\"FN\"][i] = metrics[\"FN\"][i] + FN.cpu().item()\n",
    "        metrics[\"TP\"][i] = metrics[\"TP\"][i] + TP.cpu().item()\n",
    "    return\n",
    "\n",
    "\n",
    "def calculateMatrix(metrics):\n",
    "    for i in range(len(metrics[\"Acc\"]) - 1):\n",
    "        TN = metrics[\"TN\"][i]\n",
    "        FP = metrics[\"FP\"][i]\n",
    "        FN = metrics[\"FN\"][i]\n",
    "        TP = metrics[\"TP\"][i]\n",
    "        \n",
    "        metrics[\"Acc\"][i] = (TP + TN) / (TP + TN + FP + FN)\n",
    "        metrics[\"Pre\"][i] = round(TP / (TP + FP + 0.0001) * 100, 3)\n",
    "        metrics[\"Rec\"][i] = round(TP / (TP + FN + 0.0001) * 100, 3)\n",
    "        metrics[\"IoU\"][i] = round(TP / (TP + FP + FN) * 100, 3)\n",
    "        metrics[\"TNR\"][i] = round(TN / (TN + FP) * 100, 3)\n",
    "        metrics[\"F1\"][i] = round(2 * TP / (2 * TP + FP + FN) * 100, 3)\n",
    "        \n",
    "        Pe = ((TP + FP) * (TP + FN) + (TN + FN) * (TN + FP)) / ((TP + FP + TN + FN) ** 2)\n",
    "        metrics[\"Kappa\"][i] = round((metrics[\"Acc\"][i] - Pe) / (1 - Pe) * 100, 3)\n",
    "        metrics[\"Acc\"][i] = round(metrics[\"Acc\"][i] * 100, 3)\n",
    "    \n",
    "    for k, v in metrics.items():\n",
    "        if len(metrics[\"Acc\"]) > 1:\n",
    "            metrics[k][-1] = sum(metrics[k][:-1]) / (len(metrics[\"Acc\"]) - 1)\n",
    "\n",
    "\n",
    "def printTable(metrics, displayMetrics, labelName):\n",
    "    labelNameCopy = labelName + [\"average\"]\n",
    "    table = PrettyTable([\"\"] + displayMetrics)\n",
    "    for i in range(len(metrics[\"Acc\"]) - 1):\n",
    "        row = [labelNameCopy[i]] + [metrics[key][i] for key in displayMetrics]\n",
    "        table.add_row(row)\n",
    "    print(table)\n",
    "\n",
    "\n",
    "def saveMetricsPlot(metrics, plot_metrics, stage):\n",
    "    stage_name = list(metrics.keys())\n",
    "    stage_name.sort()\n",
    "    epochs = len(list(metrics.values())[0])\n",
    "    \n",
    "    x = range(epochs)\n",
    "    len_stage = 1\n",
    "    len_metric = len(plot_metrics)\n",
    "    fig, axs = plt.subplots(len_metric, len_stage, dpi=600, figsize=(10, 10))\n",
    "    \n",
    "    if len_metric == 1:\n",
    "        axs = [axs]\n",
    "    \n",
    "    for index, each_subplot in enumerate(plot_metrics):\n",
    "        if each_subplot == \"Loss\":\n",
    "            axs[index].set_ylim(0, 0.05)\n",
    "        else:\n",
    "            axs[index].set_ylim(70, 100)\n",
    "        \n",
    "        color = ['b', 'r', 'g', 'c', 'm', 'y', 'k', 'w']\n",
    "        for each_stage in stage:\n",
    "            axs[index].plot(x, metrics[each_subplot + \" \" + each_stage], label=each_stage)\n",
    "        axs[index].set_title(each_subplot)\n",
    "        axs[index].legend()\n",
    "    \n",
    "    fig.savefig(save_dir + os.sep + \"results.png\", bbox_inches=\"tight\")\n",
    "    plt.close(\"all\")\n",
    "\n",
    "\n",
    "def creatPlotProcess(metric_record, plot_metrics, stage):\n",
    "    plotProcess = Process(target=saveMetricsPlot, args=(metric_record, plot_metrics, stage))\n",
    "    plotProcess.start()\n",
    "    plotProcess.join()\n",
    "\n",
    "\n",
    "def evaluate_single_model(model_path):\n",
    "    \"\"\"\n",
    "    MODIFIED: Function to evaluate a single model file\n",
    "    \"\"\"\n",
    "    # Check if the model file exists\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Model file not found: {model_path}\")\n",
    "        print(\"Please check the path and ensure the .pth file exists.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Evaluating single model: {model_path}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    setup_seed(42)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = get_cdnext(out_channels=2, backbone_scale=backboneName, \n",
    "                      pretrained=True, backbone_trainable=True)\n",
    "    \n",
    "    # Load the trained model weights\n",
    "    try:\n",
    "        checkpoint = torch.load(model_path, map_location=device)\n",
    "        \n",
    "        # Handle different checkpoint formats\n",
    "        if isinstance(checkpoint, dict) and 'state_dict' in checkpoint:\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "        elif isinstance(checkpoint, dict) and 'model' in checkpoint:\n",
    "            model.load_state_dict(checkpoint['model'])\n",
    "        else:\n",
    "            model.load_state_dict(checkpoint)\n",
    "            \n",
    "        print(f\"✓ Successfully loaded model from: {os.path.basename(model_path)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error loading model {model_path}: {str(e)}\")\n",
    "        return\n",
    "    \n",
    "    model.to(device).eval()\n",
    "    \n",
    "    # Initialize optimizer (needed for some model architectures)\n",
    "    modelParams = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = optim.AdamW(modelParams, lr=learning_rate, weight_decay=0.05, amsgrad=True)\n",
    "    \n",
    "    # Initialize scaler for mixed precision\n",
    "    if use_amp:\n",
    "        scaler = GradScaler()\n",
    "    else:\n",
    "        scaler = None\n",
    "    \n",
    "    # Load test dataset\n",
    "    print(\"Loading test dataset...\")\n",
    "    try:\n",
    "        valDataset, valDataloader = data_loader(ROOTDIR, mode=\"test\", taskList=labelNameList, \n",
    "                                              miniScale=1, batch_size=BATCH_SIZE * 2, \n",
    "                                              shuffle=False, drop_last=False,\n",
    "                                              total_fold=5, valid_fold=5)\n",
    "        print(f\"✓ Test dataset loaded successfully. Total samples: {len(valDataset)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error loading test dataset: {str(e)}\")\n",
    "        return\n",
    "    \n",
    "    # Setup loss criterion\n",
    "    if lossType == \"balance ce\":\n",
    "        criterion = {\n",
    "            \"focalloss\": None,\n",
    "            \"adversialsupervised\": None,\n",
    "            \"bce\": nn.CrossEntropyLoss().to(device),\n",
    "            \"diceloss\": None,\n",
    "        }\n",
    "    \n",
    "    # Initialize metrics recording\n",
    "    metric_record = {(plot_metrics[i // len(stage)] + \" \" + stage[i % len(stage)]): [] \n",
    "                    for i in range(len(stage) * len(plot_metrics))}\n",
    "    \n",
    "    print(f\"Starting evaluation...\")\n",
    "    print(f\"Model: {os.path.basename(model_path)}\")\n",
    "    print(f\"Learning rate: {optimizer.state_dict()['param_groups'][0]['lr']:.7f}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Perform validation/evaluation\n",
    "    val_avg_metric = validate(model, \"evaluation\", valDataloader, criterion, scaler, minival=False)\n",
    "    \n",
    "    # Record metrics\n",
    "    for key in val_avg_metric.keys():\n",
    "        metric_record[key + \" val\"].append(val_avg_metric[key])\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"✓ Evaluation completed for {os.path.basename(model_path)}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Print final metrics summary\n",
    "    print(\"\\nFINAL EVALUATION METRICS:\")\n",
    "    print(\"-\" * 40)\n",
    "    for metric_name, value in val_avg_metric.items():\n",
    "        print(f\"{metric_name}: {value}\")\n",
    "    \n",
    "    return val_avg_metric\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    MODIFIED: Main function to evaluate a single model\n",
    "    \"\"\"\n",
    "    print(\"Single Model Evaluation Script\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Check if model path is specified and exists\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        print(f\"Model file not found at: {MODEL_PATH}\")\n",
    "        print(\"\\nPlease update the MODEL_PATH variable with the correct path to your .pth file.\")\n",
    "        print(\"Example paths in Kaggle:\")\n",
    "        print(\"- If uploaded as dataset: '/kaggle/input/your-dataset-name/model.pth'\")\n",
    "        print(\"- If in working directory: '/kaggle/working/model.pth'\")\n",
    "        return\n",
    "    \n",
    "    # Evaluate the single model\n",
    "    results = evaluate_single_model(MODEL_PATH)\n",
    "    \n",
    "    if results:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"EVALUATION SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Model evaluated: {os.path.basename(MODEL_PATH)}\")\n",
    "        print(f\"Metrics results saved to: {result_dir}\")\n",
    "        print(f\"4-panel comparison images saved to: {result_dir}/evaluation/\")\n",
    "        print(\"Each comparison image shows: T1 | T2\")\n",
    "        print(\"                           GT | Prediction\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# In your Kaggle notebook\n",
    "%cd /kaggle/working\n",
    "!python train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T05:05:58.532701Z",
     "iopub.status.busy": "2025-09-05T05:05:58.532418Z",
     "iopub.status.idle": "2025-09-05T05:06:35.365892Z",
     "shell.execute_reply": "2025-09-05T05:06:35.365156Z",
     "shell.execute_reply.started": "2025-09-05T05:05:58.532680Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n",
      "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "/kaggle/working/models/convnext.py:168: UserWarning: Overwriting convnext_tiny in registry with models.convnext.convnext_tiny. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "/kaggle/working/models/convnext.py:185: UserWarning: Overwriting convnext_small in registry with models.convnext.convnext_small. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "/kaggle/working/models/convnext.py:201: UserWarning: Overwriting convnext_base in registry with models.convnext.convnext_base. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "/kaggle/working/models/convnext.py:217: UserWarning: Overwriting convnext_large in registry with models.convnext.convnext_large. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "/kaggle/working/models/convnext.py:233: UserWarning: Overwriting convnext_xlarge in registry with models.convnext.convnext_xlarge. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "Single Model Evaluation Script\n",
      "================================================================================\n",
      "Evaluating single model: /kaggle/input/best_model_f1_79/pytorch/default/1/CDNet_epoch-100_trainF177.71_valF179.30_change.pth\n",
      "================================================================================\n",
      "is pretrained:  True\n",
      "✓ Successfully loaded model from: CDNet_epoch-100_trainF177.71_valF179.30_change.pth\n",
      "/kaggle/working/eval.py:324: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "Loading test dataset...\n",
      "T1 patch numbers: 348\n",
      "T2 patch numbers: 348\n",
      "Label patch numbers: 348\n",
      "✓ Test dataset loaded successfully. Total samples: 348\n",
      "Starting evaluation...\n",
      "Model: CDNet_epoch-100_trainF177.71_valF179.30_change.pth\n",
      "Learning rate: 0.0000400\n",
      "--------------------------------------------------------------------------------\n",
      "0it [00:00, ?it/s]/kaggle/working/eval.py:113: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "=== FEATURE FUSION DEBUG ===\n",
      "FusionFeatures shapes: [torch.Size([32, 768, 64, 64]), torch.Size([32, 384, 64, 64]), torch.Size([32, 192, 64, 64]), torch.Size([32, 96, 64, 64])]\n",
      "fusion shape: torch.Size([32, 1440, 64, 64])\n",
      "size_change: [768, 384, 192, 96]\n",
      "sum(size_change[:-1]): 1344\n",
      "Expected channels: 1344\n",
      "Actual channels: 1440\n",
      "1it [00:06,  6.94s/it]=== FEATURE FUSION DEBUG ===\n",
      "FusionFeatures shapes: [torch.Size([32, 768, 64, 64]), torch.Size([32, 384, 64, 64]), torch.Size([32, 192, 64, 64]), torch.Size([32, 96, 64, 64])]\n",
      "fusion shape: torch.Size([32, 1440, 64, 64])\n",
      "size_change: [768, 384, 192, 96]\n",
      "sum(size_change[:-1]): 1344\n",
      "Expected channels: 1344\n",
      "Actual channels: 1440\n",
      "2it [00:08,  3.99s/it]=== FEATURE FUSION DEBUG ===\n",
      "FusionFeatures shapes: [torch.Size([32, 768, 64, 64]), torch.Size([32, 384, 64, 64]), torch.Size([32, 192, 64, 64]), torch.Size([32, 96, 64, 64])]\n",
      "fusion shape: torch.Size([32, 1440, 64, 64])\n",
      "size_change: [768, 384, 192, 96]\n",
      "sum(size_change[:-1]): 1344\n",
      "Expected channels: 1344\n",
      "Actual channels: 1440\n",
      "3it [00:10,  3.05s/it]=== FEATURE FUSION DEBUG ===\n",
      "FusionFeatures shapes: [torch.Size([32, 768, 64, 64]), torch.Size([32, 384, 64, 64]), torch.Size([32, 192, 64, 64]), torch.Size([32, 96, 64, 64])]\n",
      "fusion shape: torch.Size([32, 1440, 64, 64])\n",
      "size_change: [768, 384, 192, 96]\n",
      "sum(size_change[:-1]): 1344\n",
      "Expected channels: 1344\n",
      "Actual channels: 1440\n",
      "4it [00:12,  2.66s/it]=== FEATURE FUSION DEBUG ===\n",
      "FusionFeatures shapes: [torch.Size([32, 768, 64, 64]), torch.Size([32, 384, 64, 64]), torch.Size([32, 192, 64, 64]), torch.Size([32, 96, 64, 64])]\n",
      "fusion shape: torch.Size([32, 1440, 64, 64])\n",
      "size_change: [768, 384, 192, 96]\n",
      "sum(size_change[:-1]): 1344\n",
      "Expected channels: 1344\n",
      "Actual channels: 1440\n",
      "5it [00:14,  2.40s/it]=== FEATURE FUSION DEBUG ===\n",
      "FusionFeatures shapes: [torch.Size([32, 768, 64, 64]), torch.Size([32, 384, 64, 64]), torch.Size([32, 192, 64, 64]), torch.Size([32, 96, 64, 64])]\n",
      "fusion shape: torch.Size([32, 1440, 64, 64])\n",
      "size_change: [768, 384, 192, 96]\n",
      "sum(size_change[:-1]): 1344\n",
      "Expected channels: 1344\n",
      "Actual channels: 1440\n",
      "6it [00:16,  2.25s/it]=== FEATURE FUSION DEBUG ===\n",
      "FusionFeatures shapes: [torch.Size([32, 768, 64, 64]), torch.Size([32, 384, 64, 64]), torch.Size([32, 192, 64, 64]), torch.Size([32, 96, 64, 64])]\n",
      "fusion shape: torch.Size([32, 1440, 64, 64])\n",
      "size_change: [768, 384, 192, 96]\n",
      "sum(size_change[:-1]): 1344\n",
      "Expected channels: 1344\n",
      "Actual channels: 1440\n",
      "7it [00:18,  2.18s/it]=== FEATURE FUSION DEBUG ===\n",
      "FusionFeatures shapes: [torch.Size([32, 768, 64, 64]), torch.Size([32, 384, 64, 64]), torch.Size([32, 192, 64, 64]), torch.Size([32, 96, 64, 64])]\n",
      "fusion shape: torch.Size([32, 1440, 64, 64])\n",
      "size_change: [768, 384, 192, 96]\n",
      "sum(size_change[:-1]): 1344\n",
      "Expected channels: 1344\n",
      "Actual channels: 1440\n",
      "8it [00:20,  2.09s/it]=== FEATURE FUSION DEBUG ===\n",
      "FusionFeatures shapes: [torch.Size([32, 768, 64, 64]), torch.Size([32, 384, 64, 64]), torch.Size([32, 192, 64, 64]), torch.Size([32, 96, 64, 64])]\n",
      "fusion shape: torch.Size([32, 1440, 64, 64])\n",
      "size_change: [768, 384, 192, 96]\n",
      "sum(size_change[:-1]): 1344\n",
      "Expected channels: 1344\n",
      "Actual channels: 1440\n",
      "9it [00:22,  2.05s/it]=== FEATURE FUSION DEBUG ===\n",
      "FusionFeatures shapes: [torch.Size([32, 768, 64, 64]), torch.Size([32, 384, 64, 64]), torch.Size([32, 192, 64, 64]), torch.Size([32, 96, 64, 64])]\n",
      "fusion shape: torch.Size([32, 1440, 64, 64])\n",
      "size_change: [768, 384, 192, 96]\n",
      "sum(size_change[:-1]): 1344\n",
      "Expected channels: 1344\n",
      "Actual channels: 1440\n",
      "10it [00:24,  2.01s/it]=== FEATURE FUSION DEBUG ===\n",
      "FusionFeatures shapes: [torch.Size([28, 768, 64, 64]), torch.Size([28, 384, 64, 64]), torch.Size([28, 192, 64, 64]), torch.Size([28, 96, 64, 64])]\n",
      "fusion shape: torch.Size([28, 1440, 64, 64])\n",
      "size_change: [768, 384, 192, 96]\n",
      "sum(size_change[:-1]): 1344\n",
      "Expected channels: 1344\n",
      "Actual channels: 1440\n",
      "11it [00:29,  2.69s/it]\n",
      "+--------+--------+--------+-------+--------+--------+--------+--------+--------+\n",
      "|        |  Acc   |  Pre   |  Rec  |  IoU   |  TNR   |   F1   | Kappa  |  Loss  |\n",
      "+--------+--------+--------+-------+--------+--------+--------+--------+--------+\n",
      "| change | 98.124 | 80.514 | 71.21 | 60.742 | 99.268 | 75.577 | 74.605 | 0.0584 |\n",
      "+--------+--------+--------+-------+--------+--------+--------+--------+--------+\n",
      "\n",
      "================================================================================\n",
      "✓ Evaluation completed for CDNet_epoch-100_trainF177.71_valF179.30_change.pth\n",
      "================================================================================\n",
      "\n",
      "FINAL EVALUATION METRICS:\n",
      "----------------------------------------\n",
      "F1: 75.577\n",
      "IoU: 60.742\n",
      "Loss: 0.0584\n",
      "\n",
      "================================================================================\n",
      "EVALUATION SUMMARY\n",
      "================================================================================\n",
      "Model evaluated: CDNet_epoch-100_trainF177.71_valF179.30_change.pth\n",
      "Metrics results saved to: results/LEVIRCD\n",
      "4-panel comparison images saved to: results/LEVIRCD/evaluation/\n",
      "Each comparison image shows: T1 | T2\n",
      "                           GT | Prediction\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working\n",
    "!python eval.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T05:09:13.227062Z",
     "iopub.status.busy": "2025-09-05T05:09:13.226757Z",
     "iopub.status.idle": "2025-09-05T05:09:27.175257Z",
     "shell.execute_reply": "2025-09-05T05:09:27.174526Z",
     "shell.execute_reply.started": "2025-09-05T05:09:13.227022Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/working_backup.zip'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Create a zip archive of all files in /kaggle/working\n",
    "shutil.make_archive(\"/kaggle/working/working_backup\", 'zip', \"/kaggle/working\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T05:05:01.472567Z",
     "iopub.status.busy": "2025-09-05T05:05:01.472280Z",
     "iopub.status.idle": "2025-09-05T05:05:01.485519Z",
     "shell.execute_reply": "2025-09-05T05:05:01.484979Z",
     "shell.execute_reply.started": "2025-09-05T05:05:01.472547Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Replace \"my_folder\" with the folder name\n",
    "shutil.rmtree(\"/kaggle/working/results\", ignore_errors=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink, FileLinks\n",
    "\n",
    "# Link to a single file\n",
    "FileLink(\"/kaggle/working/results.zip\")\n",
    "\n",
    "# Or link to all files in working\n",
    "FileLinks(\"/kaggle/working\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T05:17:09.150555Z",
     "iopub.status.busy": "2025-09-05T05:17:09.149722Z",
     "iopub.status.idle": "2025-09-05T05:17:09.535593Z",
     "shell.execute_reply": "2025-09-05T05:17:09.534757Z",
     "shell.execute_reply.started": "2025-09-05T05:17:09.150528Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!mkdir -p /kaggle/working/my_outputs\n",
    "!cp -r /kaggle/working/results/* /kaggle/working/my_outputs/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8150876,
     "sourceId": 12883385,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 442465,
     "modelInstanceId": 424980,
     "sourceId": 561397,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
